<!DOCTYPE html>
<head lang="en">
	<base target="_top" rel="noopener noreferrer nofollow">
</head>

<h1>OpenGL C programming tutorial (Win32 API)</h1>
<h3><a name="#overview">Lessons overview</a></h3>

<ul class="index">
	<li><a href="#sdk">LESSON 1 - SDK</a></li>
	<li><a href="#legacy-opengl">LESSON 2 - Legacy code</a></li>
	<li><a href="#winapi-pt1">LESSON 3 - Windows API SDK pt. 1</a></li>
	<li><a href="#winapi-pt2">LESSON 4 - Windows API SDK pt. 2</a></li>
	<li><a href="#winapi-pt3">LESSON 5 - Windows SDK API pt. 3 - WM_PAINT in WndProc</a></li>
	<li><a href="#winapi-pt4">LESSON 6 - Windows SDK API pt. 4 - WM_PAINT cont.</a></li>
	<li><a href="#winapi-pt5">LESSON 7 - Windows SDK API pt. 5 - Fullscreen Application</a></li>
	<li><a href="#init-opengl-pt1">LESSON 8 - Initializing OpenGL pt. 1 - Choosing the Pixel Format</a></li>
	<li><a href="#init-opengl-pt2">LESSON 9 - Initializing OpenGL pt. 2</a></li>
	<li><a href="#clipping-area-and-viewport">LESSON 10 - Clipping Area and Viewport</a></li>
	<li><a href="#doublebuffer-pt1">LESSON 11 - Doublebuffering and Perspective pt. 1</a></li>
	<li><a href="#doublebuffer-pt2">LESSON 12 - Doublebuffering and Perspective pt. 2</a></li>
	<li><a href="#vertice-transform-pt1">LESSON 13 - Transformation of Vertices pt. 1</a></li>
	<li><a href="#vertice-transform-pt2">LESSON 14 - Transformation of Vertices pt. 2</a></li>
	<li><a href="#vertice-transform-pt3">LESSON 15 - Transformation of Vertices pt. 3</a></li>
	<li><a href="#identity-matrix">LESSON 16 - glLoadIdentity</a></li>
	<li><a href="#glulookat">LESSON 17 - gluLookAt</a></li>
	<li><a href="#drawing-advance-geo-pt1">LESSON 18 - Drawing advanced geometry pt. 1</a></li>
	<li><a href="#drawing-advance-geo-pt2">LESSON 19 - Drawing advanced geometry pt. 2 (Drawing an incircle)</a></li>
	<li><a href="#individual-transform">LESSON 20 - Adding individual transformations to objects</a></li>
	<li><a href="#drawing-3d-pt1">LESSON 21 - Drawing 3D objects</a></li>
	<li><a href="#texture-load-image-pt1">LESSON 22 - Loading an image file as texture</a></li>
	<li><a href="#load-audio-pt1">LESSON 23 - Detailing win32 load audio</a></li>
	<li><a href="#">LESSON 24 - Detailing win32 load bitmap pt. 2</a></li>
	<li><a href="#texture-quad-uv">LESSON 25 - UV coordinates of a quad</a></li>
	<li><a href="#procgen-pt1">LESSON 26 - Procedural generation pt. 1</a></li>
	<li><a href="#procgen-pt2">LESSON 27 - Procedural generation pt. 2</a></li>
	<li><a href="#drawing-advance-geo-pt3">LESSON 28 - Drawing advanced geometry pt. 3</a></li>
	<li><a href="#procgen-pt3">LESSON 29 - Procedural generation pt. 3 (Mandelbrot)</a></li>
	<li><a href="#matrix-v-identity-matrix">LESSON 30 - Matrices and Identity Matrix</a></li>
	<li><a href="#simulating-planets-glu-pt1">LESSON 31 - Simulating planets with rotation using GLU pt. 1</a></li>
	<li><a href="#simulating-planets-glu-pt2">LESSON 32 - Simulating planets with rotation using GLU pt. 2</a></li>
	<li><a href="#simulating-robotic-arm">LESSON 33 - Simulating a robotic arm with multiple joints</a></li>
	<li><a href="#progcen-drawing-circle-pt1">LESSON 34 - Procedurally drawing a circle pt. 1</a></li>
	<li><a href="#lighting-pt1">LESSON 35 - Rendering light pt. 1</a></li>
	<li><a href="#lighting-pt2">LESSON 36 - Rendering light pt. 2</a></li>
	<li><a href="#lighting-pt3">LESSON 37 - Rendering light pt. 3</a></li>
	<li><a href="#lighting-pt4">LESSON 38 - Rendering light pt. 4</a></li>
	<li><a href="#texture-sphere">LESSON 39 - Texturing a sphere</a></li>
	<li><a href="#fog-effect">LESSON 40 - Implementing fog</a></li>
	<li><a href="#improved-rendering">LESSON 41 - Improving draw calls and texture tiling</a></li>
	<li><a href="#revisiting-fixed-functional-pipeline">LESSON 42 - Revisiting the Fixed Funtional Pipeline</a></li>
	<li><a href="#programmable-pipeline-pt1">LESSON 43 - Programmable pipelines pt. 1</a></li>
	<li><a href="#programmable-pipeline-pt2">LESSON 44 - Programmable pipelines pt. 2</a></li>
	<li><a href="#programmable-pipeline-pt3">LESSON 45 - Programmable pipelines pt. 3</a></li>
	<li><a href="#modern-opengl-context-pt1">LESSON 46 - Setting up a modern OpenGL context pt. 1</a></li>
	<li><a href="#modern-opengl-context-pt2">LESSON 47 - Setting up a modern OpenGL context pt. 2</a></li>
	<li><a href="#modern-opengl-context-pt3">LESSON 48 - Setting up a modern OpenGL context pt. 3 (shaders)</a></li>
	<li><a href="#modern-opengl-context-pt4">LESSON 49 - Setting up a modern OpenGL context pt. 4</a></li>
	<li><a href="#modern-opengl-context-pt5">LESSON 50 - Setting up a modern OpenGL context pt. 5</a></li>
	<li><a href="#modern-opengl-context-pt6">LESSON 51 - Setting up a modern OpenGL context pt. 6</a></li>
	<li></li>
	<li></li>
	<li></li>
	<li></li>
	<li></li>
	<li></li>
	<li></li>
	<li></li>
</ul>



<h1><a name="sdk">LESSON 1: SDK</a></h1>


<div id="update"></div>



<h2>Software Development Kit</h2>
<label><b>Compulsary</b></label>
<ol type="1">
	<li><b>ToolChain</b> &rarr; 
			<ol>
				<li><b>Compiler</b> - <span>conversion of human understandable code to machine code</span></li>
				<li><b>Linker</b> - link with the (OS, custom header) libraries</li>
				<li><b>Loader</b> (loads exe into the RAM) / Interpreter (converts VM code and loads)</li>
				<li><b>Assembler, Diassembler,<br/>&nbsp;&nbsp;Debugger</b></li>
			</ol>
	</li>
	<li><b>API LIbraries</b> &rarr; <ol type="1"><li>Procedural Oriented</li> <li>Object Oriented</li></ol></li>
	<li><b>Documentation</b> &rarr; MSDN</li>
	<li><b>Header File</b> (C) / <b>Packages</b> (Java) / <b>Namespaces</b> (Cpp) &rarr; Languages packages containing [...]</li>
</ol>
<label><b>Optional</b></label>
<ol type="1" start="5">
	<li><b>VM</b> (virtual machine) / <b>RE</b> (runtime env. native development)</li>
	<li><b>IDE</b> - Integrated Development Environment</li>
</ol>

<b>Hello.cpp</b>
<p id="note">NOTE: Prints a standard "Hello, World!" program in C.</p>
<pre><code>
#include &lt;stdio.h&gt;

int main()
{
	printf("Hello, World!");
	return 0;
}
</code></pre>

<img src="hello-world.png" />

<h2>Compiling</h2>

<p><b>Note on compilers:</b> 
	<a href="https://courses.cs.washington.edu/courses/cse378/97au/help/compilation.html"></a>
</p>
<details>
<summary>Compiler notes</summary>
<p> <!-- This section is stolen, see link below -->
<img src="https://courses.cs.washington.edu/courses/cse378/97au/help/cc.gif" alt="cc from "https://courses.cs.washington.edu/courses/cse378/97au/help/cc.gif"" />
<p>
	First, the C preprocessor cpp expands all those macros definitions and include statements (and anything else that starts with a #) and passes the result to the actual compiler. The preprocessor is not so interesting 
	because it just replaces some short cuts you used in your code with more code. 
The output of cpp is just C code; if you didn't have any preprocessor statements in your file, you wouldn't need to run cpp. The preprocessor does not require any knowledge about the target architecture. If you had the 
correct include files, you could preprocess your C files on a LINUX machine and take the output to the instructional machines and pass that to cc. To see the output of a preprocessed file, use cc -E.
</p>

<p>
	The compiler effectively translates preprocessed C code into assembly code, performing various optimizations along the way as well as register allocation. Since a compiler generates assembly code specific to a 
	particular architecture, you cannot use the assembly output of cc from an Intel Pentium machine on one of the instructional machines (Digital Alpha machines).
</p>

<p>
	The assembly code generated by the compilation step is then passed to the assembler which translates it into machine code; the resulting file is called an object file. On the instructional machines, both cc and gcc 
	use the native assembler as that is provided by UNIX. You could write an assembly language program and pass it directly to as and even to cc (this is what we do in project 2 with sys.s). An object file is a binary 
	representation of your program. The assembler gives a memory location to each variable and instruction; we will see later that these memory locations are actually represented symbolically or via offsets. It also make 
	a lists of all the unresolved references that presumably will be defined in other object file or libraries, e.g. printf. A typical object file contains the program text (instructions) and data (constants and strings), 
	information about instructions and data that depend on absolute addresses, a symbol table of unresolved references, and possibly some debugging information. The UNIX command nm allows you to look at the symbols 
	(both defined and unresolved) in an object file.
</p>

<p>
	Since an object file will be linked with other object files and libraries to produce a program, the assembler cannot assign absolute memory locations to all the instructions and data in a file. Rather, it writes some 
	notes in the object file about how it assumed things were layed out. It is the job of the linker to use these notes to assign absolute memory locations to everything and resolve any unresolved references. Again, both 
	cc and gcc on the instructional machines use the native linker, ld. Some compilers chose to have their own linkers, so that optimizations can be performed at link time; one such optimization is that of aligning procedures 
	on page boundaries. The linker produces a binary executable that can be run from the command interface.
</p>

<p>
	Notice that you could invoke each of the above steps by hand. Since it is an annoyance to call each part separately as well as pass the correct flags and files, cc does this for you. For example, you could run the entire 
	process by hand by invoking /lib/cpp and then cc -S and then /bin/as and finally ld. If you think this is easy, try compiling a simple program in this way.
</p>


<h2>Running a Program</h2>
<p>
	When you type a.out at the command line, a whole bunch of things must happen before your program is actually run. The loader magically does these things for you. On UNIX systems, the loader creates a process. This 
	involves reading the file and creating an address space for the process. Page table entries for the instructions, data and program stack are created and the register set is initialized. Then the loader executes a 
	jump instruction to the first instruction in the program. This generally causes a page fault and the first page of your instructions is brought into memory. On some systems the loader is a little more interesting. 
	For example, on systems like Windows NT that provide support for dynamically loaded libraries (DLLs), the loader must resolve references to such libraries similar to the way a linker does.
</p>

<h2>Memory</h2>
<p>Figure 2 illustrates a typical layout for program memory. It is the job of the loader to map the program, static data (including globals and strings) and the stack to physical addresses. Notice that the stack is mapped 
to the high addresses and grows down and the program and data are mapped to the low addresses. The area labeled heap is where the data you allocate via malloc is placed. A call to malloc may use the sbrk system call to add 
more physical pages to the program's address space (for more information on malloc, free and sbrk, see the man pages).</p>
<h2>Memory layout</h2>

<img src="https://courses.cs.washington.edu/courses/cse378/97au/help/mem.gif" alt="Memory Stack from "https://courses.cs.washington.edu/courses/cse378/97au/help/mem.gif" />
<figure>Figure 2: Memory layout.</figure>

<h2>Procedure Call Conventions</h2>
<p>
	A call to a procedure is a context switch in your program. Just like any other context switch, some state must be saved by the calling procedure, or caller, so that when the called procedure, or callee, returns the caller may 
	continue execution without distraction. To enable separate compilation, a compiler must follow a set of rules for use of the registers when calling procedures. This procedure call convention may be different across compilers 
	(does cc and gcc use the same calling convention?) which is why object files created by one compiler cannot always be linked with that of another compiler.
	A typical calling convention involves action on the part of the caller and the callee. The caller places the arguments to the callee in some agreed upon place; this place is usually a few registers and the extras are passed 
	on the stack (the stack pointer may need to be updated). Then the caller saves the value of any registers it will need after the call and jumps to the callee's first instruction. The callee then allocates memory for its stack 
	frame and saves any registers who's values are guaranteed to be unaltered through a procedure call, e.g. return address. When the callee is ready to return, it places the return value, if any, in a special register and 
	restores the callee-saved registers. It then pops the stack frame and jumps to the return address.
</p>
</p>
</details>


<p>Microsoft Visual Studio Communitys compiler is called <i>cl.exe</i>, and can be invoked through the commandline by calling cl.exe &lt;<i>filename</i>&gt; - where filename is a CSV of sourcefile(s) you are compiling.</p>
	<b>cl.exe Hello.cpp</b>
<p>This creates an <i>Hello.obj</i> which is callable by <i>Hello.exe</i>.</p>

<p><b>Hardware</b> - Wrapped in the assembly language in the OS in the first ~4kb memory for the bootloader (BIOS)</p>
<p><b>Bootloader</b> - the whole brain of the OS</p>
<p><b>Win32 SDK</b> - MS created a wrapper around C language for native developers (GUI)</p>
<p><b>MFC - Microsoft Foundation Code</b> - a C++ wrapper for the SDK</p>
<p><b>Component Object Model</b> - COM is a binary-interface standard for software components</p>
<p><b>COM+</b> - Is another wrapper for the COM from WinNT mostly implemented into COM with Win2000</p>
<p><b>JVM / CLR</b> - Java Virtual Machine, .NET (not for driver development)</p>

<p>Web development  - </p>

<p>* If you write something in eg. CLR (.NET) it has to convert the code through each layer below before it's runnable.</p>

<p><b>WinRT</b> - Windows Runtime (launched in 2012 for mobile, nearer to COM, it's around COM+)</p>
<p><b>Nano-COM</b> (a.k.a XPCOM) ..? </p>

<h2>OpenGL overview</h2>
<p>Is a spesification by Silicon Group (founder) and Khronos Group (standardization).</p>

<p><b>Fixed Functional Pipeline</b> (eg. ~OpenGL 3.0) - you can't change the pipeline</p>

<p><b>More on legacy OpenGL:</b> doesn't support reading and writing graphical images (PNG, JPG, etc).</p>

<p><b>Programmable Pipeline</b> (eg. Vulkan, modern OpenGL) - you can customize the pipeline</p>
<ul>
	<li>Vertex shader (VS) &rarr; Each vertex</li>
	<li>Tesselation shader (TS) &rarr; Level of details</li>
	<li>Geometry shader (GS) &rarr; Geometry and instancing</li>
	<li>Fragment shader (FS) &rarr; Manipulate each pixel</li>
</ul>
<p>Eg. Cooking chicken - you add the Chicken (VS) &rarr; Masala (TS) &rarr; Salt (GS) &rarr; Each piece (FS)</p>

<p id="note">
Further improvements: 
- Define the fixed functional pipeline in more details
</p>





<h1><a name="legacy-opengl">LESSON 2: Legacy code</a></h1>
<p>Legacy OpenGL uses the <b>fixed functional pipeline</b> ...</p>

<h2>GLUT</h2>
<p>GLUT (<i>OpenGL Utility Toolkit</i>) is a deprecated application abstraction layer to render OpenGL code, but it's widely used in older projects.</p>

<h2>Set up freeglut</h2>
<p>To set up your <a href="https://visualstudio.microsoft.com/downloads/" target="_blank">Visual Studio Community 2019</a> to use <b>freeglut</b> download the library from <a href="http://freeglut.sourceforge.net/" target="_blank">http://freeglut.sourceforge.net/</a>,
extract it in a folder like <b>C:\libraries\freeglut\</b> and add it to your projects settings found under <b>Project &lt;%YOUR_PROJECT_NAME%&gt; Properties</b> on the <i>file menu</i>.</p> 
<p>You have to tell the compiler you want it to look for external libraries by link the library folder under the settings found under:</p>
	<b>C/C++ &gt; General &gt; Additional Include Directories</b>
<p>pointing to the folder where you extracted freeglut and</p>
	<b>Linker > General > Additional Library Directories </b>.</p>

<h2>Setting SubSystem</h2>
<p>Remove the commandline window under <b>Linker &gt; System &gt; SubSystem</b> by expanding the menu on the right side and selecting <b>Windows (/SUBSYSTEM:WINDOWS)</b>.</p>

<h2>Setting application main entry point</h2>
<p>To compile and run this project you have to set the application main entry point found under <b>Project &gt; YOUR_PROJECT_NAME Properties &gt; Linker &gt; Advanced &gt; Entry Point</b> and set it to <b>mainCRTStartup</b>.</p>

<h2>Application Entry Point</h2>
To remove the <b>LNK2019 unresolved external symbol _WinMain@16 referenced in function "int __cdecl invoke_main(void)" (?invoke_main@@YAHXZ)</b> 
error and <b>LNK1120 1 unresolved externals</b> define the application main startup by adding <b>mainCRTStartup</b> under:</p> 
	<b>Linker &gt; Advanced &gt; Entry Point</b>

<h2>OpenGL coordinate system</h2>
<p>Screen coordinates { 0.0, 0.0 } is in the upper-left corner on Windows, but in the lower-left corner (<i>anti-clockwise</i>) in OpenGL.</p>
<p>Indicies are counted from lower left corner, so given a square:</p>
<pre><code>
float vertices[] = {
	-0.5, 	 0.5, 	0.0, 	// 1st - 0		0 +-------+ 3
	-0.5,	-0.5,	0.0, 	// 2nd - 1		  |	  |
	 0.5, 	-0.5, 	0.0, 	// 3rd - 2		  |	  | <-- Covers half the screen
	 0.5, 	 0.5, 	0.0 	// 4th - 3		1 +-------+ 2
};
</code></pre>

<pre><code>
int indices = [3, 2, 1, 3, 1, 0]
</code></pre>

<p>Will create a square. If you remove <b>3, 2, 1</b> it will be a triangle in the upper right corner etc.</p>

<p>Transform default viewspace to follow windows coordinates with <b>glTranslatef(0.0f, -h, 0.0f)</b>.</p>

<h3>main.cpp</h3>
<p id="note">NOTE: Full implementation of displaying a colored triangle in the <i>fixed functional pipeline</i> in ~OpenGL3.0 using freeglut.</p>

<p id="note">Take a look at <b>glutEnterGameMode()</b> / <b>glutLeaveGameMode()</b> and <b>glutGameModeString( “990×768:32@75” )</b></p>

<p>** Using the .cpp extension on sourcefile to make Visual Studio recognize it as C++ code to compile C in Cpp.</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;GL/freeglut.h&gt;

void initialize();
void display(void);
void resize(int, int);
void keyboard(unsigned char, int, int);
void mouse(int, int, int, int);

bool bIsFullscreen = false;

int main(int argc, char* argv[])
{
	glutInit(&argc, argv);				// Initialize glut with commandline args
	glutInitDisplayMode(GLUT_SINGLE | GLUT_RGBA);	// GLUT_SINGLE single framebuffer instance, show this to the user. GLUT_RGBA is the color schema
	glutInitWindowSize(800, 600);			// Set the program width and height
	glutInitWindowPosition(100, 100);		// Position the app from the top left corner
	glutCreateWindow("C-OpenGL first triangle");	// Create the app window based on the previous params
	initialize();					// Giving a call to glClear color (glClear takes this call to the framebuffer)
	glutDisplayFunc(display);			// Display something where you will be rendering everything 
	glutReshapeFunc(resize);			// Resize the window (unhandled in this project)
	glutKeyboardFunc(keyboard);			// Callback to the keyboard
	glutMouseFunc(mouse);				// Callback to the mouse
	glutMainLoop();					// The program main loop

	return 0;					// ANSI C requires that main function returns an int
}

void initialize()
{
	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
}

void display() 
{
	glClear(GL_COLOR_BUFFER_BIT);
	// Transform matrix 
	glMatrixMode(GL_MODELVIEW);			// Set model projection for viewspace
	glLoadIdentity(); 				// OpenGL follows anti-clockwise positioning (lower left corner is (0.0f, 0.0f))

	// Note on legacy OpenGL code:
	// All drawcalls ( > OpenGL3.0 ) must be placed inbetween calls to glBegin and glEnd
	glBegin(GL_TRIANGLES);
	
		// Transformation is handled by glLoadIdentity 
		
		glColor3f(1.0f, 0.0f, 0.0f); 	// Set the color for vertex[0] to RED
		glVertex2f(0.0f, 1.0f);		// vertex[0] - top 
		glColor3f(0.0f, 1.0f, 0.0f);	// Set the color for vertex[1] to BLUE
		glVertex2f(-1.0f, -1.0f);	// vertex[1] - bottom left
		glColor3f(0.0f, 0.0f, 1.0f);	// Set the color for vertex[2] to GREEN
		glVertex2f(1.0f, -1.0f);	// vertex[2] - bottom right
		
	glEnd();

	glFlush();	// Single framebuffer, so needs a flush!
}

// callback function for window resize events
void resize(int width, int height)
{
	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
}

// callback function for keyboard input
void keyboard(unsigned char key, int x, int y)
{
	switch (key) {
		case 27: // ESC
			glutLeaveMainLoop();
			break;
		case 'f':
		case 'F':
			if (bIsFullscreen == false) {
				glutFullScreen();
				bIsFullscreen = true;
			}
			else {
				glutLeaveFullScreen();
				bIsFullscreen = false;
			}
			break;
	}
}

// callback function for mouse handling
void mouse(int button, int state, int x, int y)
{
	switch (button) {
		case GLUT_RIGHT_BUTTON:
			glutLeaveMainLoop();
			break;
	}
}
</code></pre>
</details>

<img src="first-triangle.png" />

<p id="note">Add something about: <b>glutSpecialFunc(keyboard2)</b> and <b>vod keyboard2(int key, int x, int y) {}</b> and dive deeper into an example of <b>glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA | GLUT_DEPTH)</b>. 
Give an example of a complete game written using all FreeGLUT functions and detail <b>glutGetModifiers();</b>. 
Also detail <b>glutMotionFunc(myMouseMotion)</b> and <b>void myMouseMotion(int x, int y) {}</b> to handle mouse motion. FreeGLUT will only call this function after a mouse button is pressed and the mouse is moved.
To detect when a mouse cursor is hovering over an object without being clicked  FreeGLUT has <b>glutPassiveMotionFunc(myMousePassive);</b> and <b>void myMousePassive(int x, int y) {}</b>. <b>Note:</b> All this functions uses the top-left 
corner of the window for { 0, 0 } !
Detail more about <b>glutIdleFunc(myIdle);</b> and <b>void myIdle() {}</b>.
Then there is core functions like: <b>glutInitContextFlags(GLUT_CORE_PROFILE);</b>, <b>glutInitContextVersion(4, 3);</b>, <b>glutInitContextProfile(GLUT_FORWARD_COMPATIBILE);</b> and compatibility functions like: <b>glutInitContextFlags(GLUT_COMPATIBILITY_PROFILE | GLUT_CORE_PROFILE | GLUT_DEBUG);</b>. 
<b>NOTE:</b> Setting a modern OpenGL version requires <b>GLEW</b>!
There is also <b>glutGet(GLUT_ELAPSED_TIME);</b> to find elapsed time since last call to glutGet(). Even further there is <b>glutPostRedisplay()</b> which can be called in the idle-function to redisplay the current frame.</p>



<h1><a name="winapi-pt1">LESSON 3: Windows API SDK pt. 1</a></h1>
<h2>Introduction</h2>
<p>...</p>
<p>WinMain is the (C programming) main entrance, where WINAPI is the namespace for the Windows API.</p>
<p>You have two types of programmers, commandline and Windows OS targeted GUI application developers.</p>
<p>Linux uses <b>camelCase</b>, but Windows follows <b>hungerian notation</b>.</p>

<h2>Instancing a Windows class</h2>
<p>In order to create an instance of a Windows application using the Windows API you have to include <b>windows.h</b>, which comes bundled with Windows.</p>

<pre><code>
#include &lt;windows.h&gt;

LRESULT CALLBACK WndProc (HWND, UINT, WPARAM, LPARAM);

int WINAPI WinMain (HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow) {
	// Declaration for a WIN32 SDK app (first step)
	WNDCLASSEX wndclass;
	HWND hwnd; 
	MSG msg;
	TCHAR szAppName[] = TEXT( "Win32-API-SDK" );
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;		// Registering to the callback (handles all events)
	wndclass.hInstance = hInstance;		// Registering the instance for this window

	// Register the class to the OS (second step)	
	RegisterClassEx(&wndclass);
	// WND_CLASS = RegisterClass, WND_CLASSEX = RegisterClassEx, also for extra win options

	hwnd = CreateWindow (
		szAppName,			// Giving the CreateWindow-function your instance classname
		TEXT("Win32-API-SDK"),		// Caption of the window (titlebar)
		WS_OVERLAPPEDWINDOW,		// Contains 6 styles - WS_CAPTION, WS_OVERLAPPED, WS_SYSMENU (icon left corner), WS_THICKFRAME, WS_MINIMIZEDBOX, WS_MAXIMIZEDBOX
		CW_USEDEFAULT,			// Starting X of the window
		CW_USEDEFAULT,			// Starting Y
		CW_USEDEFAULT,			// Starting width
		CW_USEDEFAULT,			// Starting height
		NULL,				// Do you have a partent window, NULL = OS IS PARENT
		NULL,				// Any menus; NULL = NO
		hInstance,			// Current instance of the app
		NULL				// Used in API hooking, but not much used today
	);
	
	// Event loop goes here

	return 0;
}

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM)
{

}
</code></pre>

<h2>The parameter list in WinMain function</h2>
<p>HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow</p>
<p>HINSTANCE hInstance is the an unique id given by the OS to keep track of running status of each instance which the OS keeps track of. </p>
<p>HINTANCE hPrevInstance is (co-operative multitask, realtime multitask) is kept for backwards compatabilites. Not used because we have a lots of computerpower.</p>
<p>LPSTR lpCmdLine cmdline args (used later...)</p>
<p>int iCmdShow ()</p>

<h2>The Window class</h2>
<p>WNDCLASSEX wndclass; to create an instance of the application.</p>
<p>HWND hwnd is the unique handle to the window application, and child apps have their separate handle.</p>
<p>MSG msg; get back to this</p>
<p>TCHAR szAppName[] = TEXT( "Win32-API-SDK" ); </p>
<p>wndclass.cbSize = sizeof(WNDCLASSEX); declaring the structure mem size.</p>
<p>wndclass.style = CS_HREDRAW | CS_VREDRAW; - horizontal and vertical redraw. </p>
<p>wndclass.cbClsExtra = 0; Extra info about the class, can be used to make circuler windows</p>
<p>wndclass.cbWndExtra = 0; Extra info about the window</p>
<p>wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION); win32 api, first param: handle to window (parent window of the app, 0 = OS is parent), second param: IDI_APPLICATION is default app icon.</p> 
<p>wndclass.hCursor = LoadCursor(NULL, IDC_ARROW); win32 api call, first is parent, 0 = OS, IDC_ARROW is default built in.</p>
<p>wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH) sets the app background color, GetStockObject returns HBRUSH</p>
<p>wndclass.lpszClassName = szAppName; binding the app name to the app</p>
<p>wndclass.lpszMenuName = NULL; Do you need filemenu and more.</p>
<p>wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION) the icon you see on the taskbar</p>
<p>wndclass.lpfnWndProc = WndProc;						// Registering to the callback (handles all events)</p>
<p>wndclass.hInstance = hInstance;						// Registering the instance for this window</p>
<p>Register the class to the OS (Second step)</p>
<h2>RegisterClassEx(&wndclass);</h2>
<p>// WND_CLASS = RegisterClass, WND_CLASSEX = RegisterClassEx, also for extra win options</p>

<h2>CreateWindow function</h2>
<p>Physical memory address - ALL available memory. OS occupies the start eg. 0 - 440.</p>
<p>Virtual memory address - your programs memory, physically begins from 440, but is mapped to virtual 0-60</p>
<p>CreateWindowA - A = ANSI, CreateWindow - Unicode.</p> 
<p>The paramter list in the CreateWindow takes the following variables (re-write this to explain what the params are!) (and add that: All present parameters in CreateWindow are the same as those found in CREATESTRUCT)</p>
<pre><code>
	szAppName,			// Giving the CreateWindow-function your instance classname
	TEXT("Win32-API-SDK"),		// Caption of the window (titlebar)
	WS_OVERLAPPEDWINDOW,		// Contains 6 styles - WS_CAPTION, WS_OVERLAPPED, WS_SYSMENU (icon left corner), WS_THICKFRAME, WS_MINIMIZEDBOX, WS_MAXIMIZEDBOX
	CW_USEDEFAULT,			// Starting X of the window
	CW_USEDEFAULT,			// Starting Y
	CW_USEDEFAULT,			// Starting width
	CW_USEDEFAULT,			// Starting height
	NULL,				// Do you have a partent window, NULL = OS IS PARENT
	NULL,				// Any menus; NULL = NO
	hInstance,			// Current instance of the app
	NULL				// Used in API hooking, but not much used
</code></pre>

<h3>Example</h3>
<p>This is where you point your application handle to the Window class...</p>
<pre></code>
hwnd = CreateWindow (
	szAppName,			// Giving the CreateWindow function your instance classname
	TEXT("Win32-API-SDK"),		// Titlebar window caption
	WS_OVERLAPPEDWINDOW,		// Contains 6 styles - WS_CAPTION, WS_OVERLAPPED, WS_SYSMENU (icon left corner), WS_THICKFRAME, WS_MINIMIZEDBOX, WS_MAXIMIZEDBOX
	CW_USEDEFAULT,			// Starting X of the window
	CW_USEDEFAULT,			// Starting Y
	CW_USEDEFAULT,			// Starting width
	CW_USEDEFAULT,			// Starting height
	NULL,				// Do you have a partent window, NULL = OS IS PARENT
	NULL,				// Any menus? NULL = No
	hInstance,			// Current instance of the app
	NULL				// Used in API hooking, but not much used
);
</code></pre>




<h1><a name="winapi-pt2">LESSON 4: Windows API SDK pt. 2</a></h1>
<h3>ShowWindow</h3>
<p>After you have defined the class' instance it's time to tell your application to show the application on screen.</p>
<pre><code>
ShowWindow(
	hwnd,				// Send your handle to the ShowWindow
	SW_NORMAL			// Show Window Normally (see MSDN documentation for further options)
);
</code></pre>

<h3>UpdateWindow</h3>
<p>You then tell your OS to handle all events in your applications handle as events in the form of messages.</p>
<pre><code>
UpdateWindow(
	hwnd				// Give the handle for the window to the OS
);
</code></pre>

<h3>The event loop</h3>
<p>Then you make an event poll to handle you applications user actions. Think of this event loop as 
the heart of the application, running in an infinite loop while waiting for the users actions, like keyboard input, mousebutton clicks and movement, 
program focus (minimization / maximization).</p>

<p>WRITE MORE ABOUT THE TranslateMessage and DispatchMessage...</p>

<pre><code>
// Running the program in an infinite loop (the heart of the application). 
// Awaits system messages - software or hardware, and directs it to the callback.
// GetMessage is an API which waits for any message (hardware, keyboard, etc)
// &msg is a structure containing the information about the event (that has occured)
// NULL is receive the messages from all child window process' as well (if you want to use this you have to specify it)
// 0 = message window (start message filter, if larger than 0 it will filter out the first once) eg you type a - b - c, 2 reads from b
// 0 = as above, end message filter
while (GetMessage(&msg, NULL, 0, 0)) {
	TranslateMessage(&msg);		// Translates your msg into it's ASCII key (eg. A = 65) 65V is sent, machine interprets it to an A
	DispatchMessage(&msg);		// Dispatches the message to the callback function
}

return ((int)msg.wParam);
</code></pre>

<h3>Defining the callback function</h3>
<p>In order for your application to handle events the function GetMessage sends all software and hardware messages to a WinProc...</p>
<p>WRITE MORE ABOUT HWND, UINT, WPARAM, LPARAM...</p>
<pre><code>
LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg) 
	{
		case WM_KEYDOWN:
			switch (wParam) 
			{
				case VK_SPACE:
					// First TEXT option is caption of message box, second is the the message, MB_OK = what message box. 
					MessageBox(hwnd, TEXT("My message"), TEXT("My message"), MB_OK);
					break;
			}
			break;
	}
	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}
</code></pre>

<p>If you compile and run your application you should see a window with your custom caption, a black background and not much else, like in the image below.</p>

<img src="win32-api-app.png" />

<p>And just like in the previous example using GLUT, you can remove the console window by going into <b>Project &gt; &lt;%YOUR_PROJECT_NAME%&gt; Properties</b> under 
<b>Linker &gt; System &gt; SubSystem</b> and setting <b>Windows (/SUBSYSTEM:WINDOWS)</b>.</p>

<h3>Configuring Visual Studio Community</h3>
<p>If you want to compile your project into a spesific folder you can customize your Build Options under <b>&lt;%YOU_PROJECT_NAME%&gt; Properties &gt; General &gt Output Directory</b>. 
The default setting is <b>$(SolutionDir)$(Platform)\$(Configuration)\</b>, but you can change it to something like <b>$(SolutionDir)\bin\$(ProjectName)</b></p>
<p>See the <a href="https://docs.microsoft.com/en-us/cpp/build/reference/common-macros-for-build-commands-and-properties?view=msvc-160">MSDN documentation</a>
on MSBuild Macros for more details.</p>

<h3>Other notes</h3>
<p>Remember to add tests if the HWND and other functions was created correctly. Eg. if(!CreateWindow() {...}</p>
<p>Append some notes on <b>#pragma comment(lib, "opengl32.lib");</b> and <b>#define _WINNT_WIN32 0x500</b> + <b>#define WIN32_MEAN_AND_LEAN</b>.</p>




<h1><a name="winapi-pt3">LESSON 5: Windows SDK API pt. 3 - WM_PAINT in WndProc</a></h1>
<h2>Introduction</h2>
<p>There are two types of rendering - online and offline rendering. Games playing online is rendering on the fly, called <b>Immidiate Mode Rendering</b>.</p>

<p>There is also offline rendering, like pre-rendered assets such as WMV files used in cutscenes. This type of rendering is known as offline rendering.</p>

<h3>Immidiate Mode Rendering</h3>

<p>Immidiate Mode Rendering uses OS spesific type for rendering, so the implementation of it is up to the OS developers and manufactorers of graphics card drivers.</p>

<p>The example below displays text in immidiate mode in a Windows application.</p>

<p>Note that this code goes in the <b>WndProc</b> function, at the top, before the switch-statement.</p>
<pre><code>
TCHAR str[255] = L"Hello, World!";					// L"" stands for long char
HDC hdc;								// Handle to the device context
RECT rc;								// Handle to the client area
</code></pre>

<p>This code goes inside the switch-statement</p>
<pre><code>
// This is only called by the OS
// UpdateWindow is the first time WM_PAINT is called 
// If not defined, it calls the default call
case WM_PAINT:
		GetClientRect(hwnd, &rc);				// You are grabbing the physical client area (excluding titlebar, statusbar, etc)
									// & = passing the address of the rect to the func, paints left, top,right, bottom
									// MessageBox or anything can't be called from here (program will crash)
		hdc = GetDC(hwnd);					// DC = Device Context (This is calling the painter, there are many given by the OS)
		SetBkColor(hdc, RGB(0, 0, 0));				// This is the background color that is printed (black) (painters colorbucket)
		SetTextColor(hdc, RGB(0, 255, 0)); 			// This is the text color
		DrawText(hdc, str, -1, &rc, DT_SINGLELINE | DT_CENTER | DT_VCENTER);	// param: the context, the str, the amount of text to print (-1 is all), &rc is where to print, DS_Singleline and rest is where to print (hor, vert)
		ReleaseDC(hwnd, hdc);					// Release the painter
		break;
</code></pre>

<p>If you get a <b>LNK2019</b> error when compiling remember to change SubSystem to WINDOWS.</p>

<h3>OpenGL context</h3>
<p>OpenGL uses the simple context to paint its context</p>
<p>Add this to the WndProc</p>

<pre><code>
TCHAR str[255] = L"Hello, World!";
HDC hdc;								// Handle to device context
RECT rc;								// The handle to the client area
PAINTSTRUCT ps;								// This is a list of brushes (structs of brushes)
</code></pre>

<pre><code>
// This is only called by the OS
case WM_PAINT:
		GetClientRect(hwnd, &rc);				// You are grabbing the physical client area (excluding titlebar, statusbar, etc)
									// & = passing the address of the rect to the func, paints left, bottom, right, top
									// MessageBox or anything can't be called from here (program will crash)
		hdc = BeginPaint(hwnd, &ps);				// This is the context OpenGL uses
		SetBkColor(hdc, RGB(0, 0, 0));				// This is the background color that is printed (black) (painters colorbucket)
		SetTextColor(hdc, RGB(0, 125, 125)); 			// This is the text color
		DrawText(hdc, str, -1, &rc, DT_SINGLELINE | DT_CENTER | DT_VCENTER);	// the context, the str, the amount of text to print (-1 is all), &rc is where to print, DS_Singleline and rest is where to print (hor, vert)
		
		EndPaint(hwnd, &ps);					// This is called to destroy the OpenGL context
		
		break;
</code></pre>




<h1><a name="winapi-pt4">LESSON 6: Windows SDK API pt. 4 - WM_PAINT cont.</a></h1>
<h3>Introduction</h3>
<p>So far all our requests to do an application window repainting via WM_PAINT has been handled automatically by the OS, but what if there was a need to handle a call to WM_PAINT ourself?</p>

<p><b>Example:</b> The programmer wants to repaint the background of the application window when the user presses R, G, B etc. Each key indicates a color to be set as the new background color of the client area of the window.</p>

<p>Inside the WndProc function you declare an instance of <b>HBRUSH</b> and a <b>static int variable</b> to handle user defined messages to be sent to WM_PAINT.</p>

<pre><code>
...
HBRUSH hbrush = NULL;
static int keyPressed;
</code></pre>

<p>Below the WM_KEYDOWN case you add another case called <b>WM_CHAR</b>.</p>

<p>Inside there your task is to change the background to the given color based on the users input: G for GREEN, B for BLUE, M for MAGENTA, Y for YELLOW, K for WHITE, W for BLACK, O for ORANGE</p>

<pre><code>
...
// Alternative to WM_KEYDOWN (if you need to handle lowercase and capital chars)
case WM_CHAR:
	// This handles keyPressed
	switch (wParam)
	{
		case 'r':
			keyPressed = 1;
			break;
		case 'g':
			keyPressed = 2;
			break;
		case 'b':
			keyPressed = 3;
			break;
		case 'm':
			keyPressed = 4;
			break;
		case 'y':
			keyPressed = 5;
			break;
		case 'k':
			keyPressed = 6;
			break;
		case 'w':
			keyPressed = 7;
			break;
		case 'o':
			keyPressed = 8;
			break;
	}
	
	// InvalidateRect is a built-in function that calls WM_PAINT for you! 
	// @param: handle to window, what rectangle to print in (NULL is whole screen), erase whole background?.
	InvalidateRect(hwnd, NULL, TRUE);  
	break;
</code></pre>

<p>Your application will now handle single keyboard inputs and direct them to the <b>InvalidateRect</b> function, which in term calls the WM_PAINT for you.</p>

<p>To process the request of changing the background color you place the following switch-case inbetween the calls to <b>BeginPaint(...)</b> and <b>EndPaint(...)</b> inside WM_PAINT.</p>

<pre><code>
...
switch (keyPressed)
{
	case 1:
		hbrush = CreateSolidBrush(RGB(255, 0, 0));
		break;
	case 2: 
		hbrush = CreateSolidBrush(RGB(0, 255, 0));
		break;
	case 3: 
		hbrush = CreateSolidBrush(RGB(0, 0, 255));
		break;
	case 4:
		hbrush = CreateSolidBrush(RGB(255, 0, 255));
		break;
	case 5: 
		hbrush = CreateSolidBrush(RGB(255, 255, 0));
		break;
	case 6: 
		hbrush = CreateSolidBrush(RGB(255, 255, 255));
		break;
	case 7:
		hbrush = CreateSolidBrush(RGB(0, 0, 0));
		break;
	case 8: 
		hbrush = CreateSolidBrush(RGB(255, 165, 0));
		break;
}
FillRect(hdc, &rc, hbrush);
DeleteObject(hbrush);
...
</code></pre>

<h3>Game Loop (basics of the algorithm)</h3>
<h4>Exmaple: Witcher 3</h4>
<p>GetMessage API checks all hardware and input events.</p>
<h4>PSEUDO CODE</h4>
<pre><code>
GAME LOOP

while(1)
{
	if (ApiWhichChecksTheEvents())
	{
		if (msg == WM_QUIT)
		{
			// Quit the window
		}
		else 
		{
			TranslateMessage(...);
			DispatchMessage(...);
		}
	}
	else 
	{
		if (WindowIsActive)
		{
			RenderingFunctions();
		}
		else
		{
			// Do Nothing
		}
	}
}
</code></pre>

<p id="note"><b>NOTE:</b> If the user continuously holds 'w' to run forward there is a nanosecond pause between each input where the rendering is processed.</p>




<h1><a name="winapi-pt5">LESSON 7: Windows API SDK pt. 5 - Fullscreen Application</a></h1>
<h3>Introduction</h3>
<p>To do a fullscreen window we need to remove the WS_OVERLAPPEDWINDOW state to allow the application to cover the entire client area without the application statusbar.</p> 

<p>Before we enter fullscreen we also need to store the windows current position and state, so it can be passed back to the application if it's reset back to window mode.</p>

<p>We write our function to handle the toggeling between window  modes by either declaring a function prototype at the top, or write the function before our <b>main</b>.</p>

<pre><code>
void toggle_fullscreen(void);
</code></pre>

<p>We also have to declare variables that stores the data passed to the window on state change, so we declare the following variables in the global namespace:</p>

<pre><code>
HWND gHwnd;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsFullscreen = false;
</code></pre>

<p>Instanciate the global window handle (gHwnd) inside the <b>main</b> below <b>CreateWindow</b> as:</p>

<pre><code>
gHwnd = hwnd;
</code></pre>

<p>Then we implement the <b>toggle_fullscreen</b> function:</p>

<pre><code>
void toggle_fullscreen(void)
{
	MONITORINFO mi;
	
	if (bIsFullscreen == false) {
		mi.cbSize = { sizeof(MONITORINFO) };
		dwStyle = GetWindowLong(gHwnd, GWL_STYLE); // GetWindowLong retrieves the style (or other info) of the specified window

		// If dwStyle (bitwise) and WS_OVERLAPPEDWINDOW is true... (both contains WS_OVERLAPPEDWINDOW)
		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			// Retrieves the show state and the restored, minimized, and maximized positions of the specified window
			bIsWindowPlacement = GetWindowPlacement(gHwnd, &wpPrev);	// GetWindowPlacement retreives the position of current active window
			hMonitor = MonitorFromWindow(gHwnd, MONITORINFOF_PRIMARY);	// Tell the OS to give the handle to the (primary) monitor the graphicscard is connected to
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);	

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				// This function changes an attribute of the specified window
				SetWindowLong(gHwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);	// Remove the WS_OVERLAPPEDWINDOW state
				SetWindowPos(gHwnd, HWND_TOP,						// Assign the monitor coords to the SetWindowPos
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		// Returns the previous version of the window
		SetWindowLong(gHwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(gHwnd, &wpPrev);
		SetWindowPos(gHwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>

<p>Lastly we handle switching between fullscreen mode in the <b>WM_KEYDOWN</b> inside our <b>WinProc</b>:</p>

<pre><code>
...
case 'f':
case 'F':
	toggle_fullscreen();
	break;
}
...
</code></pre>

<p>This example switches modes when the user presses <b>f</b> or <b>F</b>, but in most cases this would be done when the user presses <b>alt + enter</b>.</p>

<pre><code>
case WM_SYSKEYDOWN:
	// Toggle between fullscreen and window mode
	if (HIWORD(lParam) && KF_ALTDOWN) {
		if (LOWORD(wParam) == VK_RETURN) {
			toggle_fullscreen();
		}
	}
</code></pre>

<p id="note"><b>NOTE:</b> The above code gives a <i>Windows Default Sound</i> when switching in and out of fullscreen using the key command <b>alt+enter</b>, so as an exercise try to implement the resizing in <b>WM_SYSCHAR</b>, or use an <b>Keyboard Accelerator</b>.</p>
<p>Keyboard Accelerator sends their result to <b>WM_COMMAND</b> or <b>WM_SYSCOMMAND</b>, so see if any of those fixes the bug. (Both are wrong, WM_COMMAND is for IDOK or IDD_MENUITEMS, and WM_SYSCOMMAND handles SC_SCREENSAVER and SC_MONITORPOWER)</p>
<p>The (probably) correct solution is to use <b>WM_SYSKEYDOWN</b> since that is for system keys like F10 or ALT. Test with InitCommonControlsEx and adding Bits 29 in WM_SYSKEYDOWN to see if that solves it!</p>
<p id="note">
	Mention <b>AdjustWindowRect()</b> and how this prevents correct scaling in windowed mode...
</p>



<h1><a name="init-opengl-pt1">LESSON 8: Initializing OpenGL pt. 1 - Choosing the Pixel Format</a></h1>
<h3>Introduction</h3>
<p>OpenGL consists of two states, first state is the initialization part and the second one is the updating part.</p> 

<p><b>ChoosePixelFormat()</b>, <b>SetPixelFormat()</b> are both done on the OS side and gives you a <b>Device Context (HDC)</b>.</p>

<p><b>wglCreateContext()</b>, <b>wglMakeCurrent()</b> gives the <b>Device Context (g_hdc)</b> to the GPU, which gives you the <b>Rendering Context (HGLRC)</b>. We need to include the windows library and the OpenGL library to
be able to work with <b>win32</b> and using the <b>Wiggle</b> library functions.</p>

<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;

int initialize();				// Function prototype

HWND g_hwnd;					// Global Handle
HDC g_hdc = NULL;				// Device Context
HGLRC g_hrc = NULL;				// Rendering Context
</code></pre>

<p>Remember to initialize the global handle <b>(g_hwnd)</b> to the <b>hwnd</b> inside the <b>WinMain</b> by adding:</p>

<pre><code>
g_hwnd = hwnd
</code></pre>

<p>We implement the initialization of OpenGL in the newly created <b>initialize</b> function:</p>

<pre><code>
int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;						// Decribes the pixelformat to use while rendering
	// LAYERPLANEDESCRIPTOR lpd;						// Contains the palette for- and background layers 
	int iPixelFormatIndex;							// The index given by the OS
	// int iLayerPlane;							// Initialize similar to PIXELFORMATDESCRIPTOR
	
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));			// Giving the pixelformat descriptor to the system (what pixel format you are using)
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);				// Size of the pfd structure to the PIXELFORMAT (init the structure)
	pfd.nVersion = 1;							// When you are dealing with an OS its doesn't give the newest OGL, but your graphics card driver does! 
										// This gives the basic version, then it gets replaced by the newest version (driver implementation)
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL;			// Tell the draw to the window or device surface, and that it supports using OpenGL
	pfd.iPixelType = PFD_TYPE_RGBA;						// The pixeltypes should be red, green, blue, alpha
	pfd.cColorBits = 32;							// The highest number of color bitplanes for each color buffer (8 * 4 = 32)
	pfd.cRedBits = 8;							// 8 bits red channel	(flexiblity to change the color type)
	pfd.cGreenBits = 8;							// 8 bits green	channel (if one is large the color gets higher presidents)
	pfd.cBlueBits = 8;							// 8 bits blue channel
	pfd.cAlphaBits = 8;							// 8 bits alpha channel
	// pfd.bReserved							// Specifies the number of overlay and underlay planes.
	// Bits 0 through 3 specify up to 15 overlay planes and bits 4 through 7 specify up to 15 underlay planes.
	// Layers need a call to BOOL wglRealizeLayerPalette(HDC hdc, int iLayerPlane, BOOL bRealize); before use...
	
	g_hdc = GetDC(g_hwnd);							// Gets the Device Context of the OS
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);			// Tell the OS the give pixelformat with the assigned vars (gives the index of the pixelformat)
										// It might give you the approximate of the declared vars / desired format

	if (iPixelFormatIndex == 0) {
		return -1;
	}

	// Give the PixelFormat struct data to my device context
	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {	
		return -2;
	}
	
	// iLayerPlane = wglDescribeLayerPlane(g_hdc, iPixelFormatIndex, iLayerPlane, sizeof(LAYERPLANEDESCRIPTOR), &lpd);
	// if (iLayerPlane == FALSE) {
	// 		return errno;
	// }
	// if (wglDescribeLayerPlane ( HDC hdc, int iPixelFormat, int iLayerPlane, UINT nBytes, LPLAYERPLANEDESCRIPTOR plpd ) {
	// }

	// wgl (Wiggle) operates as a brigde between the OS (CPU side) and OpenGL (GPU side)
	g_hrc = wglCreateContext(g_hdc);					// I want a rendering context like g_hdc, given to g_hrc (which happens on the GPU side using the wgl))
	if (g_hrc == NULL) {
		return -3;
	}

	// Make the current context as g_hrc (rendering context)
	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}
}
</code></pre>

<p id="note">There is also a <b>GetDCEx(hwnd, hrgn, DCX_WINDOW | DCX_INTERSECTRGN | 0x10000);</b> to further control how the device context is handles...</p>

<p>Then we implement a game loop to handle the OS messages and OpenGL rendering inside <b>WinMain</b>:</p>

<pre><code>
bool bIsRunning = true;

while (bIsRunning == true) {
	// PeekMessage doesn't wait for messages - if there is no messages it will run the else-clause.
	if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
		if (msg.message == WM_QUIT) {
			bIsRunning = false;
		}
		else {
			TranslateMessage(&msg);
			DispatchMessage(&msg);
		}
	}
	else {
		// Handle your rendering context here!
	}
}
</code></pre>




<h1><a name="init-opengl-pt2">LESSON 9: Initializing OpenGL pt. 2</a></h1>
<h3>Introduction</h3>
<p>To finish the <b>initialize()</b> function we simply add:</p> 

<pre><code>
glClearColor(0.0f, 0.0f, 1.0f, 1.0f);	// Clears the buffer with this value

return 0;
</code></pre>

<p>It's time to create a remaining functions to setup an instance of OpenGL. First declare the function prototypes globally:</p> 

<pre><code>
void resize(int, int);
void display(void);
void uninitialize(void);
</code></pre>

<p>We only add a basic implementation of each function, but this will in the end give a working application displaying a white triangle.</p> 
<p id="note"><b>NOTE:</b> only works using Nvidia, AMD needs to add a shader (Is this true for legacy OGL?)). </p> 

<p>First we add the function to resize the viewport of our application.</p>

<pre><code>
void resize(int w, int h)
{
	glViewport(0, 0, (GLsizei)w, (GLsizei)h);
}
</code></pre>

<p>Our rendering loop (here displaying legacy OpenGL) is only clearing the screen to the color variable that was set in the <b>initialize()</b> with <b>glClearColor()</b> and adding a simple triangle. Notice that we use 
<b>glFlush()</b> since this program is currently using a <b>singlebuffer</b>.</p> 

<pre><code>
void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);				// Takes the latest value from glClearColor and clear the buffers with that

	// Rendering is added here
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	glBegin(GL_TRIANGLES);
		glVertex2f(0.0f, 1.0f);
		glVertex2f(-1.0f, -1.0f);
		glVertex2f(1.0f, -1.0f);
	glEnd();

	glFlush();						// This is needed in a singlebuffer program (it flushed the buffer between each interation)
}	
</code></pre>

<p>It is also good practise to clean up the initialization once we are done (user quits the program), so there wount be any resouces tide up.</p>

<pre><code>
void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		// This code is identical to the code in toggle_fullscreen()
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}
</code></pre>

<p>Then in the <b>WinMain</b> you can remove the <b>UpdateWindow</b> and add the following code to do the OpenGL initialization. Note that the call to <b>initialize</b> has to come after initializing the global handle (<b>g_hwnd</b>).</p> 

<pre><code>
// UpdateWindow(hwnd);					// This is called by the OS automatically

g_hwnd = hwnd;
int result = initialize();
</code></pre>

<p>Then it's time to add the new functions to the <b>WinProc</b>. Remove the declarations in the <b>WinProc</b> and the code in the <b>WM_PAINT</b> and add the following code to the <b>switch(uMsg)</b>-statement:</p> 

<pre><code>
// This is only called by the OS (first when the window is created)
case WM_PAINT:	
	display();					// This is used in a singlebuffer program (This will not update the window each frame - instead place the display call in the game loops else-clause!)
	break;
case WM_SIZE:
	resize(LOWORD(lParam), HIWORD(lParam));		// This takes the care by the OS and takes the LOWORD and HIWORD values of the screensize (Rewrite this into an understandable sentence)
	break;
case WM_DESTROY:
	uninitialize();
	PostQuitMessage(0);
	break;
</code></pre>

<p>If you haven't added opengl32.lib under <b>Linker &gt; Input &gt; Additional Dependencies</b> you can add this line at the top below your <b>#include</b> declarations:</p> 

<pre><code>
#pragma comment(lib, "opengl32.lib")
</code></pre>

<p>Now compile and run your program to see a white triangle on a blue background. (Again note that this will only work on a computer with an Nvidia card!)</p>

<p>Comparing the creation of an application window to the earlier version using <b>freeglut</b> we see the similarilies in the comments in the sourcecode below.</p>

<pre><code>
glutInit(&argc, argv);				// Calls WinMain internally
glutInitDisplayMode(GLUT_SINGLE | GLUT_RGBA);	// Calls the PFD struct internally
glutInitWindowSize(800, 600);			// Calls CreateWindow internally
glutInitWindowPosition(100, 100);		// Also mapped to CreateWindow
glutCreateWindow("C-OpenGL first triangle");	// Also mapped to CreateWindow
initialize();					// Gives a call to glClear color (glClear takes this call to the framebuffer)
glutDisplayFunc(display);			// else-part of the messageloop
glutReshapeFunc(resize);			// Similar to WM_SIZE
glutKeyboardFunc(keyboard);			// Similar to WM_KEYDOWN
glutMouseFunc(mouse);				// ...
glutMainLoop();					// Handles the main game loop 
</code></pre>

<p id="note">This writeup implements a modern OpenGL context adding more to <b>HMONITOR</b> and further improving <b>#pragma</b> and <b>_DEBUG</b> flag: 
<a href="https://subscription.packtpub.com/book/business-and-other/9781800208087/1/ch01lvl1sec04/creating-the-application-class">https://subscription.packtpub.com/book/business-and-other/9781800208087/1/ch01lvl1sec04/creating-the-application-class</a>
<a href="https://subscription.packtpub.com/book/business-and-other/9781800208087/1/ch01lvl1sec07/creating-a-window">https://subscription.packtpub.com/book/business-and-other/9781800208087/1/ch01lvl1sec07/creating-a-window</a>
<a href="https://github.com/PacktPublishing/Hands-On-Game-Animation-Programming/blob/master/AllChapters/Code/WinMain.cpp">https://github.com/PacktPublishing/Hands-On-Game-Animation-Programming/blob/master/AllChapters/Code/WinMain.cpp</a>
</p>

<p>Here is the cleaned up sourcecode of a win32 application running OpenGL:</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;	
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow) 
{
	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;	
	wndclass.hInstance = hInstance;	
		
	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		CW_USEDEFAULT,
		CW_USEDEFAULT,
		CW_USEDEFAULT,
		CW_USEDEFAULT,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			// Whatever you want to render - do it here!
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_PAINT:
		display();
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;
	
	g_hdc = GetDC(g_hwnd);
	
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {	
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}
	
	glClearColor(0.0f, 0.0f, 1.0f, 1.0f);

	return 0;
}

void resize(int w, int h)
{
	glViewport(0, 0, (GLsizei)w, (GLsizei)h);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	glBegin(GL_TRIANGLES);
		glVertex2f(0.0f, 1.0f);
		glVertex2f(-1.0f, -1.0f);
		glVertex2f(1.0f, -1.0f);
	glEnd();

	glFlush();
}	

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>

<p id="note">Fra Innføring i grafikk programmering: <br/>
<b>GL_MODELVIEW</b> matrisen beskriver retning og hvor kameraet er: transformerer fra <i>object space</i> til <i>eye space</i>.<br/><br/>
<b>GL_PROJECTION</b> matrisen beskriver hvordan kameraet ser (”linsen”)
transformerer mellom <i>eye space</i> og <i>clip space</i><p>





<h1><a name="clipping-area-and-viewport">LESSON 10 - Clipping Area and Viewport</a></h1>

<h3>Introduction</h3>
<p><b>Clipping Area</b> refers to the area that can be seen (ie. captured by the camera), measured in OpenGL coordinates, and is define as { <b>-1, -1</b> }, { <b>1, 1</b> }. In OpenGL coordinates { <b>0, 0</b> } is center of the screen.</p>

<p><b>Viewport</b> refers to the display area on the window (screen), which is measured in pixels in screen coordinates (excluding the title bar).</p>

<p>A viewport is where the rendering will occure, and in that particular viewport our screenspace will be shown. If your native resolution is 1920x1080, your viewport defines the drawing size of the graphics to be displayed in the given screensize.</p>

<p>Framebuffer is a space in the VRAM where the final viewport is stored. You can create your own, even multiple, framebuffer(s) as needed.</p>

<p>Objects will distorted if the aspect ratio of the clipping area and viewport is different.</p> 

<p>OpenGL defines it's viewport using <b>glViewport(x, y, width, height)</b>, where the starting <b>x</b> and <b>y</b> - <b>{ 0, 0 }</b> - is in the lower left corner, up to <b>{ width * height }</b> in the upper right corner.</p>

<p>To define a viewport you have to declare a <b>width</b> and a <b>height</b> variable (just put in it in the global space for now)</p>

<pre><code>
int width;
int height;
</code></pre>

<p>You also have to store the <b>width</b> and <b>height</b> variables in the <b>WM_SIZE</b> so you can manipulate the viewport with it:</p>

<pre><code>
case WM_SIZE:
	...
	width = LOWORD(lParam);
	height = HIWORD(lParam);
	break;
</code></pre>

<p>This example edits the viewport to draw your triangle in certain parts of the screen. Shift what screenspace to draw the triangle from the previous lesson in by using the numpad keys (or the numbers keys).</p>

<pre></code>
* Numpad0 should draw the triangle on the entire screen (like in the previous lesson)
* Numpad1 should draw the triangle in the lower left corner, covering only 1/4 of the screen
* Numpad2 should draw the triangle in the lower right corner, covering 1/4 of the screen
* Numpad3 should draw the triangle in the upper left corner, covering 1/4 of the screen
* Numpad4 should draw the triangle in the upper right corner, covering 1/4 of the screen
* Numpad5 should draw the triangle on the right side of the screen, covering the entire right half
* Numpad6 should draw the triangle on the left side of the screen, covering the entire left half
* Numpad7 should draw the triangle on the upper side, covering the entire upper half
* Numpad8 should draw the triangle on the lower side, covering the entire lower half
* Numpad9 should draw the triangle in the center of the viewport, covering 1/4 of the screen
</code></pre>

<p>Place this code in the <b>WM_KEYDOWN</b>:</p>

<pre><code>
case WM_KEYDOWN:
	switch (wParam)
	{
	case VK_NUMPAD0:
		// Full screen
		glViewport(0, 0, (GLsizei)width, (GLsizei)height);
		break;
	case VK_NUMPAD1:
		// Lower left corner
		glViewport(0, 0, (GLsizei)width / 2, (GLsizei)height / 2);
		break;
	case VK_NUMPAD2: 
		// Lower right corner
		glViewport((GLsizei)width / 2, 0, (GLsizei)width / 2, (GLsizei)height / 2);
		break;
	case VK_NUMPAD3:
		// Upper left corner
		glViewport(0, (GLsizei)height / 2, (GLsizei)width / 2, (GLsizei)height / 2);
		break;
	case VK_NUMPAD4:
		// Upper right corner
		glViewport((GLsizei)width / 2, (GLsizei)height / 2, (GLsizei)width / 2, (GLsizei)height / 2);
		break;
	case VK_NUMPAD5:
		// Whole right side
		glViewport((GLsizei)width / 2, 0, (GLsizei)width / 2, (GLsizei)height);
		break;
	case VK_NUMPAD6:
		// Whole left side
		glViewport(0, 0, (GLsizei)width / 2, (GLsizei)height);
		break;
	case VK_NUMPAD7:
		// Whole upper half
		glViewport(0, (GLsizei)height / 2, (GLsizei)width, (GLsizei)height / 2);
		break;
	case VK_NUMPAD8:
		// Whole lower half
		glViewport(0, 0, (GLsizei)width, (GLsizei)height / 2);
		break;
	case VK_NUMPAD9:
		// Centered
		glViewport((GLsizei)width / 4, (GLsizei)height / 4, (GLsizei)width / 2, (GLsizei)height / 2);
		break;
	}
	break;
</code></pre>

<p id="note"><b>NOTE:</b> If you are adding this code to the previous example you'll get an error in the <b>WM_KEYDOWN</b> case for toggeling fullscreen because <b>VK_NUMPAD6</b> has the same ASCII symbol value as the letter <b>f</b>.</p>




<h1><a name="doublebuffer-pt1">LESSON 11 - Doublebuffering and Perspective pt. 1</a></h1>
<h3>Introduction</h3>
<p>This example will demonstrate how to center the window on startup and how to add doublebuffering to your application.</p>

<p>Up to OGL 3.0 the common way to do projected rendering was using the <b>OpenGL Utility (GLU) library</b>, setting the worldspace / modelspace with <b>gluPerspective</b> and eyespace with <b>gluLookAt</b></p>

<p id="note"><b>NOTE:</b> This has been deprecated in in the modern pipeline starting from OGL 3.0 and removed entirely from OGL 3.1.</p>

<p>Start by including the header file:</b>
<pre><code>
...
#include &lt;GL/glu.h&gt;
...
</code></pre>

<p>Now we can define the metric' of the window positioning at start up by adding these variables to your <b>WinMain</b> after <b>RegisterClassEx</b>:</p>

<pre><code>
...
// Window dimensions
int sWindowWidth = 800;
int sWindowHeight = 600;
int x = 0;
int y = 0;
int monitorHalfWidth = 0;
int monitorHalfHeight = 0;

int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
// Centering the starting point
monitorHalfWidth = monitorWidth / 2;
monitorHalfHeight = monitorHeight / 2;
// Starting point
x = monitorHalfWidth - sWindowWidth / 2;
y = monitorHalfHeight - sWindowHeight / 2;
...
</code></pre>

<p id="note"><b>NOTE:</b> Try rewriting these variables using the <b>CREATESTRUCT</b> struct found in <b>windows.h</b></p>

<p>Then replace the <b>CW_USEDEFAULT</b> calls in <b>CreateWindow</b> by:</p>

<pre><code>
...
x,
y,
sWindowWidth,
sWindowHeight,
...
</code></pre>

<p>Go to your <b>initialize</b> function and append the <b>PFD_DOUBLEBUFFER</b> command to the <b>pfd.dwFlags</b></p>

<pre><code>
...
pfd.dwFlags = <b> ... | PFD_DOUBLEBUFFER</b>
...
</code></pre>

<p>Now you don't need <b>SW_PAINT</b> in your <b>WinProc</b>, but instead the draw calls will come from <b>display()</b>, once you added it to the main rendering loops <b>else</b> condition.</p>

<p>Remember to add an initial call to <b>resize()</b> at the end of <b>initialize()</b> so the projection is draw to screen.</p>

<p>Next we modify the <b>resize()</b> to handle our new projection based rendring, so we begin by ensuring that the projection isn't divided by 0:</p>

<pre><code>
...
if (h == 0) {
	h = 1;
}
...
</code></pre>

<p>Below the call to <b>glViewport</b> set the model projection, translate the view to it's identity matrix and add the viewport using <b>gluPerspective</b>: </p>

<pre><code>
...
glMatrixMode(GL_PROJECTION);
glLoadIdentity();

gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
...
</code></pre>

<p id="note"><b>NOTE:</b> Setting the <b>gluPerspective()'</b> <b>zNear</b> could significantly improve the depth calculations.</p>

<p id="note"><b>NOTE 2:</b> When the perspective is set (eg. 0.1f, 100.0f) your z-axis' (eg. glVertex3f) needs to be bigger than the zNear-value for <b>gluPerspective</b> to draw it to the screen!</p> 


<p>When your application is doublebuffering there's no need to flush the <b>display()</b>, since the back- and front buffers will automatically swap and start rendering the next frame (offscreen), once that's ready.</p>

<p>Replace <b>glFlush()</b> with the <b>wingdi.h</b> built in function <b>SwapBuffers</b>, which takes the rendering context (<b>g_hdc</b>) as a single param.</p>

<pre><code>
SwapBuffers(g_hdc);
</code></pre>

<p>And now your windows start up position is in the middle of the screen (minus the size of the application system bar).</p>
<pre><code>
<p>The gluPrespective() transformation of view... (This needs some improvement)</p>
- Local Coordinate System &rarr; World Coordinate System &rarr; View Coordinate System
- Adds the frustum in the Clip Coordinate System, which is turned into <b>Normalized Device Coordinate</b> System as rendered on the screen in the <b>viewport</b> seen at the 2D window.</p>
</code></pre>




<h1><a name="doublebuffer-pt2">LESSON 12 - Doublebuffering and Perspective pt. 2</a></h1>
<h3>Introduction</h3>
<p>When you compile a program it goes through a <b>linker</b>, <b>compiler</b> and an <b>assembly</b> stage, then your OS can load the application from your <b>harddisk</b> into your <b>random access memory (RAM)</b> and <b>execute</b> it.</p>

<p>The OS will also load the VRAM on the GPU (sending framebuffers etc). Each vertices on the GPU is display by phosphorus getting ignited in your screen.</p>

<h3>What is a framebuffer</h3>
<p>Stored in the <b>VRAM</b> on the <b>GPU</b> and holds state of the <b>color-</b>, <b>depth-</b>, <b>stencil-</b> and <b>accumelator buffers</b>.</p>

<p>Lets add our affine body transformations into your <b>display()</b> function:</p>

<pre></code>
// Positional transformation
glTranslatef(0.0f, 0.0f, -3.0f);

// Rotation transformation
glRotatef(translationValue, 1.0f, 1.0f, 0.0f);	// When all axis' are present it's an arbitrary rotation
	
// Shear transformation
glScalef(0.2f, 0.2f, 0.2f);	 		// Scales the model in view to 0.2

// All these are in the model transformation (Translation * Rotation * Shearing)
</code></pre>

<p>This example video explains the process in details: <a href="https://www.youtube.com/watch?v=q5jOLztcvsM" target="_blank">https://www.youtube.com/watch?v=q5jOLztcvsM</a>




<h1><a name="vertice-transform-pt1">LESSON 13 - Transformation of Vertices pt. 1</a></h1>
<h3>Introduction</h3>
<p>Once your program is conpiled succesfully it's located on your harddrive, and when you run it it gets loaded into the RAM.</p>

<p>Once it's in the RAM it needs to call some graphics device (GPU). Your OS will call the device driver (controlling the GPU), which allocate the GPUs VRAM.</p>

<p>The VRAM then maps the rendering content to the screen.</p>

<h3>Fixed Functional Pipeline</h3>
<p>You pass the vertex data (as vertices) and your color data into the fixed functional pipeline.</p>

<p>The fixed functional pipeline doesn't give you any control over the pipeline, you only send your data to the fixed functional pipeline. A programmable pipeline contains "holes" for VS, TS, GS and FS, which can be customized by the user. </p>

<p><b>Projection</b> is used to set up the viewport and clipping boundry, while <b>modelview</b> is used to rotate, translate and scale objects quickly.</p>

<p>The vertices inside <b>glBegin()</b> and <b>glEnd()</b> is considered (interpreted as) an array (in local space). Using the <b>glTranslatef()</b> your displayed object is multiplied by the transformation matrix, given that <b>glMatrixMode(GL_MODELVIEW)</b> is set.</p>

<p>The order of inputs matters: <b>translate</b>, <b>rotate</b> then <b>scale</b>.</p>

<p>When you call GL_MODELVIEW your put the cursor in the center in the local space.</p>

<h3>Details</h3>
<p>Position gets multiplied by the transform matrix, and we call this <b>World Space Coordinates</b>.</p>

<p><b>World Space Coordinates</b> gets multiplied by the <b>ViewMatrix</b> and we call this the <b>Eye Space Coordinates</b>.</p>


<p id="note"><b>Golden rule in OpenGL:</b> If you don't implement any camera OGL assignes the camera at <b>{ 0, 0, 0 }</b>.</p>

<h3>Why Matrices</h3>
<p>Matrices are the easiest way to represent three dimensional values.</p>

<p>Your <b>Eye Coordinates</b> gets multiplied by your perspective / orthographics view and we call this the <b>Clip Coordinates</b>.</p>

<pre><code>
Local Coordinates &rarr; World Coordinates &rarr; Eye Space Coordinates &rarr; Clip Coordinates
</code></pre>




<h1><a name="vertice-transform-pt2">LESSON 14 - Transformation of Vertices pt. 2</a></h1>
<h3>Introduction</h3>

<p>Here is a recap of how the <b>Fixed Functional Pipeline</b> works in each stage:</p>

<pre><code>
1. <b>Vertex Specification Stage</b>
	a) Vertex Data &rarr; Vertices
		a) Transformation &rarr; MODEL_TRANSFORMATION
			There are three types of transformation in OpenGL 
				1) Position Transformation
				2) Rotation Transformation
				3) Sheer Transformation
			Everything in OpenGL is in the form of Matrix. 
			
			a) Local Coordinates gets converted to World Space Coordinates
				&rarr; Vertices gets multiplied by the transformation functions (glTranslatef, glRotatef, glScalef)
			
		VIEW TRANSFORMATION 
		&rarr; Camera Matrix
		
		(MODEL - VIEW DUALITY) &rarr; Model * View Matrix
		
		Now ModelView Matrix (Eye Space) gets multiplied by the projection Matrix and we call it Clip Space
		
	b) Primitive Assembly &rarr; What gemometry gets rendered?
		(GL_TRIANGLES)
		
	c) Clipping
		Viewport clipping

	d) Perspective Divide &rarr; Here all the vertices are divided by the w component (we are converting from homogenous to cartesian)
		NDC coordinates which are mapped to the screen

	e) Viewport Transform &rarr; All your things get rendered into that viewport
		All the things gets rendered into the viewport

	f) Face Culling
		You are rendering triangles (not showing the backface)
		
2. <b>Pixel Specification Stage</b>
	a) Pixel Data &rarr; color, Textures, Light, Images
	
		Per Pixel operations and unpacking
	
		Texture Assembly &rarr; On which geomery should I render the image?
	
3. <b>Rasterization</b> &rarr; Creates the potential Pixel
	
4. <b>Per Fragment Tests</b>
	a) Pixel Ownership &rarr; Done by OpenGL automatically
	b) Scissor Test &rarr; Done by OpenGL automatically
	c) Alpha Test &rarr; Done by you (You have to enable it)
	d) Depth Test &rarr; Done by you (You have to enable it)
	e) Stencil Test &rarr; Done by you (You have to enable it)
	f) Blending &rarr; Done by OpenGL and you both
	g) Dithering &rarr; Done by OpenGL
	h) Logic Operation &rarr; Done by OpenGL
</code></pre>

<pre><code>	
1. Pre-processing of vertices (raw vertices)
2, Processing of vertices
    1. Transformation
	    The vertices are in the local space
		Here the transform to Local Space &rarr; World Space (Model Transform)
		If you add any camera or by defailt gives you the camera in the center
		World Space Coordinates gets mulitplied to the view Matrix this is known as Eye Space
		Eye Space is transformed to Clip Space.
3. Post processing
	Primitive Assembly (GL_TRIANGLES)
	Clipping &rarr; Viewport clipping
	Perspective Divide &rarr; NDC Coordinates which are mapped to the screen
	Viewport Transform &rarr; All the things get rendered into that viewport.
	Face Culling &rarr; (You are rendering a triangle (not showing the back), this called face culling)
</code></pre>

<h3>Cartesian Coordinate System</h3>
<p>
[2, 7] &rarr; Cartesian Coordinate System
[2, 7, 0] &rarr; Homogenous

Conversion  from homogenious to Cartesian is such as 
2/0, 7/0 &rarr; this represents inifinity.
2/1, 7/1 &rarr; 
</p>





<h1><a name="vertice-transform-pt3">LESSON 15 - Tranformation of Vertices pt. 3</a></h1>
<p>Vertex &rarr; (World Space) Multiplied by Tranformation, Rotate and Scale (order matters!) &rarr; Multiplied by camera coordinates (Eye coordinates) &rarr; Eye space gets multiplied by 
(Clipping plane) &rarr; Primitive Assembly &rarr; Clipping (different from Culling). Viewport clipping happens first (removes (culled!) all vertices outside of the viewport). Perspective divide 
(w-component of clipspace by NDC(Normalized Device Coordinates).). Then face culling happens (FACE_CULLING). Frustrum culling. Raterization will convert the geometry 
to potiential pixel (maps your 3D space into 2D), but we have almost no control over it.</p>

<p>View tests are performed (pixelownership tests, scissor tests (what lies inside the screenview), transformation test, alpha tests, depth tests, stencil tests (shadows and more), blending test, dithering test and 
logical test) and each pixel that passes those tests are rendered to the framebuffer.</p>

<p>After that it's render to the framebuffer</p>

<p>Fra NITH mappa Innføring i grafikk programmering: Vertexes are defined in <i>object space</i>. A coordinate system for all objects is in <i>world space</i>. Camera coodinates is called <i>eye space</i>.</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL |	PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	glTranslatef(0.0f, 0.0f, -3.0f);
	glRotatef(-75.0f, 1.0f, 0.0f, 0.0f);
	
	glLineWidth(1.0f);

	// Horizontal bars
	float x1 = -2.0f;
	float y1 = 2.0f;
	
	glBegin(GL_LINES);
		glColor3f(0.48f, 1.0f, 0.48f);
		for (float i = -2.0f; i < 2.1f; i = i + 0.2f) {
			glVertex2f(x1, i);
			glVertex2f(y1, i);
		}
	glEnd();

	// Vertical bars
	float x2 = 2.0f;
	float y2 = 2.0f;
	
	glBegin(GL_LINES);
		glColor3f(0.48f, 1.0f, 0.48f);
		for (float j = -2.0f; j < 2.1f; j = j + 0.2f) {
			glVertex2f(j, x1);
			glVertex2f(j, y2);
		}
	glEnd();

	glLineWidth(1.5f);

	// Horizontally centered line
	glBegin(GL_LINES);
		glColor3f(0.0f, 1.0f, 0.0f);
		glVertex2f(-2.0f, 0.0f);
		glVertex2f(2.0f, 0.0f);
	glEnd();

	// Vertically centered line
	glBegin(GL_LINES);
		glColor3f(0.0f, 1.0f, 0.0f);
		glVertex2f(0.0f, -2.0);
		glVertex2f(0.0f, 2.0f);
	glEnd();
	
	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>

<p id="note">
	The Transformation Pipeline<br/>
	<b>Object Space:</b> Initial transformation is called Object Space and hosts the objects local transformation.<br/>
	<b>World Space:</b> To transform the object into the position relative to your world's origin it transforms the vertices using the model transform.<br/>
	<b>Eye Space:</b> Multiplied by the view transform we get into the Eye Space.<br/>
	<b>Clip Space:</b> Once the objects are culled acording to being visible on screen gives us the Clip Space.<br/>
	<b>Normalized Device Coordinates:</b> Multiply the Clip Space by perspective division you get the NDC.<br/>
	<b>Window Space</b>: This step takes the vertices and performs the rasterization to project the objects that are visible onto the screen.<br/>
	<a href="https://openglbook.com/chapter-4-entering-the-third-dimension.html" target="_blank">https://openglbook.com/chapter-4-entering-the-third-dimension.html</a>
</p>

<p id="note">
Direct State Access for OpenGL 2.1: <a href="https://registry.khronos.org/OpenGL/extensions/EXT/EXT_direct_state_access.txt">https://registry.khronos.org/OpenGL/extensions/EXT/EXT_direct_state_access.txt</a>
</p>


<h1><a name="identity-matrix">LESSON 16 - glLoadIdentity</a></h1>
<h3>Introduction</h3>
<p><b>glLoadIdentity()</b> resets the coordinate system to the center which can make for independent movement of objects.</p>

<pre><code>
1.0f, 0.0f, 0.0f,
0.0f, 1.0f, 0.0f,
0.0f, 0.0f, 1.0f
</code></pre>

<p>In OpenGL there is two object (camera and objects). <b>glMatrixMode(GL_PERSPECTIVE)</b> handles matrices used by perspective- or orthogonal transformation. <b>glMatrixMode(GL_MODELVIEW)</b> handles the matrices 
used by model-view to transform your objects to view coordiante space (or camera space).</p>



<h1><a name="glulookat">LESSON 17 - gluLookAt</a></h1>
<h3>Introduction</h3>
<p>In order to set up a camera you have to initialize OpenGL depth testing and set up the <b>glDepthFunc()</b> and tell it how you want objects to be culled.</p>

<p><b>glEnable(GL_DEPTH_TEST)</b> enables depth testing to determine which object is closest to the screen.</p>

<p><b>glDepthFunc(GL_LEQUAL)</b> tells OGL to perform depth testing to find which object to draw (based on object culling) by finding which is closer to the screen.</p>

<p id="note">When using <b>gluLookAt()</b> the camera will displace and reposition to the view origin if the position exceeds the eye coordinates, eg. if the viewer goes beyond the set z-axis making it look like the camera is flipping in the z-direction.</p>

<p>Image an camera positioned like in the example below. If the user traverse to beyond EyeZ -5.0f, the camera flips around and will focus in the opposite direction.</p>

<pre><code>
gluLookAt(
	0.0f, 0.0f, 0.0f, 	// Camera position
	0.0f, 0.0f, -5.0f,	// Camera view position (focal point)
	0.0f, 1.0f, 0.0f 	// Camera up-vector
);
</code></pre>

<p id="note"><b>gluLookAt()</b> goes in the <b>display()</b> function</p>

<h3>Drawing a grid</h3>
<p>Here is an example of drawing a grid:</p>

<pre><code>
glLineWidth(1.0f);

// Horizontal bars
float x1 = -2.0f;
float y1 = 2.0f;

glBegin(GL_LINES);
glColor3f(0.48f, 1.0f, 0.48f);
for (float i = -2.0f; i < 2.1f; i = i + 0.2f) {
	glVertex2f(x1, i);
	glVertex2f(y1, i);
}
glEnd();

// Vertical bars
float x2 = 2.0f;
float y2 = 2.0f;

glBegin(GL_LINES);
glColor3f(0.48f, 1.0f, 0.48f);
for (float j = -2.0f; j < 2.1f; j = j + 0.2f) {
	glVertex2f(j, x1);
	glVertex2f(j, y2);
}
glEnd();

glLineWidth(1.5f);

// Horizontally centered line
glBegin(GL_LINES);
	glColor3f(0.0f, 1.0f, 0.0f);
	glVertex2f(-2.0f, 0.0f);
	glVertex2f(2.0f, 0.0f);
glEnd();

// Vertically centered line
glBegin(GL_LINES);
	glColor3f(0.0f, 1.0f, 0.0f);
	glVertex2f(0.0f, -2.0);
	glVertex2f(0.0f, 2.0f);
glEnd();
</code></pre>

<p id="note">TODO: Drawing a grid needs further explanation and detailing how to draw it as an object filled with color / texture.</p>



<h1><a name="drawing-advance-geo-pt1">LESSON 18 - Drawing advanced geometry pt. 1</a></h1>
<h3>Introduction</h3>
<p>x = r sin &theta;</p>
<p>y = r cos &theta;</p>

<p>This calculates y</p>
<p>sin &theta; = y / r</p>

<p>This calculates x</p>
<p>y = r sin &theta;</p>
<p>cos &theta; = x / r</p>


<pre><code>
#include &lt;math.h&gt;
...

GLfloat r = 0.26f;	// Radius
GLfloat theta = 0.0f; 	// Angle

glBegin(GL_POINTS);
	for (float i = 0.0f; i < 360.0f; i = i + 0.02f) {
		glVertex2f(r * cos(i), r * sin(i));
	}
glEnd();
</code></pre>

<h3>Drawing an incircle</h3>
<p>This is also known as an inscribed circle. The formula to calculate the incircle (so it touches the triangle sides) is: ...</p>

<h3>Distance formula</h3>
<p>diameter = srt((x2-x1)^2 + (y2-y1)^2)</p>
<p>Incircle (in Hindi): <a href="https://www.youtube.com/watch?v=s4QeKQUgh0A" target="_blank">https://www.youtube.com/watch?v=s4QeKQUgh0A</a></p>
<p><a href="https://mathworld.wolfram.com/Incircle.html" target="_blank">https://mathworld.wolfram.com/Incircle.html</a></p>
<p><a href="https://www.quora.com/What-is-the-radius-of-the-incircle-of-a-triangle-with-sides-of-18-24-30-cm" target="_blank">https://www.quora.com/What-is-the-radius-of-the-incircle-of-a-triangle-with-sides-of-18-24-30-cm</a></p>
<p>Read more about polar coordiante here: <a href="https://mathinsight.org/polar_coordinates" target="_blank">https://mathinsight.org/polar_coordinates</a></p>
<p>Normal maps in Barycentric coordinates (terrain texture and destructions +++): <a href="https://www.youtube.com/watch?v=JX7xlFAJ0Ds" target="_blank">https://www.youtube.com/watch?v=JX7xlFAJ0Ds</a></li>
<p>Improve terrain generation with CDLOD: <a href="https://www.youtube.com/watch?v=AT7h8pYJRiw" target="_blank">https://www.youtube.com/watch?v=AT7h8pYJRiw</a></p>
<p>AI personalities: <a href="youtube.com/watch?v=q7E1N-fJnrA" target="_blank">youtube.com/watch?v=q7E1N-fJnrA</a></li>
<p>Read Paul's Online Notes</p>

<p id="note">This math example could be used in rigging a scene to generate destructable objects. <a href=http://fire-face.com/destruction/" target="_blank">http://fire-face.com/destruction/</a></p>




<h1><a name="drawing-advance-geo-pt2">LESSON 19 - Drawing advanced geometry pt. 2 (Drawing an incircle)</a></h1>
<h3>Introduction</h3>

<p>To calculate the incircle we need to create some functions to do the calculation and declare some variables to use. Add the following function prototype and variables in the global scope:</p>

<pre><code>
#define _USE_MATH_DEFINES 1
#include &lt;math.h&gt;
...

void circle_radius(void);
void draw_circle(void);
...

float a = 4.0f;
float b = 5.0f;
float c = 5.0f;
float semiperimeter, perimeter, area, radius, xoffset, yoffset;
...
</code></pre>

<p>Then we write the functions to calculate the incircle radius, area and ...</p>

<pre><code>
void circle_radius(void)
{
	float side1 = sqrt(a);
	float side2 = sqrt(b);
	float side3 = sqrt(c);

	perimeter = side1 + side2 + side3;
	semiperimeter = perimeter / 2.0f;
	area = sqrt(semiperimeter * (semiperimeter - side1) * (semiperimeter - side2) * (semiperimeter - side3));
	radius = area / semiperimeter;			// This gives the triangles incircle area
	xoffset = ((0.0f * side1) + (-1.0f * side2) + (1.0f * side3)) / perimeter;
	yoffset = ((1.0f * side1) + (-1.0f * side2) + (-1.0f * side3)) / perimeter;
}
</code></pre>

<pre><code>
void draw_circle(void)
{
	circle_radius();

	glLoadIdentity();
	glTranslatef(0.0f, 0.0f, -3.0f);

	glBegin(GL_LINE_LOOP);
		for (float angle = 0.0f; angle < 2.0f * M_PI; angle = angle + 0.001f) 
		{
			glVertex2f(radius * cos(angle) + xoffset, radius * sin(angle) + yoffset);
		}
	glEnd();
}
</code></pre>

<p>Then we can include the new functions in the <b>display()</b>:</p>

<pre><code>
glBegin(GL_LINES);
	// Lines draw between two points
	glVertex2f(0.0f, 1.0f);
	glVertex2f(-1.0f, -1.0f);
	
	glVertex2f(-1.0f, -1.0f);
	glVertex2f(1.0f, -1.0f);

	glVertex2f(1.0f, -1.0f);
	glVertex2f(0.0f, 1.0f);
glEnd();

draw_circle();
</code></pre>

<p><a href="https://www.calculatorsoup.com/calculators/geometry-plane/distance-two-points.php" target="_blank">https://www.calculatorsoup.com/calculators/geometry-plane/distance-two-points.php</a></p>
<p><a href="http://www.gogeometry.com/problem/p193_area_of_a_triangle_semiperimeter_inradius.htm" target="_blank">http://www.gogeometry.com/problem/p193_area_of_a_triangle_semiperimeter_inradius.htm</a></p>

<h1><a name="individual-transform">LESSON 20 - Adding individual transformations to objects</a></h1>
<h3>Introduction</h3>
<p>Add the following to the <b>display()</b> function:</p>

<pre><code>
static GLfloat tri_movement = 2.0f;
static GLfloat tri_rising = -2.0f;
static float tri_rotate = 0.0f;
static bool tri_centered = false;

glTranslatef(tri_movement, tri_rising, -3.0f);
glRotatef(tri_rotate, 0.0f, 1.0f, 0.0f);
...

if (tri_movement > 0.0f) {
	tri_movement -= 0.001f;
}
else {
	tri_centered = true;
}

if (tri_rising < 0.0f) {
	tri_rising += 0.001f;
}

if (tri_centered != true) {
	tri_rotate += 0.25f;
}
else if (tri_rotate > 360.0f) {
	tri_rotate = 0.0f;
}
...

glLoadIdentity();
static GLfloat line_movement = 2.0f;
glTranslatef(0.0f, line_movement, -3.0f);

glBegin(GL_LINES);
	glVertex2f(0.0f, 1.0f);
	glVertex2f(0.0f, -1.0f);
glEnd();

if (line_movement > 0.0f)
	line_movement -= 0.001f;
</pre></code>

<p>Then edit the <b>draw_circle()</b> to include these lines of code:</p>

<pre><code>
static GLfloat cir_movement = -2.0f;
static GLfloat cir_rising = -2.0f;
static GLfloat rotate = 0.0f;
static bool centered = false;
...

glTranslatef(cir_movement, cir_rising, -3.0f);
glRotatef(rotate, 0.0f, 1.0f, 0.0f);
...

if (cir_movement < 0.0f) {
	cir_movement += 0.001f;
}
else {
	centered = true;
}

if (cir_rising < 0.0f)
	cir_rising += 0.001f;

if (centered != true) {
	rotate += 0.25f;
}
else if (rotate > 360.0f) {
	rotate = 0.0f;
}
</pre></code>

<p>This will cause the three individual objects (trianle, line and circle) to rotate until they connect in the middle, then come to a full stop facing the camera.</p>

<p>Discussion regarding positioning objects: <a href="https://www.reddit.com/r/opengl/comments/pmrcjb/how_to_rotate_houses_properly/" target="_blank">https://www.reddit.com/r/opengl/comments/pmrcjb/how_to_rotate_houses_properly/</a><p>



<h1><a name="drawing-3d-pt1">LESSON 21 - Drawing 3D objects</a></h1>
<h3>Introduction</h3>
<p>It's time to start drawing 3D object using <b>GL_TRIANGLES</b>. </p>

<p>Here is a working example of how to draw a multicolored triangle and a square and position it to the left and the right of the screen.</p>

<pre><code>
// LESSON 21
glTranslatef(-2.0f, 0.0f, -10.0f);
static GLfloat rotation = 0.05f;
glRotatef(rotation, 1.0f, 1.0f, 0.0f);

glBegin(GL_TRIANGLES);
	// Front
	glColor3f(1.0f, 0.0f, 0.0f);		// Red 
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0, 1.0f);

	// Back
	glColor3f(0.0f, 1.0f, 0.0f);		// Green
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);
	
	// Left
	glColor3f(0.0f, 0.0f, 1.0f);		// Blue
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	
	// Right
	glColor3f(1.0f, 1.0f, 0.0f);		// Yellow
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);
glEnd();

// Bottom of the triangle
glBegin(GL_QUADS);
	// Bottom
	glColor3f(0.0f, 1.0f, 1.0f);		// Cyan
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
glEnd();

glLoadIdentity();
glTranslatef(2.0f, 0.0f, -10.0f);
static GLfloat quad_rot = 0.05f;
glRotatef(quad_rot, 1.0f, 1.0f, 0.0f);

glBegin(GL_QUADS);
	// Front
	glColor3f(1.0f, 0.0f, 0.0f);		// Red
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);
	glVertex3f(-1.0f, 1.0f, 1.0f);
	
	// Left
	glColor3f(0.0f, 1.0f, 0.0f);		// Green
	glVertex3f(1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	
	// Back
	glColor3f(0.0f, 0.0f, 1.0f);		// Blue
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);
	
	// Right
	glColor3f(1.0f, 1.0f, 0.0f);		// Yellow
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(-1.0f, 1.0f, 1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);

	// Top
	glColor3f(0.0f, 1.0f, 1.0f);		// Cyan
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);

	// Bottom
	glColor3f(1.0f, 1.0f, 1.0f);		// White
	glVertex3f(-1.0f, 1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);
glEnd();

rotation += 0.05f;
quad_rot += 0.05f;
</code></pre>




<h1><a name="texture-load-image-pt1">LESSON 22 - Loading an image file as texture</a></h1>
<h3>Introduction</h3>
<p>Lets start the process of loading in bitmap images to texturize our scenary using the built in <b>WIN32 BITMAP</b> set of functions. Start by making a function prototype for the texture loading function and declare a 
variable to store the image in:</p>

<pre><code>
bool load_texture(GLuint*, TCHAR[]);
...

GLuint texture;
</code></pre>

<h3>load_texture()</h3>
<p>Then we implement the <b>load_texture()</b> along the rest of the custom functions in our project:</p>

<pre><code>
bool load_texture(GLuint* texture, TCHAR imageResourceId[])
{
	HBITMAP bitmap = NULL;
	BITMAP bmp;
	bool bStatus = false;
	bitmap = LoadImage(GetModuleHandle(NULL), imageResourceId, IMAGE_BITMAP, 0, 0, LR_CREATEDIBSECTION);

	if (bitmap != NULL) {
		GetObject(bitmap, sizeof(BITMAP), &bmp);
		glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
		// Generate texture
		glGenTextures(1, texture);
		glBindTexture(GL_TEXTURE_2D, *texture);
		// Texture filtering
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR); 
		// Texture wrapping
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_NEAREST);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_NEAREST);
		gluBuild2DMipmaps(GL_TEXTURE_2D, 3, bmp.bmWidth, bmp.bmHeight, GL_BGR_EXT, GL_UNSIGNED_BYTE, bmp.bmBits);
		DeleteObject(bitmap);
		bStatus = true;
	}

	return bStatus;
}
</code></pre>

<p>Make sure that you add <b>#include "texture.h"</b> in your <b>main.c</b> file, and that you enable <b>GL_TEXTURE_2D</b> and to load the texture into memory by placing the following code in your <b>initialize()</b> function for simplicity:</p>

<pre><code>
glEnable(GL_TEXTURE_2D);
...

load_texture(&texture, MAKEINTRESOURCE(IDBITMAP_TEXTURE));
</code></pre>

<h3>Texture.h</h3>
<p>Then create a new file called <b>texture.h</b> (or something similar) in the <b>Header Files</b> section found in <b>Solution Explorer</b>. Right-click on Solution Explorer (on the folder called <b>Header Files</b>), 
select <b>Add &rarr; New Item...</b> and choose <b>Header File (.h)</b> in the file dialog. This is where we tell Windows what resources we intend to use, so add the following line into the newly created file:</p>

<pre><code>
#define IDBITMAP_TEXTURE 101

</code></pre>

<p id="note">You might experience error messages if you don't add whitespace after the <b>#define</b> declaration, if you get a <b>RC1004 - unexpected end of line</b> error when compiling, try adding one or more new lines 
in the <b>texture.h</b> file</p>

<h3>Adding a Resource.rc file to your setup</h3>
<p>WIN32 uses a resource system (<a href="https://docs.microsoft.com/en-us/windows/win32/menurc/about-resource-files" target="_blank">More info</a>) to identify the resources your program uses, details like ICON, 
MENU / SUBMENU, BITMAP, etc. so we also need to create a <b>resource.rc</b> (usually placed in the <b>Resource Files</b> in <b>Solution Explorer</b>).</p>

<p>Right-click on the <b>Resource Files</b> <i>folder</i> and select <b>Add</b> &rarr; <b>New File</b>. In the filedialog navigate to <b>Resource</b> under <b>Visual C++</b> on the righthand side. This time choose 
<b>Resource File (.rc)</b> and name it <b>resource.rc</b>.</p>

<p id="note">To edit the content of the .rc-file right click on it and select <b>Open With...</b> and select <b>C++ Source Code Editor</b></p>

<pre><code>
#include "texture.h"

IDBITMAP_TEXTURE BITMAP Smiley.bmp

</code></pre>

<p id="note">If you are using a filename containing spaces you need to add the filename inside "", eg. "Smiley faces.bmp"</p>

<h3>Drawing objects with texturing applied</h3>
<p>After that we draw a simple quad in the <b>display()</b> function and add the texture coordinates onto it using <b>glTexCoord2f()</b> with the correct texture coordinates (ranging from <b>0 &rarr; 1</b>, where 
{<b>0, 0</b>} is the lower, left corner of the texture).</p>

<pre><code>
glBegin(GL_QUADS);
	glTexCoord2f(1.0f, 1.0f);
	glVertex2f(1.0f, 1.0f);

	glTexCoord2f(0.0f, 1.0f);
	glVertex2f(-1.0f, 1.0f);

	glTexCoord2f(0.0f, 0.0f);
	glVertex2f(-1.0f, -1.0f);

	glTexCoord2f(1.0f, 0.0f);
	glVertex2f(1.0f, -1.0f);
glEnd();
</code></pre>

<p>When you compile the project it will now display a quad with your texture on screen.</b>

<p id="note">If you use an image found online (eg. a JPG file, even if you saved it as a BMP) you might experience problems loading the image and your texture will not display at all.<br/><br/>
 
<p>If you don't see a texture on your quad try to convert the image you are using to the correct format with the right extension (<b>.BMP</b>) using your preferred image editor and try again!</p>

<p id=note">The lower left corner of the texture is <b>{ 0, 0 }</b> in OpenGL. X direction is the U-coordinate, and Y direction is V-coordinate.</p>

<h3>Applying different textures to multiple objects</h3>

<p>If you want to load multiple textures you declare a new instance in <b>resource.h</b> pr texture and give multiple calls to <b>load_texture()</b> in the <b>initialize</b> function. Then you can assign them to each 
primitive or model using <b>glBindTexture(GL_TEXTURE_2D, name_of_texture)</b>.</p>




<h1><a name="load-audio-pt1">LESSON 23 - Detailing win32 load audio</a></h1>
<h3>Introduction</h3>
<p>Using <b>resource.rc</b> all the data you use will be embedded into the executable file.</p>

<h3>Loading audio (the Windows way)</h3>
<p><b>WM_CREATE</b> automatically calls this case when you start your program. To initialize playing audio in Windows you need to include the header <b>mmsystem.h</b>, and add the library <b>winmm.lib</b> using a pragma. 
You also need to add the files you intend to load into the header file (eg.) <b>texture.h</b> and <b>resource.rc</b></p>

<h3>texture.h</h3>
<pre><code>
#define IDSOUND 102
</code></pre>

<h3>resource.rc</h3>
<pre><code>
IDSOUND WAVE audio.wav
</code></pre>

<pre><code>
#include &lt;mmsystem.h&gt;
...

#pragma comment(lib, "winmm.lib")
</code></pre>

<p>Once you have set up the program to load audio you can add it to you <b>WinProc</b> in a <b>WM_CREATE</b> case like this:</p>

<pre><code>
case WM_CREATE:
	PlaySound(MAKEINTRESOURCE(IDSOUND), NULL, SND_NODEFAULT | SND_RESOURCE | SND_ASYNC);
	break;
</code></pre>

<p>As with BMP files the audio is embedded into the executable file (<b>Note</b>: the file size of you executable will be equally much bigger)</p>

<p id="note">More info on reading and writing WAV files in MSDN: <a href="https://docs.microsoft.com/en-us/windows/win32/medfound/tutorial--decoding-audio" target=="_blank">https://docs.microsoft.com/en-us/windows/win32/medfound/tutorial--decoding-audio</a></p>






<h1><a name="">LESSON 24 - Detailing win32 load bitmap pt. 2</a></h1>
<h3>Introduction</h3>
<p id="note">To reset the colors to use (texture is nothing but a color) the original color scheme for the texture you can set the <b>glColor3f(1.0f, 1.0f, 1.0f)</b> to white, which doesn't blend with the original texture color.</p>

<pre><code>

</code></pre>

<p></p>

<pre><code>

</code></pre>




<h1><a name="texture-quad-uv">LESSON 25 - UV coordinates of a quad</a></h1>
<h3>Introduction</h3>
<p>UV coords are always in between <b>{ 0, 1 }</b>, and will never be negative.</p>

<p>Following the clockwise direction.</p>

<pre><code>
(0, 1)	       (1, 1)
  |
  1
  |
(0, 0) -- 1 -- (1, 0)
</code></pre>



<h1><a name="procgen-pt1">LESSON 26 - Procedural generation pt. 1</a></h1>
<h3>Introduction</h3>
<p>Matrix is not a formula</p>

<h3>What is a matrix</h3>
<p>Programmers should know how Matrixes and handled internally. Matrix can have two elements, the row and column</p>

<p>The order of matrixes matter! If you multiply a translation matrix with a scale, or scale by a translation matrix will be different.</p>

<p>Matrix makes representing 3D coordinates easy.</p>
<p>Can be extended to represent n number of matrixes.</p>
<p></p>
<p></p>
<p></p>

<h3>Homogenous Coodinates</h3>
<p>Can represent inifinity. (image a railway track going into the distance)</p>
<p>Your screen is representing cartesian coords.</p>
<p></p>
<p></p>
<p></p>

<h3>OpenGL internal stacks...</h3>
<p>OpenGL follows two stacks - View Stack <- (Projection Stack) and (Transformation Stack) -> Model Stack</p>
<p>Projection stack stores the perspective, orthographic or lookAt matrix</p>
<p>The second one stores the translation, rotation and scaling.</p>
<p>OpenGL inplements it's own stack which represents both.</p>

<h3>Unit Matrix / Identity Matrix </h3>
<p></p>
<p></p>

<h3>Texture matrix<h3>
<p>Your GPU has it's own dedicated texture memory.</p>
<p></p>
<p></p>

<h3>More notes</h3>
<p>Cartesian coordiantes: [2, 3]</p>
<p>Homogenous coodinates: [2, 3, 1] = (x, y & z)</p>
<p>Cartesian has no extra dimension, homogenous has an extra dimension - either 0 or 1.</p>
<h3>Conversion to homogen to cartesian</h3>
<p><var>x / w = 2 / 1 = 2</var></p>
<p><var>y / w = 3 / 1 = 3</var></p>
<h4>If w = 0</h4>
<p><var>x = x / 0 = &rarr; infinity</var></p>
<p><var>y = y / 0 = &rarr; infinity</var></p>

<p></p>
<pre><code>
     _                 _
m11 | 3.0    1.0    1.0 |    &uarr;
m21 | 1.0    1.0    1.0	|  Column 
m31 |_1.0    1.0   -0.5_|    &darr;
           &larr; Row &rarr;
</code></pre>

<p>glTranslate(3.0f, 1.0f, -0.5f);</p>
<p>glRotate(angle, 1.0f, 0.0f, 0.0f);</p>
<p>glScale(5.0f, 5.0f, 5.0f);</p>
<p>1) Row</p>
<p>2) Column</p>
<p>m11    m21</p>
<p>RC     RC</p>
<p>[T, R, S]</p>
<p>Homogenous</p>
<p>[5.0, -60.0, 0]</p>
<p>  x     y    w</p>
<p id="note">When converting to cartesian coords divided by zero makes infinity.</p>
<p>Allowing affine transformation, rotation and scaling</p>
<p>OpenGL loads two stacks internally: Unit matrix...</p>
<pre></code>
 _	   _
| 1   0   0 |
| 0   1   0 |  &rarr; glLoadIdentity()
|_0   0   1_|
</code></pre>

<details>
	<summary>Quote from the OpenGL Superbible</summary>

	<pre><code>
	The Transformation Pipeline
	To effect the types of transformations described in this chapter, you modify two matrices
	in particular: the modelview matrix and the projection matrix. Don’t worry; OpenGL
	provides some high-level functions that you can call for these transformations. After
	you’ve mastered the basics of the OpenGL API, you will undoubtedly start trying some of
	the more advanced 3D rendering techniques. Only then will you need to call the lowerlevel functions that actually set the values contained in the matrices.
	The road from raw vertex data to screen coordinates is a long one. Figure 4.7 provides a
	flowchart of this process. First, your vertex is converted to a 1×4 matrix in which the first
	three values are the x, y, and z coordinates. The fourth number is a scaling factor that you
	can apply manually by using the vertex functions that take four values. This is the w coordinate, usually 1.0 by default. You will seldom modify this value directly.
	The Matrix: Mathematical Currency for 3D Graphics 135
	4
	1
	2
	3
	1
	2
	3
	4
	4
	5
	6
	7
	8
	9
	0
	1.5
	2
	42
	0.877
	14
	FIGURE 4.7 The vertex transformation pipeline.
	The vertex is then multiplied by the modelview matrix, which yields the transformed eye
	coordinates. The eye coordinates are then multiplied by the projection matrix to yield clip
	coordinates. OpenGL effectively eliminates all data outside this clipping space. The clip
	coordinates are then divided by the w coordinate to yield normalized device coordinates.
	The w value may have been modified by the projection matrix or the modelview matrix,
	depending on the transformations that occurred. Again, OpenGL and the high-level
	matrix functions hide this process from you.
	Finally, your coordinate triplet is mapped to a 2D plane by the viewport transformation.
	This is also represented by a matrix, but not one that you specify or modify directly.
	OpenGL sets it up internally depending on the values you specified to glViewport.
	The Modelview Matrix
	The modelview matrix is a 4×4 matrix that represents the transformed coordinate system
	you are using to place and orient your objects. The vertices you provide for your primitives are used as a single-column matrix and multiplied by the modelview matrix to yield
	new transformed coordinates in relation to the eye coordinate system.
	In Figure 4.8, a matrix containing data for a single vertex is multiplied by the modelview
	matrix to yield new eye coordinates. The vertex data is actually four elements with an
	extra value, w, that represents a scaling factor. This value is set by default to 1.0, and rarely
	will you change it yourself.
	136 CHAPTER 4 Geometric Transformations: The Pipeline
	x0
	y0
	z0
	w0
	xe
	ye
	ze
	we
	xc
	yc
	zc
	wc
	xc/wc
	yc/wc
	zc/wc
	Modelview
	matrix
	Projection
	matrix
	Viewport
	transformation
	Perspective
	division …
	…
	Original
	vertex data
	Transformed
	eye coordinates
	Window coordinates
	Clip
	coordinates
	Normalized
	device coordinates
	FIGURE 4.8 A matrix equation that applies the modelview transformation to a single vertex.
	Translation
	Let’s consider an example that modifies the modelview matrix. Say you want to draw a
	cube using the GLUT library’s glutWireCube function. You simply call
	glutWireCube(10.0f);
	A cube that measures 10 units on a side is then centered at the origin. To move the cube
	up the y-axis by 10 units before drawing it, you multiply the modelview matrix by a
	matrix that describes a translation of 10 units up the y-axis and then do your drawing. In
	skeleton form, the code looks like this:
	// Construct a translation matrix for positive 10 Y
	...
	// Multiply it by the modelview matrix
	...
	// Draw the cube
	glutWireCube(10.0f);
	Actually, such a matrix is fairly easy to construct, but it requires quite a few lines of code.
	Fortunately, OpenGL provides a high-level function that performs this task for you:
	void glTranslatef(GLfloat x, GLfloat y, GLfloat z);
	This function takes as parameters the amount to translate along the x, y, and z directions.
	It then constructs an appropriate matrix and multiplies it onto the current matrix stack.
	The pseudocode looks like the following, and the effect is illustrated in Figure 4.9:
	// Translate up the y-axis 10 units
	glTranslatef(0.0f, 10.0f, 0.0f);
	// Draw the cube
	glutWireCube(10.0f);
	The Matrix: Mathematical Currency for 3D Graphics 137
	4
	= M
	FIGURE 4.9 A cube translated 10 units in the positive y direction.
	IS TRANSLATION ALWAYS A MATRIX OPERATION?
	The studious reader may note that translations do not always require a full matrix multiplication,
	but can be simplified with a simple scalar addition to the vertex position. However, for more
	complex transformations that include combined simultaneous operations, it is correct to describe
	translation as a matrix operation. Fortunately, if you let OpenGL do the heavy lifting for you, as
	we have done here, the implementation can usually figure out the optimum method to use.
	Rotation
	To rotate an object about one of the three coordinate axes, or indeed any arbitrary vector,
	you have to devise a rotation matrix. Again, a high-level function comes to the rescue:
	glRotatef(GLfloat angle, GLfloat x, GLfloat y, GLfloat z);
	Here, we perform a rotation around the vector specified by the x, y, and z arguments. The
	angle of rotation is in the counterclockwise direction measured in degrees and specified by
	the argument angle. In the simplest of cases, the rotation is around only one of the coordinate systems cardinal axes (X, Y, or Z).
	You can also perform a rotation around an arbitrary axis by specifying x, y, and z values
	for that vector. To see the axis of rotation, you can just draw a line from the origin to the
	point represented by (x,y,z). The following code rotates the cube by 45° around an arbitrary axis specified by (1,1,1), as illustrated in Figure 4.10:
	// Perform the transformation
	glRotatef(45.0f, 1.0f, 1.0f, 1.0f);
	// Draw the cube
	glutWireCube(10.0f);
	138 CHAPTER 4 Geometric Transformations: The Pipeline
	z
	x
	y
	10
	FIGURE 4.10 A cube rotated about an arbitrary axis.
	Scaling
	A scaling transformation changes the size of your object by expanding or contracting all
	the vertices along the three axes by the factors specified. The function
	glScalef(GLfloat x, GLfloat y, GLfloat z);
	multiplies the x, y, and z values by the scaling factors specified.
	Scaling does not have to be uniform, and you can use it to both stretch and squeeze
	objects along different directions. For example, the following code produces a cube that is
	twice as large along the x- and z-axes as the cubes discussed in the previous examples, but
	still the same along the y-axis. The result is shown in Figure 4.11.
	// Perform the scaling transformation
	glScalef(2.0f, 1.0f, 2.0f);
	// Draw the cube
	glutWireCube(10.0f);
	The Matrix: Mathematical Currency for 3D Graphics 139
	4
	x
	(1,1,1)
	45
	z
	y
	z
	x
	y
	10
	10
	FIGURE 4.11 A nonuniform scaling of a cube.
	The Identity Matrix
	About now, you might be wondering why we had to bother with all this matrix stuff in
	the first place. Can’t we just call these transformation functions to move our objects
	around and be done with it? Do we really need to know that it is the modelview matrix
	that is modified?
	The answer is yes and no (but it’s no only if you are drawing a single object in your
	scene). The reason is that the effects of these functions are cumulative. Each time you call
	one, the appropriate matrix is constructed and multiplied by the current modelview
	matrix. The new matrix then becomes the current modelview matrix, which is then multiplied by the next transformation, and so on.
	Suppose you want to draw two spheres—one 10 units up the positive y-axis and one 10
	units out the positive x-axis, as shown in Figure 4.12. You might be tempted to write code
	that looks something like this:
	// Go 10 units up the y-axis
	glTranslatef(0.0f, 10.0f, 0.0f);
	// Draw the first sphere
	glutSolidSphere(1.0f,15,15);
	// Go 10 units out the x-axis
	glTranslatef(10.0f, 0.0f, 0.0f);
	// Draw the second sphere
	glutSolidSphere(1.0f);
	140 CHAPTER 4 Geometric Transformations: The Pipeline
	z
	x
	y
	10
	10
	FIGURE 4.12 Two spheres drawn on the y- and x-axes.
	Consider, however, that each call to glTranslate is cumulative on the modelview matrix,
	so the second call translates 10 units in the positive x direction from the previous translation in the y direction. This yields the results shown in Figure 4.13.
	The Matrix: Mathematical Currency for 3D Graphics 141
	4
	z
	x
	y
	10
	10
	FIGURE 4.13 The result of two consecutive translations.
	You can make an extra call to glTranslate to back down the y-axis 10 units in the negative direction, but this makes some complex scenes difficult to code and debug—not to
	mention that you throw extra transformation math at the CPU or GPU. A simpler method
	is to reset the modelview matrix to a known state—in this case, centered at the origin of
	the eye coordinate system.
	You reset the origin by loading the modelview matrix with the identity matrix. The identity
	matrix specifies that no transformation is to occur, in effect saying that all the coordinates
	you specify when drawing are in eye coordinates. An identity matrix contains all 0s, with
	the exception of a diagonal row of 1s. When this matrix is multiplied by any vertex
	matrix, the result is that the vertex matrix is unchanged. Figure 4.14 shows this equation.
	Later in the chapter, we discuss in more detail why these numbers are where they are.
	 8 . 0
	 4 . 5
	- 2 . 0
	 1 . 0
	 8 . 0
	 4 . 5
	- 2 . 0
	 1 . 0
	1.0
	0
	0
	0
	0
	1.0
	0
	0
	0
	0
	1.0
	0
	0
	0
	0
	1.0
	=
	FIGURE 4.14 Multiplying a vertex by the identity matrix yields the same vertex matrix.
	As we’ve already stated, the details of performing matrix multiplication are outside the
	scope of this book. For now, just remember this: Loading the identity matrix means that
	no transformations are performed on the vertices. In essence, you are resetting the
	modelview matrix to the origin.
	The following two lines load the identity matrix into the modelview matrix:
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	The first line specifies that the current operating matrix is the modelview matrix. After
	you set the current operating matrix (the matrix that your matrix functions are affecting),
	it remains the active matrix until you change it. The second line loads the current matrix
	(in this case, the modelview matrix) with the identity matrix.
	Now, the following code produces the results shown earlier in Figure 4.12:
	// Set current matrix to modelview and reset
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	// Go 10 units up the y-axis
	glTranslatef(0.0f, 10.0f, 0.0f);
	// Draw the first sphere
	glutSolidSphere(1.0f, 15, 15);
	// Reset modelview matrix again
	glLoadIdentity();
	// Go 10 units out the x-axis
	glTranslatef(10.0f, 0.0f, 0.0f);
	// Draw the second sphere
	glutSolidSphere(1.0f, 15, 15);
	The Matrix Stacks
	Resetting the modelview matrix to identity before placing every object is not always desirable. Often, you want to save the current transformation state and then restore it after
	some objects have been placed. This approach is most convenient when you have initially
	transformed the modelview matrix as your viewing transformation (and thus are no
	longer located at the origin).
	To facilitate this procedure, OpenGL maintains a matrix stack for both the modelview and
	projection matrices. A matrix stack works just like an ordinary program stack. You can
	push the current matrix onto the stack with glPushMatrix to save it and then make your
	changes to the current matrix. Popping the matrix off the stack with glPopMatrix then
	restores it. Figure 4.15 shows the stack principle in action.
	142 CHAPTER 4 Geometric Transformations: The Pipeline
	FIGURE 4.15 The matrix stack in action.
	TEXTURE MATRIX STACK
	The texture stack is another matrix stack available to you. You use it to transform texture coordinates. Chapter 8, “Texture Mapping: The Basics,” examines texture mapping and texture coordinates and contains a discussion of the texture matrix stack.
	The stack depth can reach a maximum value that you can retrieve with a call to either
	glGet(GL_MAX_MODELVIEW_STACK_DEPTH);
	or
	glGet(GL_MAX_PROJECTION_STACK_DEPTH);
	If you exceed the stack depth, you get a GL_STACK_OVERFLOW error; if you try to pop a
	matrix value off the stack when there is none, you generate a GL_STACK_UNDERFLOW error.
	The stack depth is implementation dependent. For the Microsoft software implementation, the values are 32 for the modelview and 2 for the projection stack.
	A Nuclear Example
	Let’s put to use what we have learned. In the next example, we build a crude, animated
	model of an atom. This atom has a single sphere at the center to represent the nucleus
	and three electrons in orbit about the atom. We use an orthographic projection, as we
	have in all the examples so far in this book.
	Our ATOM program uses the GLUT timer callback mechanism (discussed in Chapter 2,
	“Using OpenGL”) to redraw the scene about 10 times per second. Each time the
	RenderScene function is called, the angle of revolution about the nucleus is incremented.
	Also, each electron lies in a different plane. Listing 4.1 shows the RenderScene function
	for this example, and the output from the ATOM program is shown in Figure 4.16.
	The Matrix: Mathematical Currency for 3D Graphics 143
	4
	glPushMatrix glPopMatrix
	Matrix stack
	LISTING 4.1 RenderScene Function from ATOM Sample Program
	// Called to draw scene
	void RenderScene(void)
	{
	// Angle of revolution around the nucleus
	static GLfloat fElect1 = 0.0f;
	// Clear the window with current clearing color
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
	// Reset the modelview matrix
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	// Translate the whole scene out and into view
	// This is the initial viewing transformation
	glTranslatef(0.0f, 0.0f, -100.0f);
	// Red Nucleus
	glColor3ub(255, 0, 0);
	glutSolidSphere(10.0f, 15, 15);
	// Yellow Electrons
	glColor3ub(255,255,0);
	// First Electron Orbit
	// Save viewing transformation
	glPushMatrix();
	// Rotate by angle of revolution
	glRotatef(fElect1, 0.0f, 1.0f, 0.0f);
	// Translate out from origin to orbit distance
	glTranslatef(90.0f, 0.0f, 0.0f);
	// Draw the electron
	glutSolidSphere(6.0f, 15, 15);
	// Restore the viewing transformation
	glPopMatrix();
	144 CHAPTER 4 Geometric Transformations: The Pipeline
	LISTING 4.1 Continued
	// Second Electron Orbit
	glPushMatrix();
	glRotatef(45.0f, 0.0f, 0.0f, 1.0f);
	glRotatef(fElect1, 0.0f, 1.0f, 0.0f);
	glTranslatef(-70.0f, 0.0f, 0.0f);
	glutSolidSphere(6.0f, 15, 15);
	glPopMatrix();
	// Third Electron Orbit
	glPushMatrix();
	glRotatef(360.0f, -45.0f, 0.0f, 0.0f, 1.0f);
	glRotatef(fElect1, 0.0f, 1.0f, 0.0f);
	glTranslatef(0.0f, 0.0f, 60.0f);
	glutSolidSphere(6.0f, 15, 15);
	glPopMatrix();
	// Increment the angle of revolution
	fElect1 += 10.0f;
	if(fElect1 > 360.0f)
	fElect1 = 0.0f;
	// Show the image
	glutSwapBuffers();
	}
	The Matrix: Mathematical Currency for 3D Graphics 145
	4
	FIGURE 4.16 Output from the ATOM sample program.
	Let’s examine the code for placing one of the electrons, a couple of lines at a time. The first
	line saves the current modelview matrix by pushing the current transformation on the stack:
	// First Electron Orbit
	// Save viewing transformation
	glPushMatrix();
	Now the coordinate system appears to be rotated around the y-axis by an angle, fElect1:
	// Rotate by angle of revolution
	glRotatef(fElect1, 0.0f, 1.0f, 0.0f);
	The electron is drawn by translating down the newly rotated coordinate system:
	// Translate out from origin to orbit distance
	glTranslatef(90.0f, 0.0f, 0.0f);
	Then the electron is drawn (as a solid sphere), and we restore the modelview matrix by
	popping it off the matrix stack:
	// Draw the electron
	glutSolidSphere(6.0f, 15, 15);
	// Restore the viewing transformation
	glPopMatrix();
	The other electrons are placed similarly.
	Using Projections
	In our examples so far, we have used the modelview matrix to position our vantage point
	of the viewing volume and to place our objects therein. The projection matrix actually
	specifies the size and shape of our viewing volume.
	Thus far in this book, we have created a simple parallel viewing volume using the function
	glOrtho, setting the near and far, left and right, and top and bottom clipping coordinates.
	In OpenGL, when the projection matrix is loaded with the identity matrix, the diagonal
	line of 1s specifies that the clipping planes extend from the origin to +1 or –1 in all directions. The projection matrix by itself does no scaling or perspective adjustments unless
	you load a perspective projection matrix.
	The next two sample programs, ORTHO and PERSPECT, are not covered in detail from the
	standpoint of their source code. These examples use lighting and shading that we haven’t
	covered yet to help highlight the differences between an orthographic and a perspective
	projection. These interactive samples make it much easier for you to see firsthand how the
	projection can distort the appearance of an object. If possible, you should run these examples while reading the next two sections.
	146 CHAPTER 4 Geometric Transformations: The Pipeline
	Orthographic Projections
	The orthographic projection that we have used for most of this book so far is square on all
	sides. The logical width is equal at the front, back, top, bottom, left, and right sides. This
	produces a parallel projection, which is useful for drawings of specific objects that do not
	have any foreshortening when viewed from a distance. This is good for 2D graphics such
	as text, or architectural drawings for which you want to represent the exact dimensions
	and measurements onscreen.
	Figure 4.17 shows the output from the sample program ORTHO in this chapter’s subdirectory in the source distribution. To produce this hollow, tubelike box, we used an orthographic projection just as we did for all our previous examples. Figure 4.18 shows the same
	box rotated more to the side so you can see how long it actually is.
	Using Projections 147
	4
	FIGURE 4.17 A hollow square tube shown with an orthographic projection.
	FIGURE 4.18 A side view showing the length of the square tube.
	In Figure 4.19, you’re looking directly down the barrel of the tube. Because the tube does
	not converge in the distance, this is not an entirely accurate view of how such a tube
	appears in real life. To add some perspective, we must use a perspective projection.
	148 CHAPTER 4 Geometric Transformations: The Pipeline
	FIGURE 4.19 Looking down the barrel of the tube.
	Perspective Projections
	A perspective projection performs perspective division to shorten and shrink objects that
	are farther away from the viewer. The width of the back of the viewing volume does not
	have the same measurements as the front of the viewing volume after being projected to
	the screen. Thus, an object of the same logical dimensions appears larger at the front of
	the viewing volume than if it were drawn at the back of the viewing volume.
	The picture in our next example is of a geometric shape called a frustum. A frustum is a
	truncated section of a pyramid viewed from the narrow end to the broad end. Figure 4.20
	shows the frustum, with the observer in place.
	Observer
	Perspective viewing volume
	near
	0
	far
	FIGURE 4.20 A perspective projection defined by a frustum.
	You can define a frustum with the function glFrustum. Its parameters are the coordinates
	and distances between the front and back clipping planes. However, glFrustum is not as
	intuitive about setting up your projection to get the desired effects, and is typically used
	for more specialized purposes (for example, stereo, tiles, asymmetric view volumes). The
	utility function gluPerspective is easier to use and somewhat more intuitive for most
	purposes:
	void gluPerspective(GLdouble fovy, GLdouble aspect,
	GLdouble zNear, GLdouble zFar);
	Parameters for the gluPerspective function are a field-of-view angle in the vertical direction, the aspect ratio of the width to height, and the distances to the near and far clipping
	planes (see Figure 4.21). You find the aspect ratio by dividing the width (w) by the height
	(h) of the window or viewport.
	Using Projections 149
	4
	Observer
	near
	fovy
	h
	w
	far
	FIGURE 4.21 The frustum as defined by gluPerspective.
	Listing 4.2 shows how we change our orthographic projection from the previous examples
	to use a perspective projection. Foreshortening adds realism to our earlier orthographic
	projections of the square tube (see Figures 4.22, 4.23, and 4.24). The only substantial
	change we made for our typical projection code in Listing 4.2 was substituting the call to
	gluOrtho2D with gluPerspective.
	FIGURE 4.22 The square tube with a perspective projection.
	FIGURE 4.23 A side view with foreshortening.
	150 CHAPTER 4 Geometric Transformations: The Pipeline
	FIGURE 4.24 Looking down the barrel of the tube with perspective added.
	LISTING 4.2 Setting Up the Perspective Projection for the PERSPECT Sample Program
	// Change viewing volume and viewport. Called when window is resized
	void ChangeSize(GLsizei w, GLsizei h)
	{
	GLfloat fAspect;
	// Prevent a divide by zero
	if(h == 0)
	h = 1;
	// Set viewport to window dimensions
	glViewport(0, 0, w, h);
	LISTING 4.2 Continued
	fAspect = (GLfloat)w/(GLfloat)h;
	// Reset coordinate system
	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
	// Produce the perspective projection
	gluPerspective(60.0f, fAspect, 1.0, 400.0);
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	}
	We made the same changes to the ATOM example in ATOM2 to add perspective. Run the
	two side by side, and you see how the electrons appear to be smaller as they swing far
	away behind the nucleus.
	A Far-Out Example
	For a more complete example showing modelview manipulation and perspective projections, we have modeled the sun and the earth/moon system in revolution in the SOLAR
	sample program. This is a classic example of nested transformations with objects being
	transformed relative to one another using the matrix stack. We have enabled some lighting and shading for drama so that you can more easily see the effects of our operations.
	You’ll learn about shading and lighting in the next two chapters.
	In our model, the earth moves around the sun, and the moon revolves around the earth.
	A light source is placed at the center of the sun, which is drawn without lighting to make
	it appear to be the glowing light source. This powerful example shows how easily you can
	produce sophisticated effects with OpenGL.
	Listing 4.3 shows the code that sets up the projection and the rendering code that keeps
	the system in motion. A timer elsewhere in the program triggers a window redraw 10
	times a second to keep the RenderScene function in action. Notice in Figures 4.25 and
	4.26 that when the earth appears larger, it’s on the near side of the sun; on the far side, it
	appears smaller.
	LISTING 4.3 Code That Produces the Sun/Earth/Moon System
	// Change viewing volume and viewport. Called when window is resized
	void ChangeSize(GLsizei w, GLsizei h)
	{
	GLfloat fAspect;
	Using Projections 151
	4
	LISTING 4.3 Continued
	// Prevent a divide by zero
	if(h == 0)
	h = 1;
	// Set viewport to window dimensions
	glViewport(0, 0, w, h);
	// Calculate aspect ratio of the window
	fAspect = (GLfloat)w/(GLfloat)h;
	// Set the perspective coordinate system
	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
	// Field of view of 45 degrees, near and far planes 1.0 and 425
	gluPerspective(45.0f, fAspect, 1.0, 425.0);
	// Modelview matrix reset
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	}
	// Called to draw scene
	void RenderScene(void)
	{
	// Earth and moon angle of revolution
	static float fMoonRot = 0.0f;
	static float fEarthRot = 0.0f;
	// Clear the window with current clearing color
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
	// Save the matrix state and do the rotations
	glMatrixMode(GL_MODELVIEW);
	glPushMatrix();
	// Translate the whole scene out and into view
	glTranslatef(0.0f, 0.0f, -300.0f);
	// Set material color, to yellow
	// Sun
	glColor3ub(255, 255, 0);
	152 CHAPTER 4 Geometric Transformations: The Pipeline
	LISTING 4.3 Continued
	glDisable(GL_LIGHTING);
	glutSolidSphere(15.0f, 15, 15);
	glEnable(GL_LIGHTING);
	// Position the light after we draw the Sun!
	glLightfv(GL_LIGHT0,GL_POSITION,lightPos);
	// Rotate coordinate system
	glRotatef(fEarthRot, 0.0f, 1.0f, 0.0f);
	// Draw the earth
	glColor3ub(0,0,255);
	glTranslatef(105.0f,0.0f,0.0f);
	glutSolidSphere(15.0f, 15, 15);
	// Rotate from Earth-based coordinates and draw moon
	glColor3ub(200,200,200);
	glRotatef(fMoonRot,0.0f, 1.0f, 0.0f);
	glTranslatef(30.0f, 0.0f, 0.0f);
	fMoonRot+= 15.0f;
	if(fMoonRot > 360.0f)
	fMoonRot = 0.0f;
	glutSolidSphere(6.0f, 15, 15);
	// Restore the matrix state
	glPopMatrix(); // Modelview matrix
	// Step Earth orbit 5 degrees
	fEarthRot += 5.0f;
	if(fEarthRot > 360.0f)
	fEarthRot = 0.0f;
	// Show the image
	glutSwapBuffers();
	}
	Using Projections 153
	4
	FIGURE 4.25 The sun/earth/moon system with the earth on the near side.
	154 CHAPTER 4 Geometric Transformations: The Pipeline
	FIGURE 4.26 The sun/earth/moon system with the earth on the far side.
	Advanced Matrix Manipulation
	These higher-level “canned” transformations (for rotation, scaling, and translation) are
	great for many simple transformation problems. Real power and flexibility, however, are
	afforded to those who take the time to understand using matrices directly. Doing so is not
	as hard as it sounds, but first you need to understand the magic behind those 16 numbers
	that make up a 4×4 transformation matrix.
	OpenGL represents a 4×4 matrix not as a two-dimensional array of floating-point values,
	but as a single array of 16 floating-point values. This approach is different from many
	math libraries, which do take the two-dimensional array approach. For example, OpenGL
	prefers the first of these two examples:
	GLfloat matrix[16]; // Nice OpenGL friendly matrix
	GLfloat matrix[4][4]; // Popular, but not as efficient for OpenGL
	OpenGL can use the second variation, but the first is a more efficient representation. The
	reason for this will become clear in a moment. These 16 elements represent the 4×4
	matrix, as shown in Figure 4.27. When the array elements traverse down the matrix
	columns one by one, we call this column-major matrix ordering. In memory, the 4×4
	approach of the two-dimensional array (the second option in the preceding code) is laid
	out in a row-major order. In math terms, the two orientations are the transpose of one
	another.
	Advanced Matrix Manipulation 155
	4
	a0
	a1
	a2
	a3
	a4
	a5
	a6
	a7
	a8
	a9
	a10
	a11
	a12
	a13
	a14
	a15
	FIGURE 4.27 Column-major matrix ordering.
	The real magic lies in the fact that these 16 values represent a particular position in space
	and an orientation of the three axes with respect to the eye coordinate system (remember
	that fixed, unchanging coordinate system we talked about earlier). Interpreting these
	numbers is not hard at all. The four columns each represent a four-element vector. To keep
	things simple for this book, we focus our attention on just the first three elements of these
	vectors. The fourth column vector contains the x, y, and z values of the transformed coordinate system’s origin. When you call glTranslate on the identity matrix, all it does is put
	your values for x, y, and z in the 12th, 13th, and 14th position of the matrix.
	The first three elements of the first three columns are just directional vectors that represent the orientation (vectors here are used to represent a direction) of the x-, y-, and z-axes
	in space. For most purposes, these three vectors are always at 90° angles from each other,
	and are usually each of unit length (unless you are also applying a scale or shear). The
	mathematical term for this (in case you want to impress your friends) is orthonormal when
	the vectors are unit length, and orthogonal when they are not. Figure 4.28 shows the 4×4
	transformation matrix with the column vectors highlighted. Notice that the last row of
	the matrix is all 0s with the exception of the very last element, which is 1.
	Xx
	Xy
	Xz
	0
	Yx
	Yy
	Yz
	0
	Zx
	Zy
	Zz
	0
	Tx
	Ty
	Tz
	1
	X axis direction
	Y axis direction
	Z axis direction
	Translation/location
	FIGURE 4.28 How a 4×4 matrix represents a position and orientation in 3D space.
	The most amazing thing is that if you have a 4×4 matrix that contains the position and
	orientation of a different coordinate system, and you multiply a vertex (as a column
	matrix or vector) by this matrix, the result is a new vertex that has been transformed to
	the new coordinate system. This means that any position in space and any desired orientation can be uniquely defined by a 4×4 matrix, and if you multiply all of an object’s
	vertices by this matrix, you transform the entire object to the given location and orientation in space!
	HARDWARE TRANSFORMATIONS
	Most OpenGL implementations have what is called hardware transform and lighting. This means
	that the transformation matrix multiplies many thousands of vertices on special graphics hardware that performs this operation very, very fast. (Intel and AMD can eat their hearts out!)
	However, functions such as glRotate and glScale, which create transformation matrices for you,
	are usually not hardware accelerated because typically they represent an exceedingly small fraction of the enormous amount of matrix math that must be done to draw a scene.
	Loading a Matrix
	After you have a handle on the way the 4×4 matrix represents a given location and orientation, you may to want to compose and load your own transformation matrices. You can
	load an arbitrary column-major matrix into the projection, modelview, or texture matrix
	stacks by using the following function:
	glLoadMatrixf(GLfloat m);
	or
	glLoadMatrixd(GLfloat m);
	Most OpenGL implementations store and manipulate pipeline data as floats and not
	doubles; consequently, using the second variation may incur some performance penalty
	because 16 double-precision numbers must be converted into single-precision floats.
	The following code shows an array being loaded with the identity matrix and then being
	loaded into the modelview matrix stack. This example is equivalent to calling
	glLoadIdentity using the higher-level functions:
	// Load an identity matrix
	GLfloat m[] = { 1.0f, 0.0f, 0.0f, 0.0f, // X Column
	0.0f, 1.0f, 0.0f, 0.0f, // Y Column
	0.0f, 0.0f, 1.0f, 0.0f, // Z Column
	0.0f, 0.0f, 0.0f, 1.0f }; // Translation
	glMatrixMode(GL_MODELVIEW);
	glLoadMatrixf(m);
	156 CHAPTER 4 Geometric Transformations: The Pipeline
	Although OpenGL implementations use column-major ordering, OpenGL (versions 1.2
	and later) does provide functions to load a matrix in row-major ordering. The following
	two functions perform the transpose operation on the matrix when loading it on the
	matrix stack:
	void glLoadTransposeMatrixf(Glfloat* m);
	and
	void glLoadTransposeMatrixd(Gldouble* m);
	Performing Your Own Transformations
	Let’s look at an example now that shows how to create and load your own transformation
	matrix—the hard way! In the sample program TRANSFORM, we draw a torus (a doughnutshaped object) in front of our viewing location and make it rotate in place. The function
	DrawTorus does the necessary math to generate the torus’s geometry and takes as an argument a 4×4 transformation matrix to be applied to the vertices. We create the matrix and
	apply the transformation manually to each vertex to transform the torus. Let’s start with
	the main rendering function in Listing 4.4.
	LISTING 4.4 Code to Set Up the Transformation Matrix While Drawing
	void RenderScene(void)
	{
	M3DMatrix44f transformationMatrix; // Storage for rotation matrix
	static GLfloat yRot = 0.0f; // Rotation angle for animation
	yRot += 0.5f;
	// Clear the window with current clearing color
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
	// Build a rotation matrix
	m3dRotationMatrix44(transformationMatrix, m3dDegToRad(yRot),
	0.0f, 1.0f, 0.0f);
	transformationMatrix[12] = 0.0f;
	transformationMatrix[13] = 0.0f;
	transformationMatrix[14] = -2.5f;
	DrawTorus(transformationMatrix);
	// Do the buffer Swap
	glutSwapBuffers();
	}
	Advanced Matrix Manipulation 157
	4
	We begin by declaring storage for the matrix here:
	M3DMatrix44f transformationMatrix; // Storage for rotation matrix
	The data type M3DMatrix44f is of our own design and is simply a typedef declared in
	math3d.h for a floating-point array 16 elements long:
	typedef GLfloat M3DMatrix44f[16]; // A column major 4x4 matrix of type GLfloat
	The animation in this sample works by continually incrementing the variable yRot that
	represents the rotation around the y-axis. After clearing the color and depth buffer, we
	compose our transformation matrix as follows:
	m3dRotationMatrix44(transformationMatrix, m3dDegToRad(yRot), 0.0f, 1.0f, 0.0f);
	transformationMatrix[12] = 0.0f;
	transformationMatrix[13] = 0.0f;
	transformationMatrix[14] = -2.5f;
	Here, the first line contains a call to another math3d function, m3dRotationMatrix44. This
	function takes a rotation angle in radians (for more efficient calculations) and three arguments specifying a vector around which you want the rotation to occur. The macro function m3dDegToRad does an in-place conversion from degrees to radians. With the exception
	of the angle being in radians instead of degrees, this is almost exactly like the OpenGL
	function glRotate. The first argument is a matrix into which you want to store the resulting rotation matrix.
	As you saw in Figure 4.28, the last column of the matrix represents the translation of the
	transformation. Rather than do a full matrix multiplication, we can simply inject the
	desired translation directly into the matrix. Now the resulting matrix represents both a
	translation in space (a location to place the torus) and then a rotation of the object’s coordinate system applied at that location.
	Next, we pass this transformation matrix to the DrawTorus function. We do not need to
	list the entire function to create a torus here, but focus your attention to these lines:
	objectVertex[0] = x0*r;
	objectVertex[1] = y0*r;
	objectVertex[2] = z;
	m3dTransformVector3(transformedVertex, objectVertex, mTransform);
	glVertex3fv(transformedVertex);
	The three components of the vertex are loaded into an array and passed to the function
	m3dTransformVector3. This math3d function performs the multiplication of the vertex
	against the matrix and returns the transformed vertex in the array transformedVertex. We
	then use the vector version of glVertex and send the vertex data down to OpenGL. The
	result is a spinning torus, as shown in Figure 4.29.
	158 CHAPTER 4 Geometric Transformations: The Pipeline
	FIGURE 4.29 The spinning torus, doing our own transformations.
	It is important that you see at least once the real mechanics of how vertices are transformed by a matrix using such a drawn-out example. As you progress as an OpenGL
	programmer, you will find that the need to transform points manually will arise for tasks
	that are not specifically related to rendering operations, such as collision detection
	(bumping into objects), frustum culling (throwing away and not drawing things you can’t
	see), and some other special effects algorithms.
	For geometry processing, however, the TRANSFORM sample program is very inefficient,
	despite its instructional value. We are letting the CPU do all the matrix math instead of
	letting OpenGL’s dedicated hardware do the work for us (which is much faster than the
	CPU!). In addition, because OpenGL has the modelview matrix, all our transformed points
	are being multiplied yet again by the identity matrix. This does not change the value of
	our transformed vertices, but it is still a wasted operation.
	For the sake of completeness, we provide an improved example, TRANSFORMGL, that
	instead uses our transformation matrix but hands it over to OpenGL using the function
	glLoadMatrixf. We eliminate our DrawTorus function with its dedicated transformation
	code and use a more general-purpose torus drawing function, gltDrawTorus, from the
	glTools library. The relevant code is shown in Listing 4.5.
	Advanced Matrix Manipulation 159
	4
	LISTING 4.5 Loading the Transformation Matrix Directly into OpenGL
	// Build a rotation matrix
	m3dRotationMatrix44(transformationMatrix, m3dDegToRad(yRot),
	0.0f, 1.0f, 0.0f);
	transformationMatrix[12] = 0.0f;
	transformationMatrix[13] = 0.0f;
	transformationMatrix[14] = -2.5f;
	glLoadMatrixf(transformationMatrix);
	gltDrawTorus(0.35, 0.15, 40, 20);
	Adding Transformations Together
	In the preceding example, we simply constructed a single transformation matrix and
	loaded it into the modelview matrix. This technique had the effect of transforming any
	and all geometry that followed by that matrix before being rendered. As you’ve seen in
	the previous examples, we often add one transformation to another. For example, we used
	glTranslate followed by glRotate to first translate and then rotate an object before being
	drawn. Behind the scenes, when you call multiple transformation functions, OpenGL
	performs a matrix multiplication between the existing transformation matrix and the one
	you are adding or appending to it. For example, in the TRANSFORMGL example, we
	might replace the code in Listing 4.5 with something like the following:
	glPushMatrix();
	glTranslatef(0.0f, 0.0f, -2.5f);
	glRotatef(yRot, 0.0f, 1.0f, 0.0f);
	gltDrawTorus(0.35, 0.15, 40, 20);
	glPopMatrix();
	Using this approach has the effect of saving the current identity matrix, multiplying the
	translation matrix, multiplying the rotation matrix, and then transforming the torus by
	the result. You can do these multiplications yourself by using the math3d function
	m3dMatrixMultiply, as shown here:
	M3DMatrix44f rotationMatrix, translationMatrix, transformationMatrix;
	...
	m3dRotationMatrix44(rotationMatrix, m3dDegToRad(yRot), 0.0f, 1.0f, 0.0f);
	m3dTranslationMatrix44(translationMatrix, 0.0f, 0.0f, -2.5f);
	m3dMatrixMultiply44(transformationMatrix, translationMatrix, rotationMatrix);
	glLoadMatrixf(transformationMatrix);
	gltDrawTorus(0.35f, 0.15f, 40, 20);
	160 CHAPTER 4 Geometric Transformations: The Pipeline
	OpenGL also has its own matrix multiplication function, glMultMatrix, that takes a
	matrix and multiplies it by the currently loaded matrix and stores the result at the top of
	the matrix stack. In our final code fragment, we once again show code equivalent to the
	preceding, but this time we let OpenGL do the actual multiplication:
	M3DMatrix44f rotationMatrix, translationMatrix, transformationMatrix;
	...
	glPushMatrix();
	m3dRotationMatrix44(rotationMatrix, m3dDegToRad(yRot), 0.0f, 1.0f, 0.0f);
	gltTranslationMatrix44(translationMatrix, 0.0f, 0.0f, -2.5f);
	glMultMatrixf(translationMatrix);
	glMultMatirxf(rotationMatrix);
	gltDrawTorus(0.35f, 0.15f, 40, 20);
	glPopMatrix();
	As you can see, there is considerable flexibility in how you handle model transformations.
	Using the OpenGL functions allows you to offload as much as possible to the graphics
	hardware. Using your own functions gives you ultimate control over any intermediate
	steps. The freedom to mix and match approaches as needed is another reason OpenGL is
	an extremely powerful and flexible API for doing 3D graphics.
	</code></pre>

</details>



<h1><a name="procgen-pt2">LESSON 27 - Procedural generation pt. 2</a></h1>
<h3>Introduction</h3>
<p id="note">OpenGL is by default aliased. </p>

<p>Let's make a few new functions and implement our first procedurally generated textures.</p>

<p>Add the following function prototypes, defines and variables in the global section of the <b>main.c</b> file:</p>

<pre><code>
void makeCheckImage(void);
void loadTexture(void);
...
// Write the defines in CAPS
#define checkImageWidth 64	
#define checkImageHeight 64
GLubyte checkImage[checkImageHeight][checkImageWidth][4];
GLuint texName;
</code></pre>

<p>Then implement the bodies of the new functions.</p>

<pre><code>
void makeCheckImage(void)
{
	int i, j, c;

	for (i = 0; i < checkImageHeight; i++)
	{
		for (j = 0; j < checkImageWidth; j++)
		{
			c = (((i & 0x8) == 0) ^ ((j & 0x8) == 0)) * 255;	// Take byte of i and multiply it by hex value of 8 in decimal (produces a checkerboard pattern * alpha) 
										// ^ represents Bitwise OR
			checkImage[i][j][0] = (GLubyte) c;			// R
			checkImage[i][j][1] = (GLubyte) c;			// G
			checkImage[i][j][2] = (GLubyte) c;			// B
			checkImage[i][j][3] = 255;				// A (Changing the value will not affect the output of this code)
		}
	}
}
</code></pre>

<p>Next we add the function body for our new texture generating function:</p>

<pre><code>
void loadTexture(void)
{
	makeCheckImage();

	glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
	glGenTextures(1, &texName);
	glBindTexture(GL_TEXTURE_2D, texName);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
	glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, checkImageWidth, checkImageHeight, 0, GL_RGBA, GL_UNSIGNED_BYTE, checkImage);
	glTexEnvf(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE);
}
</code></pre>

<p>Add this to <b>initialize()</b>.</p>

<pre><code>
glEnable(GL_TEXTURE_2D);
loadTexture();
</code></pre>

<p>Then you add this into <b>display()</b></p>

<pre><code>
glBegin(GL_QUADS);
	glTexCoord2f(0.0f, 0.0f);
	glVertex3f(-2.0, -1.0, 0.0f);
	glTexCoord2f(0.0f, 1.0f);
	glVertex3f(-2.0, 1.0f, 0.0f);
	glTexCoord2f(1.0f, 1.0f);
	glVertex3f(0.0f, 1.0f, 0.0f);
	glTexCoord2f(1.0f, 0.0f);
	glVertex3f(0.0f, -1.0f, 0.0f);

	glTexCoord2f(0.0f, 0.0f);
	glVertex3f(1.0f, -1.0f, 0.0f);
	glTexCoord2f(0.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 0.0f);
	glTexCoord2f(1.0f, 1.0f);
	glVertex3f(2.41421f, 1.0f, -1.41421f);
	glTexCoord2f(1.0f, 0.0f);
	glVertex3f(2.41421f, -1.0f, -1.41421f);
glEnd();
</code></pre>

<p>If you compile and run this project you'll see a procedurally generated texture of a checkerboard pattern facing the screen on the left and skewed to the right on the right side.</p>

<p>MSDN documentation about bitwise operators: <a href="https://docs.microsoft.com/en-us/cpp/c-language/c-bitwise-operators?view=msvc-170" target="_blank">https://docs.microsoft.com/en-us/cpp/c-language/c-bitwise-operators?view=msvc-170</a></p>


<h1><a name="drawing-advance-geo-pt3">LESSON 28 - Drawing advanced geometry pt. 3</a></h1>
<h3>Introduction</h3>
<p>Let start free drawing some real world objects, like a house, and add some texturing to it.</p>

<p>Begin by adding a new file called <b>Resource.rc</b> and a <b>texture.h</b>, like in <b>lesson 22</b>. Remember to to enable depth testing, adding <b>GL_DEPTH_BUFFER_BIT</b> in <b>display</b> and include texture.h in main, and add the <b>load_texture</b>-function.</p>

<p>Then lets declare some global variables to use for our textures. For simplicity sake I making adding a function prototype and GLuint texture variables just below our pervious code: </p>

<pre><code>
void draw_house(void);

GLuint house_front_texture, house_left_texture, house_right_texture, house_back_texture;
GLuint roof_left_texture, roof_right_texture;
GLuint door_texture;
GLuint chimney_texture;
</code></pre>

<p>Add the following code into <b>initialize</b>:</p>

<pre><code>
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_LEQUAL);
glClearDepth(1.0f);

load_texture(&house_front_texture, MAKEINTRESOURCE(IDI_TEXTURE_FRONT));
load_texture(&house_left_texture, MAKEINTRESOURCE(IDI_TEXTURE_LEFT));
load_texture(&house_right_texture, MAKEINTRESOURCE(IDI_TEXTURE_RIGHT));
load_texture(&house_back_texture, MAKEINTRESOURCE(IDI_TEXTURE_BACK));
load_texture(&door_texture, MAKEINTRESOURCE(IDI_TEXTURE_DOOR));
load_texture(&roof_left_texture, MAKEINTRESOURCE(IDI_TEXTURE_ROOF_LEFT));
load_texture(&roof_right_texture, MAKEINTRESOURCE(IDI_TEXTURE_ROOF_RIGHT));
load_texture(&chimney_texture, MAKEINTRESOURCE(IDI_TEXTURE_CHIMNEY));
</code></pre>

<p>The lets implement the function prototype of <b>draw_house</b></p>

<pre><code>

void draw_house(void)
{
	glBindTexture(GL_TEXTURE_2D, house_front_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.0f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(1.0f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(1.0f, 1.0f, 0.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, house_right_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(1.0f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(1.0f, 0.0f, -1.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(1.0f, 1.0f, -1.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(1.0f, 1.0f, 0.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, house_left_texture);
	glBegin(GL_QUADS);
		glColor3f(1.0f, 1.0f, 0.0f);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.0f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.0f, 0.0f, -1.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.0f, 1.0f, -1.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
	glEnd();

	glColor3f(1.0f, 1.0f, 1.0f);

	glBindTexture(GL_TEXTURE_2D, house_back_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.0f, 0.0f, -1.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(1.0f, 0.0f, -1.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(1.0f, 1.0f, -1.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.0f, 1.0f, -1.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, roof_left_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.5f, 1.5f, 0.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.5f, 1.5f, -1.0f);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.0f, 1.0f, -1.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, roof_right_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(1.0f, 1.0f, 0.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(1.0f, 1.0f, -1.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.5f, 1.5f, -1.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.5f, 1.5f, 0.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, house_front_texture);
	glBegin(GL_TRIANGLES);
		glTexCoord2f(0.2f, 0.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glTexCoord2f(0.8f, 0.0f);
		glVertex3f(1.0f, 1.0f, 0.0f);
		glTexCoord2f(1.0f, 0.5f);
		glVertex3f(0.5f, 1.5f, 0.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, house_front_texture);
	glBegin(GL_TRIANGLES);
		glTexCoord2f(0.8f, 0.0f);
		glVertex3f(1.0f, 1.0f, -1.0f);
		glTexCoord2f(0.2f, 0.0f);
		glVertex3f(0.0f, 1.0f, -1.0f);
		glTexCoord2f(0.5f, 1.0f);
		glVertex3f(0.5f, 1.5f, -1.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, door_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.4f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.6f, 0.0f, 0.0f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.6f, 0.6f, 0.0f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.4f, 0.6f, 0.0f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, chimney_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.3f, 1.2f, -0.4f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.5f, 1.2f, -0.4f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.5f, 1.8, -0.4f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.3, 1.8, -0.4f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, chimney_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.5f, 1.2f, -0.4f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.5, 1.8f, -0.4f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.5f, 1.8f, -0.6f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.5f, 1.2f, -0.6f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, chimney_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.5f, 1.2, -0.6f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.5f, 1.8f, -0.6f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.3f, 1.8f, -0.6f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.3f, 1.2f, -0.6f);
	glEnd();

	glBindTexture(GL_TEXTURE_2D, chimney_texture);
	glBegin(GL_QUADS);
		glTexCoord2f(0.0f, 0.0f);
		glVertex3f(0.3f, 1.2f, -0.6f);
		glTexCoord2f(1.0f, 0.0f);
		glVertex3f(0.3f, 1.2f, -0.4f);
		glTexCoord2f(1.0f, 1.0f);
		glVertex3f(0.3f, 1.8f, -0.4f);
		glTexCoord2f(0.0f, 1.0f);
		glVertex3f(0.3f, 1.8f, -0.6f);
	glEnd();
}
</code></pre>

<p>Then just add the <b>draw_house</b> and a static float rotate variable into <b>display</b>.</p>

<pre><code>
static float rotate = 0.0f;
rotate += 0.25f;
glRotatef(rotate, 0.0f, 1.0f, 0.0f);

draw_house();
</code></pre>

<p id="note">
	In a future iteration of this tutorial add a function to place point (p.x, p.y, p.z) in each vertices, like struct, and think of better naming conversion for the texture variables.
	
	<pre><code>
	typedef struct point {
		float x, y, z;
	} p;
	
	void add_points(x, y, z) {
		p.x = x;
		p.y = y;
		p.z = z;
	}
	</code></pre>
</p>


<h1><a name="procgen-pt3">LESSON 29 - Procedural generation pt. 3 (Mandelbrot)</a></h1>
<h3>Introduction</h3>
<p></p>

<p></p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);
// LESSON 29 
void mandelbrot(void);
struct type_rgb { float r; float g; float b; };
// Holds the size of the mandelbrot shape (pixels contains the colorval for the pixel, pattern is a predefined set of colors)
struct type_rgb pixels[841 * 1440], pattern[999];

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_KEYDOWN:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	int i;
	float r, g, b;
	// All pixels are initialized to white (841 * 1440 white pixels)
	for (i = 0; i < 841 * 1440; i++)
	{
		pixels[i].r = 1;
		pixels[i].g = 1;
		pixels[i].b = 1;
	}

	i = 0;
	for (r = 0.1f; r <= 0.9f; r = r + 0.1f)
	{
		for (g = 0.1f; g <= 0.9f; g = g + 0.1f)
		{
			for (b = 0.1f; b <= 0.9f; b = b + 0.1f)
			{
				// This is a simple way to manipulate the colors
				pattern[i].r = b;
				pattern[i].g = r;
				pattern[i].b = g;
				// Fills 729 different color patterns
				/*pattern[i].r = r;
				pattern[i].g = g;
				pattern[i].b = b;*/
				i++;
			}
		}
	}

	// Reinitializing the remaining patterns to white
	/*for (; i <= 999; i++)
	{
		pattern[i].r = 1;
		pattern[i].g = 1; 
		pattern[i].b = 1;
	}*/

	mandelbrot();

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	
	glDrawPixels(1440, 841, GL_RGB | GL_STENCIL_INDEX, GL_FLOAT, pixels);

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}

void mandelbrot(void)
{
	// Mandelbrot is a complex equation (contains one real number and one imaginary number)
	// x0 = real part of C value (range: -2.5, 1.1)
	// y0 = imaginary part (range: -1, 1.1)
	float x0, y0, x, y, xtemp;
	// iteration: controlled number of iterations
	// max_iteration: the maximum number of iterations
	// loc = location of the current [x, y]
	int iteration, max_iteration, loc = 0;
	
	// Zn = complex number
	// Mandelbrot Equation = Zn^2 + C
	// complex number = real part + imaginary part
	// real part = x0		
	// imaginary part = y0	[-1, 1]
	// Complex Number = x0 + y0

	// https://simple.wikipedia.org/wiki/Mandelbrot_set#:~:text=The%20Mandelbrot%20set%20can%20be,positive%20integer%20(natural%20number).

	// Zn = (x0^2 + y0^2)

	for (y0 = -1; y0 < 1.1f; y0 = y0 + 0.0025f)
	{
		for (x0 = -2.5f; x0 < 1.1f; x0 = x0 + 0.0025f)
		{
			x = 0;
			y = 0;
			iteration = 0;
			max_iteration = 1000;

			for (iteration = 0; ((x * x) + (y * y) + 1.5 < (2 * 2)) && (iteration < max_iteration); iteration = iteration + 1)
			{
				xtemp = (x * x) - (y * y) + x0;
				y = (2 * x * y) + y0;
				x = xtemp;
				pixels[loc].r = pattern[iteration].r;
				pixels[loc].g = pattern[iteration].g;
				pixels[loc].b = pattern[iteration].b;
			}

			if (iteration >= 999)
			{
				pixels[loc].r = 0;
				pixels[loc].g = 0;
				pixels[loc].b = 0;
			}

			loc = loc + 1;
		}
	}
}
</code></pre>
</details>

<p id="note">This code doesn't resize with the window, so implement that...</p>



<h1><a name="matrix-v-identity-matrix">LESSON 30 - Matrices and Identity Matrix</a></h1>
<h3>Introduction</h3>
<p>Identity matrix (known as a unit matrix)...</p>

<p>1x + 2y + 3z = 100</p>
<p>4x + 5y + 6z = 200</p>
<p>7x + 8y + 3z = 300</p>

<p>A matrix is a vehical for transformations.</p>

<pre><code>
  x  y  z
 --     --  
| 1  0  0 | 
| 0  1  0 | 
| 0  0  1 | 
 --      -- 
</code></pre>

<pre><code>
  x  y  z
 --     --     - -     --  --
| 1  2  3 |   | x |   |  100 |
| 4  5  6 | X | y | = |  200 |
| 7  8  3 |   | z |   |  300 |
 --      --    - -     --  --
</code></pre>

<pre><code>
  x  y  z
 --        --  
| 1  0  0  0 |     | x |   | x' |
| 0  1  0  0 |     | y |   | y' |
| 0  0  1  0 |  X  | z | = | z' |
| 0  0  0  1 |     |   |   |    |
 --        -- 
</code></pre>


<p>If you have a transformation matrix like this: glTranslatef(3.0f, 5.0f, -8.0f): </p>

<pre><code>
  x  y  z
 --     --           - -     -  -
| 1  0  0  tx |     | x |   | x' |
| 0  1  0  ty |     | y |   | y' |
| 0  0  1  tz |  X  | z | = | z' |
| 0  0  0  1  |     | 1 |   | 1  |
 --         --       - -     -  -
</code></pre>

<h3>Rotation Matrix</h3>

<pre><code>
 --                                                --
| 1.0f             0.0f          0.0f          0.0f  |
| 0.0f          cos &theta;   sin &theta;      0.0f  |
| -sin &theta;  cos &theta;       0.0f         0.0f  |
| 0.0f              0.0f         0.0f          1.0f  |
 --                                                --
</code></pre>

<p>You can add the matrices in your <b>display</b> function:</p>

<pre><code>
void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);

	// LESSON 30
	GLfloat identityMatrix[16];
	identityMatrix[0]	= 1.0f;
	identityMatrix[1]	= 0.0f;
	identityMatrix[2]	= 0.0f;
	identityMatrix[3]	= 0.0f;
	identityMatrix[4]	= 0.0f;
	identityMatrix[5]	= 1.0f;
	identityMatrix[6]	= 0.0f;
	identityMatrix[7]	= 0.0f;
	identityMatrix[8]	= 0.0f;
	identityMatrix[9]	= 0.0f;
	identityMatrix[10]	= 1.0f;
	identityMatrix[11]	= 0.0f;
	identityMatrix[12]	= 0.0f;
	identityMatrix[13]	= 0.0f;
	identityMatrix[14]	= 0.0f;
	identityMatrix[15]	= 1.0f;

	GLfloat translationMatrix[16];
	translationMatrix[0] = 1.0f;
	translationMatrix[1] = 0.0f;
	translationMatrix[2] = 0.0f;
	translationMatrix[3] = 0.0f;
	translationMatrix[4] = 0.0f;
	translationMatrix[5] = 1.0f;
	translationMatrix[6] = 0.0f;
	translationMatrix[7] = 0.0f;
	translationMatrix[8] = 0.0f;
	translationMatrix[9] = 0.0f;
	translationMatrix[10] = 1.0f;
	translationMatrix[11] = 0.0f;
	translationMatrix[12] = 0.0f;
	translationMatrix[13] = 0.0f;
	translationMatrix[14] = -3.0f;
	translationMatrix[15] = 1.0f;

	glLoadMatrixf(identityMatrix);
	glMultMatrixf(translationMatrix);

	static GLfloat angle = 0.0f;
	GLfloat rotationMatrix[16];
	rotationMatrix[0] = 1.0f;
	rotationMatrix[1] = 0.0f;
	rotationMatrix[2] = 0.0f;
	rotationMatrix[3] = 0.0f;
	rotationMatrix[4] = 0.0f;
	rotationMatrix[5] = cos(angle);
	rotationMatrix[6] = sin(angle);
	rotationMatrix[7] = 0.0f;
	rotationMatrix[8] = 0.0f;
	rotationMatrix[9] = -(sin(angle));
	rotationMatrix[10] = cos(angle);
	rotationMatrix[11] = 0.0f;
	rotationMatrix[12] = 0.0f;
	rotationMatrix[13] = 0.0f;
	rotationMatrix[14] = 0.0f;
	rotationMatrix[15] = 1.0f;

	glMultMatrixf(rotationMatrix);
	angle += 0.01f;

	glBegin(GL_TRIANGLES);
		glColor3f(1.0f, 0.0f, 0.0f);
		glVertex2f(0.0f, 1.0f);
		glColor3f(0.0f, 1.0f, 0.0f);
		glVertex2f(-1.0f, -1.0f);
		glColor3f(0.0f, 0.0f, 1.0f);
		glVertex2f(1.0f, -1.0f);
	glEnd();

	SwapBuffers(g_hdc);
}
</code></pre>

<p>Case study:</p>

<pre><code>
					   | cos &theta;    -sin &theta;    0            0 |  
R<sub>z</sub>(theta) = | sin &theta;    cos &theta;     0            0 |  
					   |     0               0          1            0 |  
					   |     0               0          0            1 |  
</code></pre>

<pre><code>
					   | cos &theta;         0     -sin &theta;       0 |  
R<sub>y</sub>(theta) = |     0               1          0             0 |  
					   | sin &theta;         0     cos &theta;        0 |  
					   |     0               0          0             1 |  
</code></pre>

<pre><code>
					   |     1               0          0            0 |  
R<sub>x</sub>(theta) = |     0    cos &theta;     -sin &theta;       0 |  
					   |     0    sin &theta;     cos &theta;        0 |  
					   |     0               0          0            1 |  
</code></pre>

<a href="https://cupdf.com/document/perspective-projections-opengl-viewing-3d-projections-opengl-viewing-3d-clipping.html">https://cupdf.com/document/perspective-projections-opengl-viewing-3d-projections-opengl-viewing-3d-clipping.html</a>



<h1><a name="simulating-planets-glu-pt1">LESSON 31 - Simulating planets with rotation using GLU pt. 1</a></h1>
<h3>Introduction</h3>

<p>This time we are going to simulate a planet orbiting a sun using the GLU way of drawing spheres. Start by adding these global variables to your <b>main.c</b> file: </p>

<pre><code>
GLfloat year = 0;
GLfloat day = 0;
GLUquadric* quadric = NULL;
</code></pre>

<p>We'll handle the movement manually for now, so add the follwing code into your <b>WndProc</b> in <b>WM_KEYDOWN</b>:</p>

<pre><code>
case 'y':
	year = (int)(year + 3) % 360;
	break;
case 'Y':
	year = (int)(year - 3) % 360;
	break;
case 'd':
	day = (int)(day + 6) % 360;
	break;
case 'D':
	day = (int)(day - 6) % 360;
	break;
</code></pre>

<p>This will rotate the planet around the orbit of the sun when user presses <b>y</b> or <b>Y</b>, and rotate the planet itself when the user presses <b>d</b> or <b>D</b>.</p>

<p>To enable depth testing so the rotation will look like it's hidden behind the sun you need to enable depth testing (in <b>initialize</b>): </p>

<pre><code>
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_LEQUAL);
</code></pre>

<p>To ensure that you can see the sun and planet, add the <b>gluPerspective</b> into your <b>resize</b> function: </p>

<pre><code>
gluPerspective(45.0f, (GLfloat)w/(GLfloat)h, 0.1f, 100.0f);
</code></pre>

<p>Finally we position the camera and add each object into the scene:</p>

<pre><code>
gluLookAt(
	0.0f, 0.0f, 5.0f,
	0.0f, 0.0f, 0.0f,
	0.0f, 1.0f, 0.0f
);

glPushMatrix();										// OGL handles two different stacks, proj_stack & transf_stack
	glRotatef(90.0f, 1.0f, 0.0f, 0.0f);				// This is pushed on the transformation stack
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);		// Handle polygon filling, GL_FILL is oposite of wireframe
	quadric = gluNewQuadric();						// Create the quadric object
	glColor3f(1.0f, 1.0f, 0.0f);					// 
	gluSphere(quadric, 0.75f, 30.0f, 30.0f);		// Pass the object to the quadric sphere, radius = 75, 30, longtitude, 30 latitude (resolution of the sphere)
glPopMatrix();										// Returns the stack to the original projection matrix

glPushMatrix();										// Second pushed transformation stack
	glRotatef((GLfloat)year, 0.0f, 1.0f, 0.0f);		// 
	glTranslatef(1.5f, 0.0f, 0.0f);					// 
	glRotatef((GLfloat)90.0f, 1.0f, 0.0f, 0.0f);	// Without this call the sphere is rendered in the y direction..
	glRotatef((GLfloat)day, 0.0f, 0.0f, 1.0f);		// 
	glPolygonMode(GL_FRONT_AND_BACK, GL_LINE);		// 
	quadric = gluNewQuadric();						// 
	glColor3f(0.4f, 0.9f, 1.0f);					// 
	gluSphere(quadric, 0.2f, 20.0f, 20.0f);			// 
glPopMatrix();
</code></pre>




<h1><a name="simulating-planets-glu-pt2">LESSON 32 - Simulating planets with rotation using GLU pt. 2</a></h1>
<h3>Introduction</h3>

<p>Now lets add a moon orbiting the planet to continue our space simulation or orbiting bodies in space.</p>

<p>First we need to declare a variable that controlls the moon, so add the following into the global namespace:</p>

<pre><code>
GLfloat moon_revolution = 0.0f;
</code></pre>

<p>The moon should orbit the planet we generated in the previous lesson in the same way the planet orbits the sun, therefor you have to add another <b>glPushMatrix</b> / <b>glPopMatrix</b> inside the stack that controls the planet orbitation: </p>

<pre><code>
glPushMatrix();
	glRotatef((GLfloat)year, 0.0f, 1.0f, 0.0f);	
	glTranslatef(1.5f, 0.0f, 0.0f);	 
	glRotatef((GLfloat)90.0f, 1.0f, 0.0f, 0.0f); 
	glRotatef((GLfloat)day, 0.0f, 0.0f, 1.0f);	 
	glPolygonMode(GL_FRONT_AND_BACK, GL_LINE);	 
	quadric = gluNewQuadric();
	glColor3f(0.4f, 0.9f, 1.0f);
	gluSphere(quadric, 0.2f, 20.0f, 20.0f);	
	
	...							// Add the new substack here
	
glPopMatrix();
</code></pre>

<p>The new substack should look exactly like the previous ones except for the size of the moon. I've also chosen to draw the with filled <b>glPolygonMode</b> to improve the visibility.</p>
<pre><code>
glPushMatrix();
	// Earth is rotating, so moon should rotate as well
	glRotatef((GLfloat)day, 0.0f,0.0f, 1.0f);
	glTranslatef(0.5f, 0.0f, 0.0f);
	// Controls the moons own axis
	glRotatef((GLfloat)moon_revolution, 0.0f, 0.0f, 1.0f);
	// Rotates to it's correct positional axis
	glRotatef(90.0f, 1.0f, 0.0f, 0.0f);
	// Creating the moons sphere
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
	quadric = gluNewQuadric();
	glColor3f(0.8f, 0.8f, 0.8f);
	gluSphere(quadric, 0.1f, 15.0f, 15.0f);
glPopMatrix();
</code></pre>

<p>Lastly we update the <b>WndProc</b> to add orbitational movement when the user presses the <b>d</b> or <b>D</b> button on the keyboard.</p>

<p id="note">Note that we have changed the case in our switch-statement to <b>case WM_CHAR:</b> to handle the keyboard input correctly</p>

<pre><code>
...
case WM_CHAR:
	...
	case 'd':
		day = (int)(day + 6) % 360;
		moon_revolution = (int)(moon_revolution + 9) % 360;
		break;
	case 'D':
		day = (int)(day - 6) % 360;
		moon_revolution = (int)(moon_revolution + 9) % 360;
		break;
	...
</code></pre>

<p>If you compile and run your program now, then press lower- or uppercase <b>d</b> or lower- or uppercase <b>y</b> you'll see the planet orbiting around the sun, with the moon orbiting around the planet.</p>

<p id="note">Complete code from this lesson</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows")

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

GLfloat year = 0;
GLfloat day = 0;
GLUquadric* quadric = NULL;
GLfloat moon_revolution = 0.0f;

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	// case WM_KEYDOWN:
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'y':
			year = (int)(year + 3) % 360;
			break;
		case 'Y':
			year = (int)(year - 3) % 360;
			break;
		case 'd':
			day = (int)(day + 6) % 360;
			moon_revolution = (int)(moon_revolution + 9) % 360;
			break;
		case 'D':
			day = (int)(day - 6) % 360;
			moon_revolution = (int)(moon_revolution + 9) % 360;
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
	glEnable(GL_DEPTH_TEST);
	glDepthFunc(GL_LEQUAL);
	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w/(GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	// LESSON 31
	gluLookAt(
		0.0f, 0.0f, 5.0f,
		0.0f, 0.0f, 0.0f,
		0.0f, 1.0f, 0.0f
	);

	glPushMatrix();	
		glRotatef(90.0f, 1.0f, 0.0f, 0.0f);	
		glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
		quadric = gluNewQuadric();
		glColor3f(1.0f, 1.0f, 0.0f);
		gluSphere(quadric, 0.75f, 30.0f, 30.0f);
	glPopMatrix();

	glPushMatrix();	
		glRotatef((GLfloat)year, 0.0f, 1.0f, 0.0f);	 
		glTranslatef(1.5f, 0.0f, 0.0f);	 
		glRotatef((GLfloat)90.0f, 1.0f, 0.0f, 0.0f);
		glRotatef((GLfloat)day, 0.0f, 0.0f, 1.0f);	 
		glPolygonMode(GL_FRONT_AND_BACK, GL_LINE);	 
		quadric = gluNewQuadric();	 
		glColor3f(0.4f, 0.9f, 1.0f);
		gluSphere(quadric, 0.2f, 20.0f, 20.0f); 
		glPushMatrix();
			glRotatef((GLfloat)day, 0.0f,0.0f, 1.0f);
			glTranslatef(0.5f, 0.0f, 0.0f);
			glRotatef((GLfloat)moon_revolution, 0.0f, 0.0f, 1.0f);
			glRotatef(90.0f, 1.0f, 0.0f, 0.0f);
			glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
			quadric = gluNewQuadric();
			glColor3f(0.8f, 0.8f, 0.8f);
			gluSphere(quadric, 0.1f, 15.0f, 15.0f);
		glPopMatrix();
	glPopMatrix();

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</pre></code>
</details>




<h1><a name="simulating-robotic-arm">LESSON 33 - Simulating a robotic arm with multiple joints</a></h1>
<h3>Introduction</h3>

<p>This time we'll create a moving robotic arm, with joints that seem connected.</p>

<p>Begin by declaring three new variables in the global scope:</p>

<pre><code>
GLfloat shoulder = 0.0f;
GLfloat elbow = 0.0f;
GLUquadric* quadric = NULL;
</code></pre>

<p>Now we update our <b>display</b>-function with the following: </p>

<pre><code>
glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
glColor3f(0.5f, 0.35f, 0.005f);
glTranslatef(0.0f, 0.0f, -12.0f);
glPushMatrix();
	glRotatef((GLfloat)shoulder, 0.0f, 0.0f, 1.0f);
	glTranslatef(1.0f, 0.0f, 0.0f);
	
	glPushMatrix();
		glScalef(2.0f, 0.5f, 1.0f);
		quadric = gluNewQuadric();
		gluSphere(quadric, 0.5f, 10.0f, 10.0f);
	glPopMatrix();

	glTranslatef(1.0f, 0.0f, 0.0f);
	glRotatef((GLfloat)elbow, 0.0f, 0.0f, 1.0f);
	glTranslatef(1.0f, 0.0f, 0.0f);
	
	glPushMatrix();
		glScalef(2.0f, 0.5f, 1.0f);
		quadric = gluNewQuadric();
		gluSphere(quadric, 0.5, 10.0f, 10.0f);
	glPopMatrix();

glPopMatrix();
</code></pre>

<p>And lastely we update out <b>WndProc</b> with the following code: </p>

<pre><code>
case 'S':
	shoulder = (int)(shoulder + 3) % 360;
	break;
case 's':
	shoulder = (int)(shoulder - 3) % 360;
	break;
case 'E':
	elbow = (int)(elbow + 3) % 360;
	break;
case 'e':
	elbow = (int)(elbow - 3) % 360;
	break;
}
</code></pre>

<p>Now the user can rotate the shoulder and elbow of the robotic arm by pressing <b>'e'</b> or <b>'s'</b> on the keyboard.</p>

<p id="note">Complete code from this lesson</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

GLfloat shoulder = 0.0f;
GLfloat elbow = 0.0f;
GLUquadric* quadric = NULL;

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'S':
			shoulder = (int)(shoulder + 3) % 360;
			break;
		case 's':
			shoulder = (int)(shoulder - 3) % 360;
			break;
		case 'E':
			elbow = (int)(elbow + 3) % 360;
			break;
		case 'e':
			elbow = (int)(elbow - 3) % 360;
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	int i;
	float r, g, b;
	
	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w/(GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
	glColor3f(0.5f, 0.35f, 0.005f);
	glTranslatef(0.0f, 0.0f, -12.0f);
	glPushMatrix();
		glRotatef((GLfloat)shoulder, 0.0f, 0.0f, 1.0f);
		glTranslatef(1.0f, 0.0f, 0.0f);
		
		glPushMatrix();
			glScalef(2.0f, 0.5f, 1.0f);
			quadric = gluNewQuadric();
			gluSphere(quadric, 0.5f, 10.0f, 10.0f);
		glPopMatrix();

		glTranslatef(1.0f, 0.0f, 0.0f);
		glRotatef((GLfloat)elbow, 0.0f, 0.0f, 1.0f);
		glTranslatef(1.0f, 0.0f, 0.0f);
		
		glPushMatrix();
			glScalef(2.0f, 0.5f, 1.0f);
			quadric = gluNewQuadric();
			gluSphere(quadric, 0.5, 10.0f, 10.0f);
		glPopMatrix();

	glPopMatrix();

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>




<h1><a name="progcen-drawing-circle-pt1">LESSON 34 - Procedurally drawing a circle pt. 1</a></h1>
<h3>Introduction</h3>

<p>Today we'll begin procedurally drawing a circle. Lets import the math-library and declare a function prototype:</p>

<pre><code>
...
#define _USE_MATH_DEFINES 1
#include &lt;math.h&gt;

...
void draw_sphere(float, int);
</code></pre>

<p>Our function implemention takes a <b>float r</b> for <i>radius</i>, and an <b>int n</b> for <i>number of sides</i> in our triangle strip.</p>

<p>Then we implement the drawing function to procedurally generate a circle. We declare the local variables we need to work with: <i>i</i>, <i>j</i>, <i>phi1 <var>&Phi;</var></i>, <i>phi2 <var>&rho;</var></i>, <i>theta <var>&theta;</var></i>, <i>s</i> and <i>t</i>.</p>

<p>We use the i and j as loop variables, and phi1, phi2 and theta to define our circle... s and j are used as texture coordinates (??) and is not implemented in this lesson.</p>

<p>Next we declare <i>ex</i>, <i>ey</i> and <i>ez</i>, then <i>px</i>, <i>py</i> and <i>pz</i>, all as <b>GLfloat</b>. Those define the (...something size of the circle??)</p>

<pre><code>
void draw_sphere(float r, int n)
{
	int i, j;
	GLdouble phi1, phi2, theta, s, t;
	GLfloat ex, ey, ez;
	GLfloat px, py, pz;

	if (r < 0) r = -r;
	if (n < 0) n = -n;
	// Since triangle only has three sides...
	if (n < 4 || r <= 0) {
		// Calculates the origon of the circle
		glBegin(GL_POINTS);
			glVertex3f(0.0f, 0.0f, 0.0f);
		glEnd();
		return;
	}
	
	for (j = 0; j < n; j++) {
		phi1 = j * M_PI * 2 / n;
		phi2 = (j + 1) * M_PI * 2 / n;
		// Calculates two more points, and draws it using GL_TRINGLE_STRIP, then moves phi1
		glBegin(GL_TRIANGLE_STRIP);
			for (i = 0; i <= n; i++) {
				theta = i * M_PI / n;
				ex = sin(theta) * cos(phi2);
				ey = sin(theta) * sin(phi2);
				ez = cos(theta);
				px = r * ex;
				py = r * ey;
				pz = r * ez;
				glVertex3f(px, py, pz);

				ex = sin(theta) * cos(phi1);
				ey = sin(theta) * sin(phi1);
				ez = cos(theta);
				px = r * ex;
				py = r * ey;
				pz = r * ez;
				glVertex3f(px, py, pz);
			}
		glEnd();
	}
}
</code></pre>

<p>We define our center of the circle using the <b>if (n < 4 || r <= 0)</b> and then we append another two points in or for-loop, and increment the 2D circle by <b>phi2 = (j + 1) * M_PI * 2 / n</b></p>

<p>The in our <b>display</b> we add the viewport transformation and call the newly created function:</p>

<pre><code>
glTranslatef(0.0f, 0.0f, -3.0f);
draw_sphere(0.2f, 60);
</code></pre>

<p>Compile and run the program and you'll see a white, 3 dimentional circle in the middle of the screen.</p>

<p id="note">For more details about calculating a circle take a look at these links: <br/>
<a href="Spherical Coordinates on mathinsight.org: ">https://mathinsight.org/spherical_coordinates</a><br/>
<a href="Implementing a circle in OpenGL: ">https://mathinsight.org/spherical_coordinates</a>
</p>



<h1><a name="lighting-pt1">LESSON 35 - Rendering light pt. 1</a></h1>
<h3>Introduction</h3>
<p>So far this tutorial has been focusing on the lower leverl stuff, and drawing various shapes, but what is a complete scene without lighting and shading?</p>

<p>This lesson we'll start adding lighting to our scene, so as always, lets declare some variables to use when adding light. In our global space add the following:</p>

<pre><code>
#include &lt;GL/glu.h&gt;
...
bool bLight = false;
GLfloat light_ambient[] = { 0.5f, 0.5f, 0.5f, 1.0f };
GLfloat light_diffuse[] = { 1.0f, 1.0f, 1.0f, 0.0f };
GLfloat light_position[] = { 0.0f, 0.0f, 2.0f, 1.0f }; 
</code></pre>

<p>The first variable is just a boolean switch to turn lighting on or off. We set the <b>bLight</b> variable to <i>false</i>. Next up we define the basics of our lighting model, as our <b>ambient light</b>, <b>diffuse light</b> and the <b>light position</b>.</p>

<p><b>Ambient light</b> is light that origins from an unknown source, think of it as the light that is scattered in the scene based on what light exists otherwise. <b>Diffuse light</b> is the known source of the light, eg. the sun or a lamp emitting light. Lastly we add the light position where the light origins form, which is drawn into our scene from that position.</p>

<p>When creating a diffuse light the fourth input in the array is either <b>0.0f</b> for an directional light (a position) or <b>1.0f</b> for a omnipresent lightsource (a direction), and tells if the light is a omnipresent source, like the sun or a local element, like a lamp.</p>

<p>Light has to be enabled for OpenGL to use it, so we need to update our <b>initialize</b> to include lighting in our scene.</p>

<pre><code>
...
glClearDepth(1.0f);
glEnable(GL_LIGHT0);
glLightfv(GL_LIGHT0, GL_AMBIENT, light_ambient);
glLightfv(GL_LIGHT0, GL_DIFFUSE, light_diffuse);
glLightfv(GL_LIGHT0, GL_POSITION, light_position);
glShadeModel(GL_SMOOTH);
glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);
...
</code></pre>

<p>In this example we only implement one light source, and we use <b>glClearDepth()</b> so that we clear our perspective[...]. Lighting is enabled with <b>glEnable</b>, and Legacy OpenGL supports up to 8 light sources pr scene (<b>GL_LIGHT0</b> - GL_LIGHT7</b>).</p>

<p>We also add the three variables we added in the global space using <b>glLightfv</b> to add the <b>GL_AMBIENT</b>, <b>GL_DIFFUSE</b> and <b>GL_POSITION</b> for our lighting model.</p>

<p><b>glShadeModel</b> is used to enable the way lighting and shading is drawn, so we add <b>GL_SMOOTH</b> to use the built in Geraud Shading. You can also use <b>GL_FLAT</b>. Then we tell OpenGL that we want the <b>GL_NICEST</b> for of Perspective correction, so minimize jagged edges.</p>

<p>The on to our model drawing routing in <b>display</b>. Since light is calculated from it's origin into any given point in our scene we have to define the normals in our scene so that lighting will be calculated correctly. A normal is a perpendicular ray to a particular face on our model.</p>

<p>Lets draw a simple cube which will be illustrated using our light source that we have defined so far.</p>

<pre><code>
...
glBegin(GL_QUADS);
	// TOP
	glNormal3f(0.0f, 1.0f, 0.0f);
	glColor3f(1.0f, 0.0f, 0.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, 1.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);

	// BOTTOM
	glNormal3f(0.0f, -1.0f, 0.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);

	// FRONT
	glNormal3f(0.0f, 0.0f, 1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);
	glVertex3f(-1.0f, 1.0f, 1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);

	// BACK
	glNormal3f(0.0f, 0.0f, -1.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);

	// RIGHT
	glNormal3f(1.0f, 0.0f, 0.0f);
	glVertex3f(1.0f, 1.0f, -1.0f);
	glVertex3f(1.0f, 1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);

	// LEFT
	glNormal3f(-1.0f, 0.0f, 0.0f);
	glVertex3f(-1.0f, 1.0f, 1.0f);
	glVertex3f(-1.0f, 1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
glEnd();
...
</code></pre>

<p>All that is left now is to add the lighting to our scene, which we do in the <b>WndProc</b> in our <b>WM_CHAR</b>, so we can turn the light on or off using lowercase or uppercase <b>L</b>.</p>

<pre><code>
...
case 'l':
case 'L':
	if (bLight == false) {
		bLight = true;
		glEnable(GL_LIGHTING);
	}
	else {
		bLight = false;
		glDisable(GL_LIGHTING);
	}
	break;
...
</code></pre>

<p>If you compile and run your program now, you'll see the cube is drawn as a completly white, unlit cube, or if you press <b>L</b> as lit by our lightsource.</p>





<h1><a name="lighting-pt2">LESSON 36 - Rendering light pt. 2</a></h1>
<h3>Introduction</h3>
<p>This time we'll go back to our rendering of a single lightsource, but this time we will add the material component to the lighting as well.</p>

<p>We'll declare the variables we need to handle the light and material in the global scope.</p>

<pre><code>
#include &lt;GL/glu.h&gt;
...
bool bLight = false;
GLUquadric* quadric = NULL;

GLfloat light_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat light_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat light_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat light_position[] = { 100.0f, 100.0f, 100.0f, 1.0f };

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f };
...
</code></pre>

<p>We use the boolean value to handle enabeling or disabeling the lighting in the scene. Then we use the GLU librarys quadric function to draw an object to be lit.</p>

<p>Now comes the interesting part: We define our lightings component with <b>light_ambient</b>, <b>light_diffuse</b>, <b>light_specular</b> and <b>light_position</b>. OpenGL treats this as the lightsource in the scene, and you can think of it as: </p>

<p id="note">Light independent of the object</p>

<p>Next we define the lighting material components with <b>material_ambient</b>, <b>material_diffuse</b>, <b>material_specular</b> and <b>material_shininess</b>. This is the component in the lighting that mixes with the lightsource to form a semi-realistic lighting model. Material can be thought of as: </p>

<p id="note">Lighting that resembles the object</p>

<p>We have to tell OpenGL that we want to enable lighting and material components, so add the following code to our <b>initialize</b>:</p>

<pre><code>
...
glEnable(GL_LIGHT0);
glEnable(GL_DEPTH_TEST);
glClearDepth(1.0f);
glDepthFunc(GL_LEQUAL);
glLightfv(GL_LIGHT0, GL_AMBIENT, light_ambient);
glLightfv(GL_LIGHT0, GL_DIFFUSE, light_diffuse);
glLightfv(GL_LIGHT0, GL_SPECULAR, light_specular);
glLightfv(GL_LIGHT0, GL_POSITION, light_position);
glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);
glShadeModel(GL_SMOOTH);
glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);
...
</code></pre>

<p>Nothing new, except for the various initialization of <b>glMaterialv(...)</b>.</p>

<p>Continuing on we define the <b>display</b> logic by adding: </p>

<pre><code>
...
glTranslatef(0.0f, 0.0f, -0.7f);
glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
quadric = gluNewQuadric();
gluSphere(quadric, 0.2f, 30.0f, 30.0f);
...
</code></pre>

<p>Short and simple; define the viewing position by traslating the view origin, tell OpenGL we want to draw filled polygons and handle the drawing of an object the GLU way - a sphere in this example.</p>

<p>Last but not least we give the user a way to enable / disable the lighting when pressing 'l' (or 'L') inside our <b>WndProc</b>:</p>

<pre><code>
...
case 'l':
case 'L':
	if (bLight == false) {
		bLight = true;
		glEnable(GL_LIGHTING);
	}
	else {
		bLight = false;
		glDisable(GL_LIGHTING);
	}
	break;
...
</code></pre>

<p>If you compile and run this program you should see a white sphere being drawn at the center of the screen, and it will turn into a grey-ish looking sphere with lighting, specular, reflection and material drawn on it when pressing <i>L</i>!</p>







<h1><a name="lighting-pt3">LESSON 37 - Rendering light pt. 3</a></h1>
<h3>Introduction</h3>
<p>In todays lecture we'll implement multiple lightsources into our program, so make a simple scene (a 3D triangle) with multiple lightsources.</p>

<p>Begin by adding a few variables in the global scope: </p>

<pre><code>
bool bLight = false;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
};

struct Light light[2] = {
	{ 
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{ 
		{ 0.0f, 0.0f, 0.0f, 1.0f }, 
		{ 0.0f, 0.0f, 1.0f, 1.0f }, 
		{ 0.0f, 0.0f, 1.0f, 1.0f }, 
		{ 2.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f };
</code></pre>

<p>We declare our boolean switch to enable or disable the lighting, then we add a <b>struct</b> to hold the positional data for the light source. After that we initialize the lighting data with a lightsource coming from the left and one from the right.</p>

<p id="note">The data you store in the struct holding the lighting data is declared in the same order as they were declared in the struct definition!</p>

<p>Then we initialize the lighting and depth functions for OpenGL to handle lighting correctly with the following variables in our <b>initialize</b>:</p>

<pre><code>
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_LEQUAL);
glShadeModel(GL_SMOOTH);
glClearDepth(1.0f);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);

glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);
glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);

glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);
glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);

glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);
</code></pre>

<p>To have something to shine a light on we have to add something in our <b>display</b> function, so we draw a 3 dimensional triangle with precalculated normals:</p>

<pre><code>
static float angle = 0.0f;
glTranslatef(0.0f, 0.0f, -7.0f);
glRotatef(angle, 0.0f, 1.0f, 0.0f);
glBegin(GL_TRIANGLES);
	glNormal3f(0.0f, 0.447214f, 0.894427f);
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);

	glNormal3f(0.894427f, 0.447214f, 0.0f);
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(1.0f, -1.0f, 1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);

	glNormal3f(0.0f, 0.447214f, -0.894427f);
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(1.0f, -1.0f, -1.0f);

	glNormal3f(-0.894427f, 0.447214f, 0.0f);
	glVertex3f(0.0f, 1.0f, 0.0f);
	glVertex3f(-1.0f, -1.0f, -1.0f);
	glVertex3f(-1.0f, -1.0f, 1.0f);
glEnd();

angle += 0.05f;
</code></pre>

<p>To end things off we add a user enabled switch to turn on or off the lightings in our <b>WndProc</b>:</p>

<pre><code>
case 'l':
case 'L':
	if (bLight == false) {
		bLight = true;
		glEnable(GL_LIGHTING);
	}
	else {
		bLight = false;
		glDisable(GL_LIGHTING);
	}
	break;
</code></pre>

<p>Just put it below any other <b>WM_CHAR</b> code you may already have in there.</p>

<p>If you compile and run the program you should see a white, rotating triangle, and if you press <b>l</b> or <b>L</b> it will be lit up with a red and a blue color coming from the left and right side of the triangle.</p>

<p>The entire code for this lesson is found below</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

bool bLight = false;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
};

struct Light light[2] = {
	{ 
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{ 
		{ 0.0f, 0.0f, 0.0f, 1.0f }, 
		{ 0.0f, 0.0f, 1.0f, 1.0f }, 
		{ 0.0f, 0.0f, 1.0f, 1.0f }, 
		{ 2.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f };

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'l':
		case 'L':
			if (bLight == false) {
				bLight = true;
				glEnable(GL_LIGHTING);
			}
			else {
				bLight = false;
				glDisable(GL_LIGHTING);
			}
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
	
	glEnable(GL_DEPTH_TEST);
	glDepthFunc(GL_LEQUAL);
	glShadeModel(GL_SMOOTH);
	glClearDepth(1.0f);
	glEnable(GL_LIGHT0);
	glEnable(GL_LIGHT1);

	glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
	glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);
	glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
	glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);

	glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
	glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);
	glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
	glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);

	glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
	glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
	glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
	glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	
	static float angle = 0.0f;
	glTranslatef(0.0f, 0.0f, -7.0f);
	glRotatef(angle, 0.0f, 1.0f, 0.0f);
	glBegin(GL_TRIANGLES);
		glNormal3f(0.0f, 0.447214f, 0.894427f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glVertex3f(-1.0f, -1.0f, 1.0f);
		glVertex3f(1.0f, -1.0f, 1.0f);

		glNormal3f(0.894427f, 0.447214f, 0.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glVertex3f(1.0f, -1.0f, 1.0f);
		glVertex3f(1.0f, -1.0f, -1.0f);

		glNormal3f(0.0f, 0.447214f, -0.894427f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glVertex3f(-1.0f, -1.0f, -1.0f);
		glVertex3f(1.0f, -1.0f, -1.0f);

		glNormal3f(-0.894427f, 0.447214f, 0.0f);
		glVertex3f(0.0f, 1.0f, 0.0f);
		glVertex3f(-1.0f, -1.0f, -1.0f);
		glVertex3f(-1.0f, -1.0f, 1.0f);
	glEnd();

	angle += 0.05f;

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>




<h1><a name="lighting-pt4">LESSON 38 - Rendering light pt. 4</a></h1>
<h3>Introduction</h3>
<p>In this lesson we'll again render muliple lightsources, but we'll begin adding transformation to the lightsources. We begin by declaring the variables we need in the global scope:</p>

<pre><code>
bool bLight = false;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
	GLfloat angle;
};

struct Light light[3] = {
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLUquadric* quadric = NULL;
GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f, 50.0f, 50.0f };
</code></pre>

<p>This time we add a variable to handle the angle that the light is pointing in, and initialize all the light variables by defining our <b>struct Light</b>. We'll also declare a sphere using <b>GLU</b> and define the material for lightsources.</p>  

<p>Now we initialize the lighting, the depth handling and shading model in our <b>initialize</b>:</p>

<pre><code>
...
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_LEQUAL);
glShadeModel(GL_SMOOTH);
glClearDepth(1.0f);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);
glEnable(GL_LIGHT2);

glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);

glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);

glLightfv(GL_LIGHT2, GL_AMBIENT, light[2].ambient);
glLightfv(GL_LIGHT2, GL_SPECULAR, light[2].specular);
glLightfv(GL_LIGHT2, GL_DIFFUSE, light[2].diffuse);

glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);

glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);
...
</code></pre>

<p>Filling in the <b>display</b> with the lighting, material and the model to be lit, we'll add some rotation to the lightsources, so they will move across the surface of the sphere:</p>

<p>First we instialize the camera angle using <b>gluLookAt</b> and setting it three units back, otherwise pointing in the direction of the object that's being lit.</p>

<p>Next we add a matrix transformation for the first light in the scene, and do the same for the remaining two.</p>

<p>In the end we increment the lightsources position by the floating value of 0.1 so they scan across the surface of the sphere.</p>

<pre><code>
...
glPushMatrix();
	gluLookAt(
		0.0f, 0.0f, 3.0f,
		0.0f, 0.0f, 0.0f,
		0.0f, 1.0f, 0.0f
	);
	glPushMatrix();
		glRotatef(light[0].angle, 1.0f, 0.0f, 0.0f);
		// Updating the position of the light[0], this is startig for the y-direction
		light[0].position[1] = light[0].angle;
		glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);
	glPopMatrix();

	glPushMatrix();
		glRotatef(light[1].angle, 0.0f, 1.0f, 0.0f);
		// Update the light[1] by a rotation, like above
		light[1].position[0] = light[1].angle;
		glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);
	glPopMatrix();
glPopMatrix();

glPushMatrix();
	glRotatef(light[2].angle, 0.0f, 0.0f, 1.0f);
	light[2].position[0] = light[2].angle;
	glLightfv(GL_LIGHT2, GL_POSITION, light[2].position);
glPopMatrix();

glPushMatrix();
	glTranslatef(0.0f, 0.0f, -0.7f);
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
	quadric = gluNewQuadric();
	gluSphere(quadric, 0.2f, 80.0f, 80.0f);
glPopMatrix();

light[0].angle += 0.1f;
light[1].angle += 0.1f;
light[2].angle += 0.1f; 
...
</code></pre>

<p>Go a head and compile your program, and you'll see an unlit, white sphere, but when you press <b>l</b> or <b>L</b> you'll add the lightsources we just added.</p>

<p id="note">The entire sourcecode for this project is found below:</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

bool bLight = false;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
	GLfloat angle;
};

struct Light light[3] = {
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },		// Red diffuse light
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },		// Green diffuse light
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },		// Blue diffuse light
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLUquadric* quadric = NULL;
GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f, 50.0f, 50.0f };

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'l':
		case 'L':
			if (bLight == false) {
				bLight = true;
				glEnable(GL_LIGHTING);
			}
			else {
				bLight = false;
				glDisable(GL_LIGHTING);
			}
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	// LESSON 38
	glEnable(GL_DEPTH_TEST);
	glDepthFunc(GL_LEQUAL);
	glShadeModel(GL_SMOOTH);
	glClearDepth(1.0f);
	glEnable(GL_LIGHT0);
	glEnable(GL_LIGHT1);
	glEnable(GL_LIGHT2);

	glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
	glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
	glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);

	glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
	glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
	glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);

	glLightfv(GL_LIGHT2, GL_AMBIENT, light[2].ambient);
	glLightfv(GL_LIGHT2, GL_SPECULAR, light[2].specular);
	glLightfv(GL_LIGHT2, GL_DIFFUSE, light[2].diffuse);

	glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
	glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
	glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
	glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);
	
	glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	glPushMatrix();
		gluLookAt(
			0.0f, 0.0f, 3.0f,
			0.0f, 0.0f, 0.0f,
			0.0f, 1.0f, 0.0f
		);
		glPushMatrix();
			glRotatef(light[0].angle, 1.0f, 0.0f, 0.0f);
			// Updating the position of the light[0], this is startig for the y-direction
			light[0].position[1] = light[0].angle;
			glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);
		glPopMatrix();

		glPushMatrix();
			glRotatef(light[1].angle, 0.0f, 1.0f, 0.0f);
			// Update the light[1] by a rotation, like above
			light[1].position[0] = light[1].angle;
			glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);
		glPopMatrix();
	glPopMatrix();

	glPushMatrix();
		glRotatef(light[2].angle, 0.0f, 0.0f, 1.0f);
		light[2].position[0] = light[2].angle;
		glLightfv(GL_LIGHT2, GL_POSITION, light[2].position);
	glPopMatrix();

	glPushMatrix();
		glTranslatef(0.0f, 0.0f, -0.7f);
		glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
		quadric = gluNewQuadric();
		gluSphere(quadric, 0.2f, 80.0f, 80.0f);
	glPopMatrix();

	light[0].angle += 0.1f;
	light[1].angle += 0.1f;
	light[2].angle += 0.1f; 

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>




<h1><a name="texture-sphere">LESSON 39 - Texturing a sphere</a></h1>
<h3>Introduction</h3>
<p>A normal is a perpendicular vector to each vertex. If you want to find the normals of any object, which is perpendicular to each side. </p>

<p>In Fixed Function Pipeline we can only give normals for one front (in a qube, one normal for four vertices), while in a programmable pipeline you can define a normal per vertex. This is the difference between FFP and PP.</p>

<p>A vector is something that represents a direction and a length.</p>

<p>Whenever you give a normal, the length doesn't matter, but the direction does.</p>

light                 O
      normal 	  |	/   	 { source light }
				  |/
surface        ----

<h3>Why do we need a normal?</h3>

<p>The normal tells us (how much reflection the light causes) what angle the light source is hits. (also for reflections).</p>

<p>1) What OpenGL does for us internally?</p>
<p>a) You give the position of the light. eg: { 100, 100, 100, 1 }</p>
<p>1 is a direction. 0 is a position.</p>
<p>OpenGL will convert this positional vector and store it</p>
<p>b) You give the normal</p>
<p>OpenGL will check the angle of the position vector with the normal and apply dot product internally.</p>
<p>Dot product and cross product is for multiplying two vector.</p>

<p>Cross prod. used to derive the normals to give the perpendicular vector of the two vectors.</p>
<p>Dot prod. give the effect of one vector on another vector (for finding the length).</p>

<p>Dot prod: <var>a x b x cos &theta;</var>. a = the normal light, b = the source light, theta is angle between the vectors.</p>
<p>This dot product will determine the impact of light on that particular vertex.</p>
<p>Bigger the angle, the impact of light on a object decreases, while smaller angle increases.</p>

<p>Cross prod: formula <var>a x b sin &theta;</var></p>


<p>Now lets start implementing the code we need to texture a shpere.</p>

<p>We need to include <b>math.h</b> and add a resource file to hold the textures, so add the following into the include section:</p>

<pre><code>
...
#define _USE_MATH_DEFINES 1
#include &lt;math.h&gt;
#include "texture.h"
...
</code></pre>

<p>Next we need a function prototype to generate a shpere, and some function prototypes and variables from some previous lessons: </p>

<pre><code>
...
void draw_sphere(float, int);
bool load_texture(GLuint*, TCHAR[]);
bool bLight = false;
GLuint texture;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
	GLfloat angle;
};

struct Light light[3] = {
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f, 50.0f, 50.0f };

...
</code></pre>

<p>We also want to be able to switch the lighting on and off, so we make a user defined switch inside WndProc:</p>

<pre><code>
case 'l':
case 'L':
	if (bLight == false) {
		bLight = true;
		glEnable(GL_LIGHTING);
	}
	else {
		bLight = false;
		glDisable(GL_LIGHTING);
	}
	break;
}
</code></pre>

<p>Then we enable ligthing and texture etc in initialize:</p>

<pre><code>
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_LEQUAL);
glShadeModel(GL_SMOOTH);
glClearDepth(1.0f);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);
glEnable(GL_LIGHT2);
glEnable(GL_TEXTURE_2D);

glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);

glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);

glLightfv(GL_LIGHT2, GL_AMBIENT, light[2].ambient);
glLightfv(GL_LIGHT2, GL_SPECULAR, light[2].specular);
glLightfv(GL_LIGHT2, GL_DIFFUSE, light[2].diffuse);

glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);

glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);

resize(800, 600);
load_texture(&texture, MAKEINTRESOURCE(IDBITMAP_TEXTURE));
</code></pre>

<p>Then we update the <b>draw_sphere</b> function and add the <b>load_texture</b>:</p>

<p id="note">Add a writeup on the formula in <b>draw_sphere</b> the handles applying texturing to the sphere (marked LESSON 38 in the function definition)
Source: <a href="https://denigma.app/" target="_blank">https://denigma.app/</a><br/>
- The code is a function that draws a sphere with radius r and center at the origin of the coordinate system.<br/>
- The code starts by checking if the radius is less than 0.<br/>
- If it is, then the radius will be set to -r. Next, n is checked to see if it's less than 4 or r &lt;= 0.<br/>
- If either of these are true, then a triangle will not be drawn and the function returns without drawing anything.<br/>
- The next part of the code loops through each side of a triangle that has been drawn in order to draw two more points on top of them using GL_TRIANGLE_STRIP and calculates their coordinates with respect to phi1<br/>
and phi2 which are calculated from M_PI * 2 / n for each point where j = 0 and j + 1 respectively.<br/>
- Then they're all drawn with GL_TRIANGLE_STRIP before finally being moved back into place by calculating their new coordinates based on sin(theta) * cos(phi1) and sin(theta) * sin(phi1).<br/>
</p>

<pre><code>
void draw_sphere(float r, int n)
{
	int i, j;
	GLdouble phi1, phi2, theta, s, t;
	GLfloat ex, ey, ez;
	GLfloat px, py, pz;

	if (r < 0) r = -r;
	if (n < 0) n = -n;
	// Since triangle only has three sides...
	if (n < 4 || r <= 0) {
		// Calculates the origon of the circle
		glBegin(GL_POINTS);
			glVertex3f(0.0f, 0.0f, 0.0f);
		glEnd();
		return;
	}

	for (j = 0; j < n; j++) {
		phi1 = j * M_PI * 2 / n;
		phi2 = (j + 1) * M_PI * 2 / n;
		// Calculates two more points, and draws it using GL_TRINGLE_STRIP, then moves phi1
		glBegin(GL_TRIANGLE_STRIP);
		for (i = 0; i <= n; i++) {
			theta = i * M_PI / n;
			ex = sin(theta) * cos(phi2);
			ey = sin(theta) * sin(phi2);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi2 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);
			
			glVertex3f(px, py, pz);

			ex = sin(theta) * cos(phi1);
			ey = sin(theta) * sin(phi1);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi1 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);
			
			glVertex3f(px, py, pz);
		}
		glEnd();
	}
}

bool load_texture(GLuint* texture, TCHAR imageResourceId[])
{
	HBITMAP bitmap = NULL;
	BITMAP bmp;
	bool bStatus = false;
	bitmap = LoadImage(GetModuleHandle(NULL), imageResourceId, IMAGE_BITMAP, 0, 0, LR_CREATEDIBSECTION);

	if (bitmap != NULL) {
		GetObject(bitmap, sizeof(BITMAP), &bmp);
		glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
		// Generate texture
		glGenTextures(1, texture);
		glBindTexture(GL_TEXTURE_2D, *texture);
		// Texture filtering
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
		// Texture wrapping
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_NEAREST);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_NEAREST);
		gluBuild2DMipmaps(GL_TEXTURE_2D, 3, bmp.bmWidth, bmp.bmHeight, GL_BGR_EXT, GL_UNSIGNED_BYTE, bmp.bmBits);
		DeleteObject(bitmap);
		bStatus = true;
	}

	return bStatus;
}
</code></pre>

<p>Add the following into <b>display</b> to draw a sphere, with texture (see <b>lesson 22</b> for details on how to add textures): </p>

<pre><code>
...
glTranslatef(0.0f, 0.0f, -3.0f);
static float rotation = 1.0f;
glRotatef(rotation, 0.0f, 1.0f, 1.0f);
rotation += 0.1f;
draw_sphere(1.0f, 60);


glPushMatrix();
	gluLookAt(
		0.0f, 0.0f, 3.0f,
		0.0f, 0.0f, 0.0f,
		0.0f, 1.0f, 0.0f
	);
	glPushMatrix();
		glRotatef(light[0].angle, 1.0f, 0.0f, 0.0f);
		// Updating the position of the light[0], this is startig for the y-direction
		light[0].position[1] = light[0].angle;
		glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);
	glPopMatrix();

	glPushMatrix();
		glRotatef(light[1].angle, 0.0f, 1.0f, 0.0f);
		// Update the light[1] by a rotation, like above
		light[1].position[0] = light[1].angle;
		glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);
	glPopMatrix();
glPopMatrix();

glPushMatrix();
	glRotatef(light[2].angle, 0.0f, 0.0f, 1.0f);
	light[2].position[0] = light[2].angle;
	glLightfv(GL_LIGHT2, GL_POSITION, light[2].position);
glPopMatrix();

glPushMatrix();
	glTranslatef(0.0f, 0.0f, -0.7f);
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
glPopMatrix();

light[0].angle += 0.1f;
light[1].angle += 0.1f;
light[2].angle += 0.1f;
...
</code></pre>

<p>And just like that we now have a textured sphere with three lighting sources translating over it!</p>

<p>Entire code: </p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#define _USE_MATH_DEFINES 1
#include &lt;math.h&gt;
#include "texture.h"
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

// LESSON 38
void draw_sphere(float, int);
bool load_texture(GLuint*, TCHAR[]);
bool bLight = false;
GLuint texture;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
	GLfloat angle;
};

struct Light light[3] = {
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f, 50.0f, 50.0f };

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'l':
		case 'L':
			if (bLight == false) {
				bLight = true;
				glEnable(GL_LIGHTING);
			}
			else {
				bLight = false;
				glDisable(GL_LIGHTING);
			}
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	glEnable(GL_DEPTH_TEST);
	glDepthFunc(GL_LEQUAL);
	glShadeModel(GL_SMOOTH);
	glClearDepth(1.0f);
	glEnable(GL_LIGHT0);
	glEnable(GL_LIGHT1);
	glEnable(GL_LIGHT2);
	glEnable(GL_TEXTURE_2D);

	glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
	glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
	glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);

	glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
	glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
	glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);

	glLightfv(GL_LIGHT2, GL_AMBIENT, light[2].ambient);
	glLightfv(GL_LIGHT2, GL_SPECULAR, light[2].specular);
	glLightfv(GL_LIGHT2, GL_DIFFUSE, light[2].diffuse);

	glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
	glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
	glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
	glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);

	glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);
	
	resize(800, 600);
	load_texture(&texture, MAKEINTRESOURCE(IDBITMAP_TEXTURE));

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	glTranslatef(0.0f, 0.0f, -3.0f);
	static float rotation = 1.0f;
	glRotatef(rotation, 0.0f, 1.0f, 1.0f);
	rotation += 0.1f;
	draw_sphere(1.0f, 60);


	glPushMatrix();
		gluLookAt(
			0.0f, 0.0f, 3.0f,
			0.0f, 0.0f, 0.0f,
			0.0f, 1.0f, 0.0f
		);
		glPushMatrix();
			glRotatef(light[0].angle, 1.0f, 0.0f, 0.0f);
			// Updating the position of the light[0], this is startig for the y-direction
			light[0].position[1] = light[0].angle;
			glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);
		glPopMatrix();

		glPushMatrix();
			glRotatef(light[1].angle, 0.0f, 1.0f, 0.0f);
			// Update the light[1] by a rotation, like above
			light[1].position[0] = light[1].angle;
			glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);
		glPopMatrix();
	glPopMatrix();

	glPushMatrix();
		glRotatef(light[2].angle, 0.0f, 0.0f, 1.0f);
		light[2].position[0] = light[2].angle;
		glLightfv(GL_LIGHT2, GL_POSITION, light[2].position);
	glPopMatrix();

	glPushMatrix();
		glTranslatef(0.0f, 0.0f, -0.7f);
		glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
	glPopMatrix();

	light[0].angle += 0.1f;
	light[1].angle += 0.1f;
	light[2].angle += 0.1f;

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}

void draw_sphere(float r, int n)
{
	int i, j;
	GLdouble phi1, phi2, theta, s, t;
	GLfloat ex, ey, ez;
	GLfloat px, py, pz;

	if (r < 0) r = -r;
	if (n < 0) n = -n;
	// Since triangle only has three sides...
	if (n < 4 || r <= 0) {
		// Calculates the origon of the circle
		glBegin(GL_POINTS);
			glVertex3f(0.0f, 0.0f, 0.0f);
		glEnd();
		return;
	}

	for (j = 0; j < n; j++) {
		phi1 = j * M_PI * 2 / n;
		phi2 = (j + 1) * M_PI * 2 / n;
		// Calculates two more points, and draws it using GL_TRINGLE_STRIP, then moves phi1
		glBegin(GL_TRIANGLE_STRIP);
		for (i = 0; i <= n; i++) {
			theta = i * M_PI / n;
			ex = sin(theta) * cos(phi2);
			ey = sin(theta) * sin(phi2);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi2 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);
			
			glVertex3f(px, py, pz);

			ex = sin(theta) * cos(phi1);
			ey = sin(theta) * sin(phi1);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi1 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);
			
			glVertex3f(px, py, pz);
		}
		glEnd();
	}
}

bool load_texture(GLuint* texture, TCHAR imageResourceId[])
{
	HBITMAP bitmap = NULL;
	BITMAP bmp;
	bool bStatus = false;
	bitmap = LoadImage(GetModuleHandle(NULL), imageResourceId, IMAGE_BITMAP, 0, 0, LR_CREATEDIBSECTION);

	if (bitmap != NULL) {
		GetObject(bitmap, sizeof(BITMAP), &bmp);
		glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
		// Generate texture
		glGenTextures(1, texture);
		glBindTexture(GL_TEXTURE_2D, *texture);
		// Texture filtering
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
		// Texture wrapping
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_NEAREST);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_NEAREST);
		gluBuild2DMipmaps(GL_TEXTURE_2D, 3, bmp.bmWidth, bmp.bmHeight, GL_BGR_EXT, GL_UNSIGNED_BYTE, bmp.bmBits);
		DeleteObject(bitmap);
		bStatus = true;
	}

	return bStatus;
}
</code></pre>
</details>



<h1><a name="fog-effect">LESSON 40 - Implementing fog</a></h1>
<h3>Introduction</h3>
<p>This lesson will focus on adding fog to give your scene some ambience. Let's dive into it!</p>

<p>Begin by adding some global variables to use to set up the fog:</p>

<pre><code>
...
bool g_pressed;				// Switch variable to enable or disable fog
GLuint fog_mode[] = {			// Storage variable for three types of fog
	GL_EXP,	
	GL_EXP2, 
	GL_LINEAR
};

GLuint fog_filter = 0;			// Which filter to use
GLfloat fog_color[4] = {		// Color of the fog
	0.5f, 0.5f, 0.5f, 1.0f
};
...
</code></pre>

<p>Now enable the fog inside your <b>display</b>:</p>

<pre><code>
glFogi(GL_FOG_MODE, fog_mode[fog_filter]);		// Fog mode - EXP, EXP2 or LINEAR
glFogfv(GL_FOG_COLOR, fog_color);			// Fog color
glFogf(GL_FOG_DENSITY, 0.25f);				// Fog density
glHint(GL_FOG_HINT, GL_DONT_CARE);			// More spesification (how the fog should look...)
glFogf(GL_FOG_START, 1.0f);				// Fog application based on the Z-value of the depth buffer
glFogf(GL_FOG_END, 15.0f);				// How deep into the Z-axis the fog should be rendered
</code></pre>

<p>Lastly we add the switch to turn fog on or off by placing the following in your <b>WndProc</b>: </p>

<pre><code>
...
case 'g':
case 'G':
	if (g_pressed == false) {
		g_pressed = true;
		fog_filter += 1;				// Increment the fog_filter
		if (fog_filter &gt; 2) {
			fog_filter = 0;				// Resetting the fog_filter
		}
		glEnable(GL_FOG);				// Enabling the internal statemachine of OpenGL
		glFogi(GL_FOG_MODE, fog_mode[fog_filter]);	// Switch through the various fog_filter
	}
	break;
...
</code></pre>

<p>Compile and run the program, then press <b>g</b> to enable the fog!</p>

<p>Complete code example: </p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;gl/glu.h&gt;
#include &lt;stdbool.h&gt;
#define _USE_MATH_DEFINES 1
#include &lt;math.h&gt;
// #include "texture.h"
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "glu32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

// LESSON 40
bool g_pressed;				// Switch to enable / disable fog
GLuint fog_mode[] = {			// Storage for three type of fog
	GL_EXP,	
	GL_EXP2, 
	GL_LINEAR
};

GLuint fog_filter = 0;			// Which filter to use
GLfloat fog_color[4] = {		// Color of the fog
	0.5f, 0.5f, 0.5f, 1.0f
};

// LESSON 38
void draw_sphere(float, int);
bool load_texture(GLuint*, TCHAR[]);
bool bLight = false;
GLuint texture;

struct Light {
	GLfloat ambient[4];
	GLfloat diffuse[4];
	GLfloat specular[4];
	GLfloat position[4];
	GLfloat angle;
};

struct Light light[3] = {
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ 1.0f, 0.0f, 0.0f, 1.0f },
		{ -2.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 1.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	},
	{
		{ 0.0f, 0.0f, 0.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 1.0f, 1.0f },
		{ 0.0f, 0.0f, 0.0f, 1.0f }
	}
};

GLfloat material_ambient[] = { 0.0f, 0.0f, 0.0f, 1.0f };
GLfloat material_diffuse[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_specular[] = { 1.0f, 1.0f, 1.0f, 1.0f };
GLfloat material_shininess[] = { 50.0f, 50.0f, 50.0f };

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		case 'l':
		case 'L':
			if (bLight == false) {
				bLight = true;
				glEnable(GL_LIGHTING);
			}
			else {
				bLight = false;
				glDisable(GL_LIGHTING);
			}
			break;
		case 'g':
		case 'G':
			if (g_pressed == false) {
				g_pressed = true;
				fog_filter += 1;				// Increment the fog_filter
				if (fog_filter > 2) {
					fog_filter = 0;				// Resetting the fog_filter
				}
				glEnable(GL_FOG);				// Enabling the internal statemachine of OpenGL
				glFogi(GL_FOG_MODE, fog_mode[fog_filter]);	// Switch through the various fog_filter
			}
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	glEnable(GL_DEPTH_TEST);
	glDepthFunc(GL_LEQUAL);
	glShadeModel(GL_SMOOTH);
	glClearDepth(1.0f);
	glEnable(GL_LIGHT0);
	glEnable(GL_LIGHT1);
	glEnable(GL_LIGHT2);
	glEnable(GL_TEXTURE_2D);

	glLightfv(GL_LIGHT0, GL_AMBIENT, light[0].ambient);
	glLightfv(GL_LIGHT0, GL_SPECULAR, light[0].specular);
	glLightfv(GL_LIGHT0, GL_DIFFUSE, light[0].diffuse);

	glLightfv(GL_LIGHT1, GL_AMBIENT, light[1].ambient);
	glLightfv(GL_LIGHT1, GL_SPECULAR, light[1].specular);
	glLightfv(GL_LIGHT1, GL_DIFFUSE, light[1].diffuse);

	glLightfv(GL_LIGHT2, GL_AMBIENT, light[2].ambient);
	glLightfv(GL_LIGHT2, GL_SPECULAR, light[2].specular);
	glLightfv(GL_LIGHT2, GL_DIFFUSE, light[2].diffuse);

	glMaterialfv(GL_FRONT, GL_AMBIENT, material_ambient);
	glMaterialfv(GL_FRONT, GL_DIFFUSE, material_diffuse);
	glMaterialfv(GL_FRONT, GL_SPECULAR, material_specular);
	glMaterialfv(GL_FRONT, GL_SHININESS, material_shininess);

	glHint(GL_PERSPECTIVE_CORRECTION_HINT, GL_NICEST);

	resize(800, 600);
	// load_texture(&texture, MAKEINTRESOURCE(IDBITMAP_TEXTURE));

	// LESSON 40
	//glFogi(GL_FOG_MODE, fog_mode[fog_filter]);
	//glFogfv(GL_FOG_COLOR, fog_color);
	//glFogf(GL_FOG_DENSITY, 2.25f);
	//glHint(GL_FOG_HINT, GL_DONT_CARE);
	//glFogf(GL_FOG_START, 1.0f);
	//glFogf(GL_FOG_END, 15.0f);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();

	gluPerspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
	
	// LESSON 40
	glFogi(GL_FOG_MODE, fog_mode[fog_filter]);		// Fog mode - EXP, EXP2 or LINEAR
	glFogfv(GL_FOG_COLOR, fog_color);			// Fog color
	glFogf(GL_FOG_DENSITY, 0.25f);				// Fog density
	glHint(GL_FOG_HINT, GL_DONT_CARE);			// More spesification (how the fog should look...)
	glFogf(GL_FOG_START, 1.0f);				// Fog application based on the Z-value of the depth buffer
	glFogf(GL_FOG_END, 15.0f);				// How deep into the Z-axis the fog should be rendered

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	glTranslatef(0.0f, 0.0f, -3.0f);
	static float rotation = 1.0f;
	glRotatef(rotation, 0.0f, 1.0f, 1.0f);
	rotation += 0.1f;
	draw_sphere(1.0f, 60);

	glPushMatrix();
	gluLookAt(
		0.0f, 0.0f, 3.0f,
		0.0f, 0.0f, 0.0f,
		0.0f, 1.0f, 0.0f
	);
	glPushMatrix();
	glRotatef(light[0].angle, 1.0f, 0.0f, 0.0f);
	// Updating the position of the light[0], this is startig for the y-direction
	light[0].position[1] = light[0].angle;
	glLightfv(GL_LIGHT0, GL_POSITION, light[0].position);
	glPopMatrix();

	glPushMatrix();
	glRotatef(light[1].angle, 0.0f, 1.0f, 0.0f);
	// Update the light[1] by a rotation, like above
	light[1].position[0] = light[1].angle;
	glLightfv(GL_LIGHT1, GL_POSITION, light[1].position);
	glPopMatrix();
	glPopMatrix();

	glPushMatrix();
	glRotatef(light[2].angle, 0.0f, 0.0f, 1.0f);
	light[2].position[0] = light[2].angle;
	glLightfv(GL_LIGHT2, GL_POSITION, light[2].position);
	glPopMatrix();

	glPushMatrix();
	glTranslatef(0.0f, 0.0f, -0.7f);
	glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);
	glPopMatrix();

	light[0].angle += 0.1f;
	light[1].angle += 0.1f;
	light[2].angle += 0.1f;

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}

void draw_sphere(float r, int n)
{
	int i, j;
	GLdouble phi1, phi2, theta, s, t;
	GLfloat ex, ey, ez;
	GLfloat px, py, pz;

	if (r < 0) r = -r;
	if (n < 0) n = -n;
	// Since triangle only has three sides...
	if (n < 4 || r <= 0) {
		// Calculates the origon of the circle
		glBegin(GL_POINTS);
		glVertex3f(0.0f, 0.0f, 0.0f);
		glEnd();
		return;
	}

	for (j = 0; j < n; j++) {
		phi1 = j * M_PI * 2 / n;
		phi2 = (j + 1) * M_PI * 2 / n;
		// Calculates two more points, and draws it using GL_TRINGLE_STRIP, then moves phi1
		glBegin(GL_TRIANGLE_STRIP);
		for (i = 0; i <= n; i++) {
			theta = i * M_PI / n;
			ex = sin(theta) * cos(phi2);
			ey = sin(theta) * sin(phi2);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi2 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);

			glVertex3f(px, py, pz);

			ex = sin(theta) * cos(phi1);
			ey = sin(theta) * sin(phi1);
			ez = cos(theta);
			px = r * ex;
			py = r * ey;
			pz = r * ez;
			// LESSON 38
			s = phi1 / (M_PI * 2);
			t = 1 - (theta / M_PI);
			glTexCoord2f(s, t);
			glNormal3f(ex, ey, ez);

			glVertex3f(px, py, pz);
		}
		glEnd();
	}
}

bool load_texture(GLuint* texture, TCHAR imageResourceId[])
{
	HBITMAP bitmap = NULL;
	BITMAP bmp;
	bool bStatus = false;
	bitmap = LoadImage(GetModuleHandle(NULL), imageResourceId, IMAGE_BITMAP, 0, 0, LR_CREATEDIBSECTION);

	if (bitmap != NULL) {
		GetObject(bitmap, sizeof(BITMAP), &bmp);
		glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
		// Generate texture
		glGenTextures(1, texture);
		glBindTexture(GL_TEXTURE_2D, *texture);
		// Texture filtering
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
		// Texture wrapping
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_NEAREST);
		glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_NEAREST);
		gluBuild2DMipmaps(GL_TEXTURE_2D, 3, bmp.bmWidth, bmp.bmHeight, GL_BGR_EXT, GL_UNSIGNED_BYTE, bmp.bmBits);
		DeleteObject(bitmap);
		bStatus = true;
	}

	return bStatus;
}
</code></pre>
</details>




<h1><a name="improved-rendering">LESSON 41 - Improving draw calls and texture tiling</a></h1>
<h3>Introduction</h3>
<p>To repeatedly load a seamless texture OpenGL uses texture tiling, as demonstrated in the example code beneath: </p>

<pre><code>
glBegin(GL_QUADS);
	// Texture tiling
	glTexCoord2f(50.0f, 50.0f); 
	glVertex2f(1.0f, 1.0f);

	glTexCoord2f(0.0f, 50.0f);
	glVertex2f(-1.0f, 1.0f);

	glTexCoord2f(0.0f, 0.0f);
	glVertex2f(-1.0f, -1.0f);

	glTexCoord2f(50.0f, 0.0f);
	glVertex2f(1.0f, -1.0f);
glEnd();
</code></pre>

<p>A good practice of making drawcalls in OpenGL is to avoid looping, like a for() or while()-loop.</p>




<h1><a name="revisiting-fixed-functional-pipeline">LESSON 42 - Revisiting the Fixed Funtional Pipeline (Summary of legacy OpenGL)</a></h1>
<h3>Introduction</h3>
<p>CPU - RAM - HDD - GPU</p>

<p>The program and instructions are loaded from the HDD to the RAM. CPU then handles the instructions that are called (and executes them), the CPU calls the device driver for your GPU which renders in the VRAM (attached to the framebuffer).</p>

<p>There are two types of pipelines: Fixed Functional Pipeline, or a Programmable Pipeline (which is an extension of the FFP adding shaders).</p>

<p>FFP: You can't controll over the data, you just pass it to the pipeline which has predefined stages.</p>

<pre><code>
1. Pre-vertex Stage - You pass the vertices to the pipeline
2. Vertex Stage 
a. Transformation 
   a) Position (in x, y and x-axis)
   b) Rotation ()
   c) Scaling
Our vertices are in the local space.

Everything in Computer Graphcis is Matrix. 

a) Local Space will multiply it to Transformation Matrix and this will result in the Model Matrix.
b) Camera - Model matrix will get multiplied with camera (lookAt) matrix and will result in ModelView Space matrix.
c) ModelView Space matrix gets multiplied with the Projection Matrix and will result in Clip Space
 

3. Post Vertex Stage
a) Primitive Assembly 
b) Viewport clipping / mapping
c) Perspective divide &rarr; culling

4) Rasterizer Stage
5) Fragment Stage
6) Per Framebuffer tests
   a) Pixel Ownership
   b) Scissor tests
   c) Blend tests
   d) Depth tests
   e) Logic op
   f) Stencil tests
   g) Dithering tests
   h) Alpha tests
   

</code></pre>




<h1><a name="programmable-pipeline-pt1">LESSON 43 - Programmable pipelines pt. 1</a></h1>
<h3>Introduction</h3>
<p>Pipeline has an order. There are two types of rendering; realtime rendering and offline rendering.</p>

<p>Realtime rendering occures in real time and is handled in code, unlike offline rendering, which is pre-rendered and stored in eg. a videoformat and displayed by a video player.</p>

<h3>Attributes for the pipeline</h3>
<p>Vertices, Normals, Texture coordinates &rarr; added into the pipeline.</p>

<p>Vertices: Is just a point inside the space...</p>

<p>1. Vertex spesification: Here you give the vertices as an input.</p>

<p>The vertex is inside pipeline</p>

<p>a) Transformation (Order doesn't matter here)</p>
<p>1: Translate 2: Rotate 3: Scale</p>

<h3>Projection</h3>
<p>two types - orthographic (bounding box) and perspective (v-shape viewfrustum) - perspective is a (fake) volume in "3D" projected onto a 2D screen.</p>

<p>Orthographic: ()</p>

<p>Matrix: Only way to store the 3D volume. It's basically an array (2D or 3D).</p>

<p>Vertex gets multiplied with the (internal matrix of...) translate, rotate and scale. Here the order matter.</p>

<p>It will result into the world matrix. (The result of the vertex matrix multiplied by the translate, rotate, scale matrix)</p>

<p>Now you define the view (if you don't it gets set to <b>{0, 0, 0}</b>).</p>

<p>World matrix will get multiplied with the camera matrix and will result in the World View Matrix</p>

<p>World View Matrix will get multiplied with the Projection Matrix and will result in the Clip Matrix.</p>

<p>A transformation is the journey of a vertice from it's local space to the clip space.</p>

<p>Local Space &rarr; World Space &rarr; World View Space &rarr; Clip Space</p>

<p>All this is the work of the VERTEX SHADER.</p>





<h1><a name="programmable-pipeline-pt2">LESSON 44 - Programmable pipelines pt. 2</a></h1>
<h3>Introduction</h3>
<p>Difference between legacy and modern OpenGL is the introduction of shaders and programmable pipelines.</p>

<p>Rendering flow is the transformation of vertices *MUST / textures coords / normals (attributes - basic raw data passed to the pipeline).</p>

<h3>Pre Vertex Stage</h3>
<pre><code>
- You are passing attributes to the Pipeline
  Attributes - Vertices, Normals, Color, Texture Coordinates
</code></pre>

<p id="note"><b>RULES</b> :- There are two compulsary shaders - Vertex and Fragment</p>

<h3>Vertex Stage</h3>
<pre><code>
a) All the data is passed the Vertex Shader
   Shader is a program that runs on the GPU (why render on GPU over the CPU)
   Every shader has a spesific task or motive
   
   Vertex shaders runs PER Vertex
   If there are three vertices to render a Trinagle. It will run three times.
   
b) Usng that data, Vertex shader will preform Transformation

There are three types of transformation - Translate, Rotate and Scale

These Translate, Rotate and Scale are the Matrices.

Why Matrix ? Represent 3D data {into Matrix Container}[...].

Vertices which you have passed to the vertex shader gets multiplied with Transformation Matrix
and will result in Model Space

<b>vPosition * translateMatrix = ModelSpace;</b>

<b>CameraMatrix * ModelSpace = Model-View Matrix;</b>

<i>(Define Orthographic or Projection )</i>

<b>ProjectionMatrix * Model-View Matrix = Clip Space;</b>
</code></pre>

<p id="note">Clip Space is the return type or value of the VERTEX SHADER.</p>

<h3>CPU has 8 Cores (i7 processor) vs GPU - RTX 2060 (1920 cuda cores)</h3>
<p></p>

<pre><code>
CPU (5 cores)
+-----------+
|+---------+|
|| ++	++ ||
|| ++	++ ||
|+---------+|
+-----------+

GPU (1920 cores)
+-----------+
|||||||||||||
|||||||||||||
|||||||||||||
|||||||||||||
+-----------+
</code></pre>

<h3>How do you pass data to any Shader?</h3>
<p>By using the 'in' keyword</p>

<p>Example - <b>in vec3 vPosition;</b></p>

<h3>Post Vertex Processing Stage</h3>

<p></p>

<pre><code>
  a) Primitive Assembly ? - What geometry do you wish to render? Eg. Triangle, Line, Point, LineLoop, LineStrip
  b) Viewport Clipping  ? - See illustration below (Viewport clipping)
  c) Perspective Divide ? - What Homogenous coordinates? Cartesian coordinates (x, y, z axis bound)
  d) Face Culling       ? - Back-face culling (disable or enable to avoid rendering unecessary objects)
  
[2,3]
x = 2 and y = 3 (Cartesian)
[2,3,w] where w can be either 0 or 1
Conversion of cartesion to homogenous 

<b>x/w and y/w</b>
2/1 and 3/1 = [2,3]
what if w = 0?
2/0 and 3/0 = inifinity
</code></pre>

<p>All this is frustum calculation...</p>

<pre><code>
+---------------+
|		|
|		|
|      /\   	|
+-----/..\------|
     /____\

Viewport clipping
</code></pre>


<h3>Rasterization</h3>
<p>Create potential pixels... this stage isn't programmable!</p>





<h1><a name="programmable-pipeline-pt3">LESSON 45 - Programmable pipeline pt. 3</a></h1>
<h3>Introduction</h3>
<p>Shaders are: GLSL is a C-based programming language to handle vertices and transfer it into the pipeline.</p>

<p>The viewing matrix is considered the view projection. Two types - orthographic and projection</p>

<p>Vertex shader returns the clip space (keyword is gl_Position, available even to the Fragment shaders)...</p>

<p>Post Vertex Stage: primitive assembly - viewport clipping(discarding object outside of the viewporr)</p>

<p>Perspective divide (homogenous coordinate (adds the w) &rarr; cartesian coordinate).</p>

<p>Face Culling (Hints of- or remove "hidden" sides). It's an optimisation in the renderer.</p>

<p>Rasterizer: Creates a potential pixel. The "brain" or logic where all primitives are rendered.</p>

<p>Fragment Shader Stage: whatever pixels are in the Fragment shader is colored by this stage.</p>

<p>Vertex Shader: runs once pr vertex, Fragment Shader: runs once pr fragment</p>

<p>Main job for Fragment Shader is to color each pixel.</p>

<p>Two optional shaders: Geometry shader and Tesselation shader.</p>

<p>Geometry Shader (creates multiple objects out of a single object).</p>

<p>Tesselation Shader: (add or increase details to a object (stiching...))</p>

<pre><code>
PER FRAGMENT STAGE (PER SAMPLE PROCESSING)

1) 	SCISSOR TEST
	+---------------------------+
	|  +--+	 	  .				|
	|  +--+       /\			|
	+---------------------------+
	
	Inside a viewport you can cull out an object if needed.
2)  DEPTH TEST (happens inside the pipeline)

	Testing the z-values on fragments

3)	PIXEL OWNERSHIP TEST

	If a pixel is hidden by a window the Pixel Ownership Test will fail this stage
	
4) 	BLENDING TEST 
	
	Alpha blending is handled in the pipeline (front object is transparemt- objects behind should be visible)

5) 	LOGICAL OPERATIONS
	
	All the bitwise operations are handled by the pipeline
	
6) 	DITHERING  TEST (WRITE MASK)

	Image processing algorithm to intenionally apply noise (handled by OpenGL internatlly.
	
7) 	STENCIL TEST

	We'll get back to this stage (advanced ...)
</code></pre>

<p>If a pixel returns from all these stages it is added to the Framebuffer. The content of the framebuffer is displayed to the screen.</p>






<h1><a name="modern-opengl-context-pt1">LESSON 46 - Setting up a modern OpenGL context pt. 1</a></h1>
<h3>Introduction</h3>
<p>To initialize a modern OpenGL context you need glew.h (GL Extension Wrangler Lib). It's open platform and released by the Khronos Foundation.</p>

<p>First we have to download the library (https://glew.sourceforge.net/)</p>

<p>Add the include and lib folder in setup (TODO) and copy the DLL into the folder... #include <glew.h> before gl.h</p>

<pre><code>

</code></pre>

<p>There are two types of pipelines, rasterization &rarr; DEFine: you pass a set of vertices, then processed by the rasterizer and put into the framebuffer.</p>

<p>Rasterization is the journey from the fragment to the final pixel! You need vertices to render...</p>

<p>You define some vertices, which will be rasterized and render to screen.</p>

<p>the second thing OpenGL support is called global illumination (volumetric rendering). Here you don't have any vertices, (ray-tracing, ray-marching, path-tracing) &rarr; it has it's another way to render (no vertices), but can render multiple thing.</p>

<p>modern pipeline supports both types (first rasterization pipeline works).</p>

<details>
<summary>Code example</summary>
<pre><code>
#include &lt;windows.h&gt;
// LESSON 46
#include &lt;GL/glew.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
// LESSON 46
#pragma comment(lib, "glew32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);
	
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	// LESSON 46
	GLenum result = glewInit();
	if (result != GLEW_OK) {
		return -5;
	}

	SetWindowTextA(g_hwnd, glGetString(GL_VERSION));

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>

<p id="note">
https://github.com/alberto-paparella/SimpleFirstPersonGame/tree/main/src
</p>




<h1><a name="modern-opengl-context-pt2">LESSON 47 - Setting up a modern OpenGL context pt. 2</a></h1>
<h3>Introduction</h3>
<p>Everything in OpenGL previous lessons we used the legacy pipeline. To get a modern extensions that comes with the modern pipeline, we use glew and get the EXT for modern context.</p>

<p>We don't have to change the rendering context, because we use the OS calls, so all we need is the modern funtions that comes with OGL. (New extensions)</p>

<p>Khronos maintains OpenGL for the desktop, for android it's called OpenGL ES (Embedded systems). The latests version is OpenGL ES3.2</p>

<p>In the browser it's called WebGL, which is OpenGL ES internally. WebGL2 is locked to OGL ES 3.0. When OpenGL ES 3.1 (same as OGL 4.2) was released it came with the tesselation shader.</p>

<p>When OpenGL ES 3.2 was released it introduced the geometry shader was introduced.</p>

<p>WebGL only supports vert and frag, but not tess and geo shaders.</p>

<p>OpenGL has three versions, OGL, OGL ES and WebGL for desktop, mobile and browser.</p>

<p>OpenGL was supported for Mac until 18 (19?), but it was swapped for their own technology to support Metal, but it's availble up to version 4.1 CHECK IT OUT (with warning).</p>

<p>All of these OpenGL version uses the shader language GLSL (Graphic Language Shader Language).</p>

<p>There are two types of shader, one is outside of the program and one is inside. Industry standard is outside the program, while for home use inside the program will work just fine.</p>

<p>A shader is a (small C-)program that runs on the GPU. Every shader has it's own spesific task to do. Each shader perferms it's own task. Vert = pr vertex. if you send in 10k vert the vert shader will run 10k times. </p>

<p>What we seing on the screen is from the rasterization pipeline (creation of meshes to screen).</p>

<p>You pass data to the shader which processes it and passes it into the next stage of the pipeline.</p>

<p>You pass the data from one shader to the next using the <b>in</b> keyword.</p>

<p>Every shader also has it's own return type. The type depends on what the shader does</p>

<p>Every shader will it's own <b>main()</b>, similar to the applications main-function.|</p>

<p>You pass some data to the shader, it will process it and pass it back into the pipeline.</p>

<h3>Vertex shader</h3>
<pre><code>
// important in any shader (version has to match between each shader that's defined)
version core 460
in vec3 position;

void main()
{
	// some computation related to position
	gl_Position = // someCalculations
}

Not no return-keyword, gl_Position is handling that for us.
</code></pre>

<h3>Fragment shader</h3>
<pre><code>
version core 460
in vec3 color;
out vec3 out_color,

void main()
{
	// color = vec(1.0f, 1.0f, 1.0f);
	out_color = color;
}
</code></pre>

<p>Frag shader used to have a keyword for frag color, but it's deprecated.</p>

<p>These shaders are compiled at runtime, so it's compiled when the appllication is put in a RAM. We'll write our own Shader debugger to handle this (shaders are difficult to debug).</p>






<h1><a name="modern-opengl-context-pt3">LESSON 48 - Setting up a modern OpenGL context pt. 3 (shaders)</a></h1>
<h3>Introduction</h3>
<p>There are two types of content in a shader, first one is attr, second is uniforms. Attributes are fixed once it's passed to the shaders. Uniforms can be updated dynimically without any changes.</p>

<p>Both have spesific usecases: attr can be verts, normals, tex coords. These are only sent once to the shader.</p>

<p>Uniforms can be any data, ex if you want change your color you pass a var as uniform. These are sent every frame.</p>

<p>Shader is a program that runs on the GPU. Every shader has it's work spesified. GLSL is a C like language with it's own keywords. GLSL is the shader language.</p>

<p>Inside the shader you have the attr (verts, norms, texcoords) and the uniforms (anything). </p>

<p>Setting up a modern OpenGL program by adding a shader program object in the global space and adding the following into your <b>initialize()</b> funtion:</p>

<pre><code>
...
GLuint shader_program_obj;
...

bool initialize()
{
	...
	// LESSON 48 (You can write multiple vs and fs shaders)
	GLuint vertex_shader_obj = glCreateShader(GL_VERTEX_SHADER);					// Give the pointer to the vertex shader obj (this will create the shader)
	const GLchar* vertex_shader = "#version 450" \
		"\n" \
		"void main()" \
		"{" \
		"" \
		"}";

	glShaderSource(vertex_shader_obj, 1, (const GLchar**)&vertex_shader, NULL);		// This will take the vert shader and fill the shader in the vs into the vs obj (sec param is nr of shaders to compile) (4th is amount of lines to compile from top)
	glCompileShader(vertex_shader_obj);

	// Setting up fragment shader
	GLuint fragment_shader_obj = glCreateShader(GL_FRAGMENT_SHADER);
	const GLchar* fragment_shader = "#version 450" \
		"\n" \
		"void main()" \
		"{" \
		"" \
		"}";

	glShaderSource(fragment_shader_obj, 1, (const GLchar**)&fragment_shader, NULL);
	glCompileShader(fragment_shader_obj);

	shader_program_obj = glCreateProgram();
	glAttachShader(shader_program_obj, vertex_shader_obj);
	glAttachShader(shader_program_obj, fragment_shader_obj);

	glLinkProgram(shader_program_obj);
	...
}
</code></pre>

<details>
<summary>Code sample:</summary> 
<pre><code>
#include &lt;windows.h&gt;
// LESSON 46
#include &lt;GL/glew.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;
#pragma comment(lib, "opengl32.lib")
// LESSON 46
#pragma comment(lib, "glew32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)


LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;
// LESSON 48
GLuint shader_program_obj;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-SDK");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);
	
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	// LESSON 46
	GLenum result = glewInit();
	if (result != GLEW_OK) {
		return -5;
	}

	SetWindowTextA(g_hwnd, glGetString(GL_VERSION));

	// LESSON 48 (You can write multiple vs and fs shaders)
	GLuint vertex_shader_obj = glCreateShader(GL_VERTEX_SHADER);					// Give the pointer to the vertex shader obj (this will create the shader)
	const GLchar* vertex_shader = "#version 450" \
		"\n" \
		"void main()" \
		"{" \
		"" \
		"}";

	glShaderSource(vertex_shader_obj, 1, (const GLchar**)&vertex_shader, NULL);		// This will take the vert shader and fill the shader in the vs into the vs obj (sec param is nr of shaders to compile) (4th is amount of lines to compile from top)
	glCompileShader(vertex_shader_obj);

	// Setting up fragment shader
	GLuint fragment_shader_obj = glCreateShader(GL_FRAGMENT_SHADER);
	const GLchar* fragment_shader = "#version 450" \
		"\n" \
		"void main()" \
		"{" \
		"" \
		"}";

	glShaderSource(fragment_shader_obj, 1, (const GLchar**)&fragment_shader, NULL);
	glCompileShader(fragment_shader_obj);

	shader_program_obj = glCreateProgram();
	glAttachShader(shader_program_obj, vertex_shader_obj);
	glAttachShader(shader_program_obj, fragment_shader_obj);

	glLinkProgram(shader_program_obj);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);


	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	

	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>




<h1><a name="modern-opengl-context-pt4">LESSON 49 - Setting up a modern OpenGL context pt. 4</a></h1>
<h3>Introduction</h3>
<p>include vmath, change main.c to main.cpp, </p>
<p></p>

<pre><code>
</code></pre>

<p></p>

<pre><code>
</code></pre>

<details>
<summary>Code sample:</summary> 
<pre><code>
#include &lt;windows.h&gt;
// LESSON 46
#include &lt;GL/glew.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;
#include "vmath.h"
#pragma comment(lib, "opengl32.lib")
#pragma comment(lib, "openal32.lib")
// LESSON 46
#pragma comment(lib, "glew32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)
// using namespace vmath;

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;
// LESSON 48
GLuint shader_program_obj;

// LESSON 49
enum {
	POSITION = 0,
};
GLuint vao_triangle;
GLuint vbo_position_triangle;
GLuint mvp_uniform;
vmath::mat4 perspective_projection_matrix;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-OpenGL-App");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);
	
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	// LESSON 46
	GLenum result = glewInit();
	if (result != GLEW_OK) {
		return -5;
	}

	// SetWindowTextA(g_hwnd, glGetString(GL_VERSION));

	// LESSON 48 (You can write multiple vs and fs shaders)
	// LESSON 49 ()
	GLuint vertex_shader_obj = glCreateShader(GL_VERTEX_SHADER);					// Give the pointer to the vertex shader obj (this will create the shader)
	const GLchar* vertex_shader = "#version 450 core" \
		"\n" \
		"in vec4 vpos;" \
		"uniform mat4 mvp_matrix;" \
		"void main()" \
		"{" \
		"	gl_Position = mvp_matrix * vpos;" \
		"}";

	glShaderSource(vertex_shader_obj, 1, (const GLchar**)&vertex_shader, NULL);		// This will take the vert shader and fill the shader in the vs into the vs obj (sec param is nr of shaders to compile) (4th is amount of lines to compile from top)
	glCompileShader(vertex_shader_obj);

	// Setting up fragment shader
	GLuint fragment_shader_obj = glCreateShader(GL_FRAGMENT_SHADER);

	// LESSON 49 (core tells ogl to use the core (latest shader vers vs legacy))
	// Emitting a blue color to whatever the vert has passed
	const GLchar* fragment_shader = "#version 450 core" \
		"\n" \
		"out vec4 fragColor;" \
		"void main()" \
		"{" \
		"	fragColor = vec4(0.0, 0.0, 1.0, 1.0);" \
		"}";

	glShaderSource(fragment_shader_obj, 1, (const GLchar**)&fragment_shader, NULL);
	glCompileShader(fragment_shader_obj);

	shader_program_obj = glCreateProgram();
	glAttachShader(shader_program_obj, vertex_shader_obj);
	glAttachShader(shader_program_obj, fragment_shader_obj);

	// LESSON 49
	glBindAttribLocation(shader_program_obj, POSITION, "vpos");

	glLinkProgram(shader_program_obj);

	// LESSON 49
	mvp_uniform = glGetUniformLocation(shader_program_obj, "mvp_matrix");

	// LESSON 49
	const GLfloat triangleVertices[] =
	{
		// Perspective triangle (Front face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f,  1.0f,     // Right bottom
		// Perspective triangle (Right face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f, -1.0f,     // Right bottom
		// Perspective triangle (Back face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f, -1.0f,     // Left bottom
	   -1.0f, -1.0f, -1.0f,		// Right bottom
		// Perspective triangle (Left face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f, -1.0f,		// Left bottom
	   -1.0f, -1.0f,  1.0f
	};

	glGenVertexArrays(1, &vao_triangle);
	glBindVertexArray(vao_triangle);
	glGenBuffers(1, &vbo_position_triangle);
	glBindBuffer(GL_ARRAY_BUFFER, vbo_position_triangle);
	glBufferData(GL_ARRAY_BUFFER, sizeof(triangleVertices), triangleVertices, GL_STATIC_DRAW);
	glVertexAttribPointer(POSITION, 3, GL_FLOAT, GL_FALSE, 0, NULL);
	glEnableVertexAttribArray(POSITION);
	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	// LESSON 49
	perspective_projection_matrix = vmath::perspective(45.0f, (GLfloat)w / (GLfloat)h, 1.0f, 100.0f );

	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	// LESSON 49
	glUseProgram(shader_program_obj);

	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();
	
	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>





<h1><a name="modern-opengl-context-pt5">LESSON 50 - Setting up modern openGL context - pt 5</a></h1>
<h3>Introduction</h3>
<p>GFX pippeline(Verts, Normals, Tex) &rarr; VS &rarr; FS</p>
<p>There are two places you can send the data. First one is attributes (They are data that cant be changes, eg. drawdata (rawdata = attr)) You pass this as the pipeline is initialized.</p>
<p>The second on is the uniforms (passed on runtime, eg Color of the geo (in a shader)). </p>
<pre><code>
</code></pre>
VERTEX SHADER

in vec4 vPos;
in vec2 vTex;
in vec3 vNormal;

void main()
{
	// write the logic to convert raw data accordingly
}
<pre><code>
</code></pre>

<p>You are binding (creating a pipe) between the CPU and GPU by sharing the memaddr (pointer). (Add the GL calls you need to set things up)</p>

<details>
<summary>Code sample:</summary> 
<pre><code>
#include &lt;windows.h&gt;
// LESSON 46
#include &lt;GL/glew.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;
#include "vmath.h"
#pragma comment(lib, "opengl32.lib")
// LESSON 46
#pragma comment(lib, "glew32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)
// using namespace vmath;

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;
// LESSON 48
GLuint shader_program_obj;

// LESSON 49
enum {
	POSITION = 0,
};
GLuint vao_triangle;
GLuint vbo_position_triangle;
GLuint mvp_uniform;
vmath::mat4 perspective_projection_matrix;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-OpenGL-App");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);
	
	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	// LESSON 46
	GLenum result = glewInit();
	if (result != GLEW_OK) {
		return -5;
	}

	// SetWindowTextA(g_hwnd, glGetString(GL_VERSION));

	// LESSON 48 (You can write multiple vs and fs shaders)
	// LESSON 49 ()
	GLuint vertex_shader_obj = glCreateShader(GL_VERTEX_SHADER);					// Give the pointer to the vertex shader obj (this will create the shader)
	const GLchar* vertex_shader = "#version 450 core" \
		"\n" \
		"in vec4 vpos;" \
		"uniform mat4 mvp_matrix;" \
		"void main()" \
		"{" \
		"	gl_Position = mvp_matrix * vpos;" \
		"}";

	glShaderSource(vertex_shader_obj, 1, (const GLchar**)&vertex_shader, NULL);		// This will take the vert shader and fill the shader in the vs into the vs obj (sec param is nr of shaders to compile) (4th is amount of lines to compile from top)
	glCompileShader(vertex_shader_obj);

	// Setting up fragment shader
	GLuint fragment_shader_obj = glCreateShader(GL_FRAGMENT_SHADER);

	// LESSON 49 (core tells ogl to use the core (latest shader vers vs legacy))
	// Emitting a blue color to whatever the vert has passed
	const GLchar* fragment_shader = "#version 450 core" \
		"\n" \
		"out vec4 fragColor;" \
		"void main()" \
		"{" \
		"	fragColor = vec4(0.0, 0.0, 1.0, 1.0);" \
		"}";

	glShaderSource(fragment_shader_obj, 1, (const GLchar**)&fragment_shader, NULL);
	glCompileShader(fragment_shader_obj);

	shader_program_obj = glCreateProgram();
	glAttachShader(shader_program_obj, vertex_shader_obj);
	glAttachShader(shader_program_obj, fragment_shader_obj);

	// LESSON 49
	glBindAttribLocation(shader_program_obj, POSITION, "vpos");

	glLinkProgram(shader_program_obj);

	// LESSON 49
	mvp_uniform = glGetUniformLocation(shader_program_obj, "mvp_matrix");

	// LESSON 49
	const GLfloat triangleVertices[] =
	{
		// Perspective triangle (Front face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f,  1.0f,     // Right bottom
		// Perspective triangle (Right face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f, -1.0f,     // Right bottom
		// Perspective triangle (Back face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f, -1.0f,     // Left bottom
	   -1.0f, -1.0f, -1.0f,		// Right bottom
		// Perspective triangle (Left face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f, -1.0f,		// Left bottom
	   -1.0f, -1.0f,  1.0f
	};

	// Creating a memlocation on the CPU storing the GPU mem addr in the variable
	glGenVertexArrays(1, &vao_triangle);	
	// Bind this instance to a state
	glBindVertexArray(vao_triangle);
	// Creating a subbuffer 
	glGenBuffers(1, &vbo_position_triangle);
	glBindBuffer(GL_ARRAY_BUFFER, vbo_position_triangle);
	// First param: pointer to a datatype, second is size of data, 3rd: what data is sent, 4th: draw command
	glBufferData(GL_ARRAY_BUFFER, sizeof(triangleVertices), triangleVertices, GL_STATIC_DRAW);
	// Once a buffer has been created -> take this position data and 2nd: vert shaders -> 3 parts each time, 3rd: data type of the data 4th: no ratation, 5th: TBA 6th: TBA 
	glVertexAttribPointer(POSITION, 3, GL_FLOAT, GL_FALSE, 0, NULL);
	// Push the data from the CPU to the GPU (via it's pointer)
	glEnableVertexAttribArray(POSITION);
	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	// LESSON 50 homework
	shader_program_obj = glCreateProgram();

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	// LESSON 49
	perspective_projection_matrix = vmath::perspective(45.0f, (GLfloat)w / (GLfloat)h, 1.0f, 100.0f );
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	// LESSON 49
	glUseProgram(shader_program_obj);

	glDrawArrays(GL_TRIANGLES, 0, 3);
		
	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}


	// glDeleteShader(vertex_shader);
	// glDeleteShader(fragment_shader);
}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>



<h1><a name="modern-opengl-context-pt6">LESSON 51 - Setting up modern openGL context - pt 6</a></h1>
<h3>Introduction</h3>
<p>Continuation of previous setup by adding color to the triangle</p>

<details>
<summary>Code sample:</summary> 
<pre><code>
#include &lt;windows.h&gt;
// LESSON 46
#include &lt;GL/glew.h&gt;
#include &lt;GL/gl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;
#include "vmath.h"
#pragma comment(lib, "opengl32.lib")
// LESSON 46
#pragma comment(lib, "glew32.lib")
#pragma comment(linker, "/subsystem:windows" /*/entry:mainCRTStartup*/)
// using namespace vmath;

LRESULT CALLBACK WndProc(HWND, UINT, WPARAM, LPARAM);
int initialize(void);
void resize(int, int);
void display(void);
void uninitialize(void);
void toggle_fullscreen(void);

HWND g_hwnd;
HDC g_hdc = NULL;
HGLRC g_hrc = NULL;
DWORD dwStyle;
HMONITOR hMonitor;
WINDOWPLACEMENT wpPrev = { sizeof(WINDOWPLACEMENT) };
bool bIsMonitorInfo;
bool bIsWindowPlacement;
bool bIsRunning = true;
bool bIsFullscreen = false;
// LESSON 48
GLuint shader_program_obj;

// LESSON 49
enum {
	POSITION = 0,
	// LESSON 51
	COLOR = 1,
};
GLuint vao_triangle;
GLuint vbo_position_triangle;
GLuint mvp_uniform;
// LESSON 51
GLuint vbo_triangle_color;
vmath::mat4 perspective_projection_matrix;

int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR lpCmdLine, int iCmdShow)
{
	// Window dimensions
	int sWindowWidth = 800;
	int sWindowHeight = 600;
	int x = 0;
	int y = 0;
	int monitorHalfWidth = 0;
	int monitorHalfHeight = 0;

	int monitorWidth = GetSystemMetrics(SM_CXFULLSCREEN);
	int monitorHeight = GetSystemMetrics(SM_CYFULLSCREEN);
	// Centering the starting point
	monitorHalfWidth = monitorWidth / 2;
	monitorHalfHeight = monitorHeight / 2;
	// Starting point
	x = monitorHalfWidth - sWindowWidth / 2;
	y = monitorHalfHeight - sWindowHeight / 2;

	WNDCLASSEX wndclass;
	HWND hwnd;
	MSG msg;
	TCHAR szAppName[] = TEXT("Win32-API-OpenGL-App");
	wndclass.cbSize = sizeof(WNDCLASSEX);
	wndclass.style = CS_HREDRAW | CS_VREDRAW;
	wndclass.cbClsExtra = 0;
	wndclass.cbWndExtra = 0;
	wndclass.hIcon = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.hCursor = LoadCursor(NULL, IDC_ARROW);
	wndclass.hbrBackground = (HBRUSH)GetStockObject(BLACK_BRUSH);
	wndclass.lpszClassName = szAppName;
	wndclass.lpszMenuName = NULL;
	wndclass.hIconSm = LoadIcon(NULL, IDI_APPLICATION);
	wndclass.lpfnWndProc = WndProc;
	wndclass.hInstance = hInstance;

	RegisterClassEx(&wndclass);

	hwnd = CreateWindow(
		szAppName,
		TEXT("Win32-API-SDK"),
		WS_OVERLAPPEDWINDOW,
		x,
		y,
		sWindowWidth,
		sWindowHeight,
		NULL,
		NULL,
		hInstance,
		NULL
	);

	ShowWindow(hwnd, SW_NORMAL);

	g_hwnd = hwnd;
	int result = initialize();

	while (bIsRunning == true) {
		if (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {
			if (msg.message == WM_QUIT) {
				bIsRunning = false;
			}
			else {
				TranslateMessage(&msg);
				DispatchMessage(&msg);
			}
		}
		else {
			display();
		}
	}

	return ((int)msg.wParam);
}

LRESULT CALLBACK WndProc(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
	switch (uMsg)
	{
	case WM_CHAR:
		switch (wParam)
		{
		case 'f':
		case 'F':
			toggle_fullscreen();
			break;
		}
		break;
	case WM_SIZE:
		resize(LOWORD(lParam), HIWORD(lParam));
		break;
	case WM_DESTROY:
		uninitialize();
		PostQuitMessage(0);
		break;
	}

	return (DefWindowProc(hwnd, uMsg, wParam, lParam));
}

int initialize()
{
	PIXELFORMATDESCRIPTOR pfd;
	int iPixelFormatIndex;
	ZeroMemory(&pfd, sizeof(PIXELFORMATDESCRIPTOR));
	pfd.nSize = sizeof(PIXELFORMATDESCRIPTOR);
	pfd.nVersion = 1;
	pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
	pfd.iPixelType = PFD_TYPE_RGBA;
	pfd.cColorBits = 32;
	pfd.cRedBits = 8;
	pfd.cGreenBits = 8;
	pfd.cBlueBits = 8;
	pfd.cAlphaBits = 8;

	g_hdc = GetDC(g_hwnd);

	iPixelFormatIndex = ChoosePixelFormat(g_hdc, &pfd);
	if (iPixelFormatIndex == 0) {
		return -1;
	}

	if (SetPixelFormat(g_hdc, iPixelFormatIndex, &pfd) == FALSE) {
		return -2;
	}

	g_hrc = wglCreateContext(g_hdc);
	if (g_hrc == NULL) {
		return -3;
	}

	if (wglMakeCurrent(g_hdc, g_hrc) == FALSE) {
		return -4;
	}

	// LESSON 46
	GLenum result = glewInit();
	if (result != GLEW_OK) {
		return -5;
	}

	// LESSON 48 (You can write multiple vs and fs shaders)
	// LESSON 49 
	GLuint vertex_shader_obj = glCreateShader(GL_VERTEX_SHADER);					// Give the pointer to the vertex shader obj (this will create the shader)
	const GLchar* vertex_shader = "#version 450 core" \
		"\n" \
		"in vec4 vpos;" \
		"in vec3 color;" \
		"out vec3 outColor;" \
		"uniform mat4 mvp_matrix;" \
		"void main()" \
		"{" \
		"	gl_Position = mvp_matrix * vpos;" \
		"   outColor = color;" \
		"}";

	glShaderSource(vertex_shader_obj, 1, (const GLchar**)&vertex_shader, NULL);		// This will take the vert shader and fill the shader in the vs into the vs obj (sec param is nr of shaders to compile) (4th is amount of lines to compile from top)
	glCompileShader(vertex_shader_obj);

	// Setting up fragment shader
	GLuint fragment_shader_obj = glCreateShader(GL_FRAGMENT_SHADER);
	// LESSON 49 (core tells ogl to use the core (latest shader vers vs legacy))
	// Emitting a blue color to whatever the vert has passed
	const GLchar* fragment_shader = "#version 450 core" \
		"\n" \
		"" \
		"in vec3 outColor;" \
		"out vec4 fragColor;" \
		"void main()" \
		"{" \
		"	fragColor = vec4(outColor, 1.0);" \
		"}";

	glShaderSource(fragment_shader_obj, 1, (const GLchar**)&fragment_shader, NULL);
	glCompileShader(fragment_shader_obj);

	shader_program_obj = glCreateProgram();
	glAttachShader(shader_program_obj, vertex_shader_obj);
	glAttachShader(shader_program_obj, fragment_shader_obj);

	// LESSON 49
	glBindAttribLocation(shader_program_obj, POSITION, "vpos");
	// LESSON 51
	glBindAttribLocation(shader_program_obj, COLOR, "color");

	glLinkProgram(shader_program_obj);

	// LESSON 49
	mvp_uniform = glGetUniformLocation(shader_program_obj, "mvp_matrix");

	// LESSON 51
	const GLfloat triangleColor[] = {
		1.0f, 0.0f, 0.0f
	};

	// LESSON 49
	const GLfloat triangleVertices[] = {
		// Perspective triangle (Front face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f,  1.0f,     // Right bottom
		// Perspective triangle (Right face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f,  1.0f,     // Left bottom
		1.0f, -1.0f, -1.0f,     // Right bottom
		// Perspective triangle (Back face)
		0.0f,  1.0f,  0.0f,     // Apex
		1.0f, -1.0f, -1.0f,     // Left bottom
	   -1.0f, -1.0f, -1.0f,		// Right bottom
		// Perspective triangle (Left face)
		0.0f,  1.0f,  0.0f,     // Apex
	   -1.0f, -1.0f, -1.0f,		// Left bottom
	   -1.0f, -1.0f,  1.0f
	};

	// Creating a memlocation on the CPU storing the GPU mem addr in the variable
	glGenVertexArrays(1, &vao_triangle);	
	// Bind this instance to a state
	glBindVertexArray(vao_triangle);
	// Creating a subbuffer 
	glGenBuffers(1, &vbo_position_triangle);
	glBindBuffer(GL_ARRAY_BUFFER, vbo_position_triangle);
	// First param: pointer to a datatype, second is size of data, 3rd: what data is sent, 4th: draw command
	glBufferData(GL_ARRAY_BUFFER, sizeof(triangleVertices), triangleVertices, GL_STATIC_DRAW);
	// Once a buffer has been created -> take this position data and 2nd: vert shaders -> 3 parts each time, 3rd: data type of the data 4th: no ratation, 5th: TBA 6th: TBA 
	glVertexAttribPointer(POSITION, 3, GL_FLOAT, GL_FALSE, 0, NULL);	
	// Push the data from the CPU to the GPU (via it's pointer)
	glEnableVertexAttribArray(POSITION);

	// LESSON 51
	//glBindBuffer(GL_ARRAY_BUFFER, 0);
	glGenBuffers(1, &vbo_triangle_color);
	glBindBuffer(GL_ARRAY_BUFFER, vbo_triangle_color);
	glBufferData(GL_ARRAY_BUFFER, sizeof(triangleColor), triangleColor, GL_STATIC_DRAW);
	glVertexAttribPointer(COLOR, 3, GL_FLOAT, GL_FALSE, 0, NULL);
	glEnableVertexAttribArray(COLOR);
	glClearColor(0.0f, 0.0f, 0.0f, 1.0f);

	resize(800, 600);

	return 0;
}

void resize(int w, int h)
{
	if (h == 0)
		h = 1;

	glViewport(0, 0, (GLsizei)w, (GLsizei)h);

	// LESSON 49
	perspective_projection_matrix = vmath::perspective(45.0f, (GLfloat)w / (GLfloat)h, 0.1f, 100.0f);
}

void display(void)
{
	glClear(GL_COLOR_BUFFER_BIT);

	// LESSON 49
	glUseProgram(shader_program_obj);

	glDrawArrays(GL_TRIANGLES, 0, 3);
		
	SwapBuffers(g_hdc);
}

void uninitialize(void)
{
	if (bIsFullscreen == true)
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
	}

	if (wglGetCurrentContext() == g_hrc) {
		wglMakeCurrent(NULL, NULL);
	}

	if (g_hrc) {
		wglDeleteContext(g_hrc);
		g_hrc = NULL;
	}

	if (g_hdc) {
		ReleaseDC(g_hwnd, g_hdc);
		g_hdc = NULL;
	}


	// glDeleteShader(vertex_shader);
	// glDeleteShader(fragment_shader);

}

void toggle_fullscreen(void)
{
	MONITORINFO mi;

	if (bIsFullscreen == false) {
		mi.cbSize = sizeof(MONITORINFO);

		dwStyle = GetWindowLong(g_hwnd, GWL_STYLE);

		if (dwStyle & WS_OVERLAPPEDWINDOW) {
			bIsWindowPlacement = GetWindowPlacement(g_hwnd, &wpPrev);
			hMonitor = MonitorFromWindow(g_hwnd, MONITORINFOF_PRIMARY);
			bIsMonitorInfo = GetMonitorInfo(hMonitor, &mi);

			if (bIsWindowPlacement == true && bIsMonitorInfo == true) {
				SetWindowLong(g_hwnd, GWL_STYLE, dwStyle & ~WS_OVERLAPPEDWINDOW);
				SetWindowPos(g_hwnd, HWND_TOP,
					mi.rcMonitor.left,
					mi.rcMonitor.top,
					mi.rcMonitor.right - mi.rcMonitor.left,
					mi.rcMonitor.bottom - mi.rcMonitor.top,
					SWP_NOZORDER | SWP_FRAMECHANGED);
			}
		}
		ShowCursor(FALSE);
		bIsFullscreen = true;
	}
	else
	{
		SetWindowLong(g_hwnd, GWL_STYLE, dwStyle | WS_OVERLAPPEDWINDOW);
		SetWindowPlacement(g_hwnd, &wpPrev);
		SetWindowPos(g_hwnd, HWND_TOP, 0, 0, 0, 0, SWP_NOZORDER | SWP_FRAMECHANGED | SWP_NOMOVE | SWP_NOSIZE | SWP_NOOWNERZORDER);
		ShowCursor(TRUE);
		bIsFullscreen = false;
	}
}
</code></pre>
</details>





<h1><a name="modern-opengl-context-pt7">LESSON 52 - Setting up modern openGL context - pt 7</a></h1>
<h3>Introduction</h3>
<p></p>
<p></p>

<pre><code>
</code></pre>

<p></p>

<pre><code>
</code></pre>

<details>
<summary>Code sample:</summary> 
<pre><code>

</code></pre>
</details>



<h1><a name="modern-opengl-context-pt8">LESSON 53 - Setting up modern openGL context - pt 8</a></h1>
<h3>Introduction</h3>
<p></p>
<p></p>

<pre><code>
</code></pre>

<p></p>

<pre><code>
</code></pre>

<details>
<summary>Code sample:</summary> 
<pre><code>

</code></pre>
</details>


<details>
<summary>Appendix and Notes</summary>
<h1><a name="">KNOWN BUGS</a></h1>
<ul>
	<li>Something adds a transparent layer to <b>GL_LINE_STRIP</b> when drawn</li>
	<li>Frequent framedrops when adding lighting with rotation and multiple models</li>
	<li>When entering and leaving fullscreen there is a small delay between redrawing</li>
</ul>

<pre><code>
<h3>From Fermant's Library via Linkedin</h3>
<p>&pi; = 666 / 212</p>
<b>It's a palidromic approximation of PI</b>
</code></pre>

<pre><code>
<h3>The Phi Ratio (Golden Mean)</h3>
<p>The Golden Mean, represented by the Greek letter phi, is an irrational number, like e or pi, which seems to arise out of the basic</p>
<p>structure of nature. It is defined as a ratio of heigh to width of 1:1.618. The Phi Ratio appears regularly in the proportions</p>
<p>of plants, animals, DNS, the solar system and even, population growth. Since early mankind, the phi ratio has been represented</p>
<p>in the design of structures, tools and creative arts.</p>
<p>Its use in early societies that had no formal understanding of mathematics leads scholars to believe that phi is a fundamental</p>
<p>subconscious aesthetic preference.</p>
<p>The Phi Ratio is applied more commonly today in graphic artts, photography and design as the "Rule of Thirds". The Rule of Thirds</p>
<p>states that people have a strong visial attraction to objects that reside at the intersections of hypothetical lines on a page </p>
<p>or in a photograph that is divided into thirds vertically and/or horizontally (Lindwell, Holden, Butler 2003). The rule of thirds </p>
<p>is simply a representation of the world in which welive. Whether natural as in beach, water and sky or manmade as in floors, walls and</p>
<p>ceilings, these horizontal divisions are so innate to our nature that they are beaely, if ever, consciously preceived.</p>
<b>A is to B as B is to C</b
<p>______________</p>
<p>A ------------</p>
<p>B --------</p>
<p>C ----</p>
<br/>
<p>|-------------| A </p>
<p>|             |</p>
<p>|--------|----| B & C</p>
<p>|             |</p>
<p>_______________</p>
</code></pre>

<h1><a name="">WORKING-ON & CURRENTLY TESTING</a></h1>
<h3>Procedural drawing and scenary</h3>

<p>Try implementing a full world with lots of models to create realistic scenary.</p>
<pre><code>
glBegin(GL_LINE_STRIP);
	for (i = p1; i <= p2; i++) {
		glEvalcoord1(u1 + i*(u2-u1)/n);
	}
glEnd();
</code></pre>
<p>Note: if i = 0 and i = n, then <b>glEvalcoord1()</b> is called with exactly u1 or u2 as parameter.</p>
<p id="note">Please see OpenGL Programming Guide 7th Ed. p 578 for further details</p>

<h3>Bézier Curves</h3>
<p>Two-dimensional Evaluators [...] must take u and v into account. Points, colors, normals, or texture coordinates must be supplied over a surface instead of a curve. Mathematically, the definition of a Bézier surface patch 
is given by</p>
<pre><code>
S(u, v) = n sigma i = 0, m sigma j = 0, B SupN SubI (u) B Supm Subj (v) P Subi Subj
</code></pre>
<p>where Pij values are a set of m*n control points, and the Bi functions are the same Bernstein polynomials for one dimension. As before, the Pji values can represent vertices, normals, colors, or texture coordinates.</p>

<p>The procedure for using two-dimensional evaluators is similar to the procedure for one dimension:</p>
<ul>
	<li>Define the evalutor(s) with <b>mlMap2*()</b>.</li>
	<li>Enable them by passing the appropriate value to <b>glEnable()</b>.</li>
	<li>Invoke them either by calling <b>glEvalCoord2()</b> between a <b>glBegin()</b> and <b>glEnd()</b> pair or by specifying and then applying a mesh with <b>glMapGrid2()</b> and <b>glEvalMesh2()</b>.</li>
</ul>

<p id="note">Please see OpenGL Programming Guide 7th Ed. p 578 for further details</p>

<p id="note">
DSA for OpenGL 4.4: <a href="https://registry.khronos.org/OpenGL/extensions/ARB/ARB_direct_state_access.txt">https://registry.khronos.org/OpenGL/extensions/ARB/ARB_direct_state_access.txt</a>
</p>

<pre><code>
Fermat's Library
The fifth hyperfactorial: 5sub5 × 4sub4 × 3³ × 2² × 1¹ = 86400000 milliseconds is exactly 1 day

1 day has 24 hours: 24=4·3·2
1 hour has 60 minutes: 60=5·4·3
1 minute has 60 seconds: 60=5·4·3
1 second has 1000 milliseconds: 1000=5·5·5·4·2
</code></pre>

<pre><code>
Source: https://www.reddit.com/r/GraphicsProgramming/comments/yibs49/math_struggle_with_dot_products_vector_algebra/
I'm currently working through the ray tracing in one weekend books and while I've now got a pretty good grasp on everything in here, I'm really hung not being able to understand a bit of math surrounding this:
(A + tb − C) ⋅ (A + tb − C) = r^2
The rules of vector algebra are all that we would want here. If we expand that equation and move all the terms to the left hand side we get:
t^2 b ⋅ b + 2tb ⋅ (A−C) + (A−C) ⋅ (A−C) − r^2 = 0
Anyone able to help explain how the author has made this jump using vector algebra? Thanks.
---
(A + tb − C) ⋅ (A + tb − C) = r2
(tb + (A − C)) ⋅ (tb + (A − C)) - r2 = 0
t2 b · b + tb · (A - C) + (A - C) · tb + (A - C) ⋅ (A - C) - r2 = 0
t2 b · b + 2 tb · (A - C) + (A - C) · (A - C) - r2 = 0
Just using the associative property of vector addition and the commutative property of the dot product.
---
Dot products distribute like multiplication (you can prove it to yourself if you write out the x, y, z components). 
If you rewrite A-C as X, and tb as Y. Then you have your typical (X+Y)2 form = X2 + 2XY + Y2. Where scalar multiplication is replaced with a vector dot product.
</code></pre>
<pre><code>
Read more about: 
- Bernstein polynomial, Bézier Curves and Surfaces
In the mathematical field of numerical analysis, a Bernstein polynomial is a polynomial that is a linear combination of Bernstein basis polynomials. The idea is named after Sergei Natanovich Bernstein.

A numerically stable way to evaluate polynomials in Bernstein form is de Casteljau's algorithm.

Polynomials in Bernstein form were first used by Bernstein in a constructive proof for the Weierstrass approximation theorem. With the advent of computer graphics, Bernstein polynomials, restricted to the interval [0, 1], 
became important in the form of Bézier curves.

- Affine Transformations
In Euclidean geometry, an affine transformation, or an affinity (from the Latin, affinis, "connected with"), is a geometric transformation that preserves lines and parallelism (but not necessarily distances and angles).

More generally, an affine transformation is an automorphism of an affine space (Euclidean spaces are specific affine spaces), that is, a function which maps an affine space onto itself while preserving both the dimension of 
any affine subspaces (meaning that it sends points to points, lines to lines, planes to planes, and so on) and the ratios of the lengths of parallel line segments. Consequently, sets of parallel affine subspaces remain 
parallel after an affine transformation. An affine transformation does not necessarily preserve angles between lines or distances between points, though it does preserve ratios of distances between points lying on a 
straight line.

If X is the point set of an affine space, then every affine transformation on X can be represented as the composition of a linear transformation on X and a translation of X. Unlike a purely linear transformation, an affine 
transformation need not preserve the origin of the affine space. Thus, every linear transformation is affine, but not every affine transformation is linear.

Examples of affine transformations include translation, scaling, homothety, similarity, reflection, rotation, shear mapping, and compositions of them in any combination and sequence.

Viewing an affine space as the complement of a hyperplane at infinity of a projective space, the affine transformations are the projective transformations of that projective space that leave the hyperplane at infinity 
invariant, restricted to the complement of that hyperplane.

A generalization of an affine transformation is an affine map[1] (or affine homomorphism or affine mapping) between two (potentially different) affine spaces over the same field k. Let (X, V, k) and (Z, W, k) be two 
affine spaces with X and Z the point sets and V and W the respective associated vector spaces over the field k. 
A map f: X → Z is an affine map if there exists a linear map mf : V → W such that mf (x − y) = f (x) − f (y) for all x, y in X.[2]
</code></pre>


<pre><code>
Define a Physical Renderer with F1-F12 to toggle rendering mode and positions
Create a Powered-by newscasting website
</code></pre>


<p>Calculate the normals to display lighting</p>
<pre><code>
double[] calculate_normal(double[] a, double[] b, double[] c)
{
	double[] <var>x</var> = {b[0] - a[0], b[1] - a[1], b[2] - a[2]};
	double[] <var>y</var> = {c[0] - a[0], c[1] - a[1], c[2] - a[2]};
	
	double[] result = {x[1] * y[2] - y[1] * x[2], -(x[0] * y[2] - y[0]* x[2]), x[0] * y[1] - y[0] * x[1]};
	return result;
}
...

void display()
{
	...
	glBegin(GL_TRIANGLES);
		glNormal3f(calculate_normal(a, b, c));
		glVertex2f(...);
	glEnd();
}
</code></pre>

<h3>Rendering Equation</h3>

<p>Full playlist of topics: <a href="https://www.youtube.com/playlist?list=PLplnkTzzqsZS3R5DjmCQsqupu43oS9CFN">https://www.youtube.com/playlist?list=PLplnkTzzqsZS3R5DjmCQsqupu43oS9CFN</a></p>

<h3>Blinn/Phong Material Model</h3>

<pre><code>
<b>C = I (cos&theta; K<sub>d</sub> + K<sub>s</sub>(cos&phi;<sup>&alpha;</sup>))</b>
The cosine part inside the parentesis are called the <b>Geometry Term</b>, which is a function of the incoming light to the surface, and can be written as:
<b>C = I cos&theta; (K<sub>d</sub> + K<sub>s</sub> <sup>(cos&phi;)<sup>&alpha;</sup>)</sup>&frasl;<sub>cos&theta;</sub>)</b>
This gives a freflectance function: 
<b>C = I cos&theta; &int;<sub>r</sub>(&omega;, v)</b>
<b>Note:</b> <i>d</i> in the equation stands for difuse, which is constant over all directions, while <i>s</i> stands for specular and is which depends on the incoming light directions.
</code></pre>

<pre><code>
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &int; <sub>&Omega;</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>) d&omega;<sub>i</sub></b>
<img src="C:\Users\Jon\Desktop\Rendering Equation Illustration.png">
<p>How to interpret this: 
<a href="https://pbs.twimg.com/media/CHW_bGCUwAAIS1r.png">https://pbs.twimg.com/media/CHW_bGCUwAAIS1r.png</a>  from: <a href="http://viclw17.github.io/2018/06/30/raytracing-rendering-equation/">http://viclw17.github.io/2018/06/30/raytracing-rendering-equation/</a></p>

What if you have a bunch of light sources?
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &Sigma; L<sub>i</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>)</b>

What if light is coming from all directions (above a hemisphere):
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = L<sub>i</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>)</b>

What if you have a sun and a sky the reflects the light:
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &int;<sub>&Omega;</sub> L<sub>sky</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>) d&omega;<sub>i</sub></b>
<b>          + L<sub>sun</sub> (&omega;<sub>sun</sub>) cos&theta;<sub>sun</sub> f<sub>r</sub> (&omega;<sub>sun</sub>, &omega;<sub>0</sub>)</b>

What if the light is a single source, eg the sun:
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &int;<sub>&Omega;</sub> L<sub>i</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>) d&omega;<sub>i</sub></b>

What if you have a specular surface an a direct and indirect light source:
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &int;<sub>&Omega;</sub> L<sub>i</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>r</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>) d&omega;<sub>i</sub></b>
<b>L<sub>i</sub>(&omega;<sub>i</sub>) = L<sub>direct</sub>(&omega;i) + L<sub>indirect</sub>(&omega;i)</b>

Subsurface scattering / refraction: 
<b>L<sub>0</sub>(&omega;<sub>0</sub>) = &int; <sub>S<sup>2</sup></sub> L<sub>i</sub> (&omega;<sub>i</sub>) cos&theta;<sub>i</sub> f<sub>s</sub> (&omega;<sub>i</sub>, &omega;<sub>0</sub>) d&omega;<sub>i</sub></b>
         <b>+ L<sub>emission</sub>(&omega;<sub>0</sub>)</b>

</code></pre>


<p id="note">Newer OpenGL functions: </p>

<i>source: Cem Yuksel</i>

<pre><code>
#include &lt;glext.h&gt;
#include &lt;wingdi.h&gt;
PFNGLGENVERTEXARRAYSPROC glGenVertexArrays = (PFNGLGENVERTEXARRAYSPROC) wglGetProcAddress("glGenVertexArrays");
	
typedef void (*PFNGLGENVERTEXARRAYSPROC)(GLsizei n, GLuint *arrays);
</code></pre>

<p>This is the most effective way...</p>

<p>Better way that initialize all the modern OpenGL functions: </p>
<pre><code>
#include &lt;glew.h&gt;
glewInit();
</code></pre>
</p>



<h1><a name="">Further reading</a></h1>
<ul>
	<li>Great Win32 API tutorial: <a href="http://www.winprog.org/tutorial/" target="_blank">http://www.winprog.org/tutorial/</a></li>
	<li>Make the intro screen logo with bumpmapping!</li>
	<li>What is a 3D object: <a href="https://www.youtube.com/watch?v=4EcHkA-2cwM&t" target="_blank">https://www.youtube.com/watch?v=4EcHkA-2cwM&t</a></li>
	<li>Read up on MSVC' cmdline compiler options</li>
	<li>Take a look at <b>DescribePixelFormat</b> for when you initialize OpenGL.</li>
	<li><b>ChangeDisplaySettings()</b> should be called in uninitialize to reset the display settings.</li>
	<li>OpenGL supports <b>timers</b> (Note: only available in OpenGL 3.2 or higher)<pre><code>
	GLint64 timer;
	glGetInteger64v(GL_TIMESTAMP, &timer);
	printf("Milliseconds: %f\n", timer/1000000.0);
	</code></pre></li>
	<li>Microsoft's C language resource: <a href="https://docs.microsoft.com/en-us/cpp/c-language/c-language-reference?view=msvc-160" target="_blank">https://docs.microsoft.com/en-us/cpp/c-language/c-language-reference?view=msvc-160</a></li>
	<li>Remove the MSVCRT100.dll Not found problem: <h href="https://iq.direct/blog/324-how-to-make-your-c-app-independent-of-visual-c-runtime.html" target="_blank">https://iq.direct/blog/324-how-to-make-your-c-app-independent-of-visual-c-runtime.html</a></li>
	<li>Check if <b>InitCommonControlsEx()</b> with the flag <b>ICC_HOTKEY_CLASS</b> solves the <b>alt+enter</b> playing a default sound issue.</li>
	<li>Probably a good start for a level editor (rip this style!): <a href="http://www.alanbaylis.com/freeworld.html" target="_blank">http://www.alanbaylis.com/freeworld.html</a></li>
	<li>Another great example of a level editor (2D) (rip this style too): <a href="https://nooskewl.itch.io/ashedit" target="_blank">https://nooskewl.itch.io/ashedit</a></li>
	<li>Good program example for spline creation (camera paths, roads and other curves): <a href="https://www.alanbaylis.com/apps.html#spline_ed" target="_blank">https://www.alanbaylis.com/apps.html#spline_ed</a></li>
	<li>Splash Screen example that could be modified to generate a loading modal screen: <a href="http://www.alanbaylis.com/win32_tut04.html" target="_blank">http://www.alanbaylis.com/win32_tut04.html</a></li>
	<li>LOWORD and HIWORD is a 32-bit information struct that holds low-order word (last 16 bits) and high-order word (first 16 bits) of the <b>wParam</b>.</li>
	<li>OpenGL white book (ogl and win95): <a href="http://opengl.czweb.org/ewtoc.html" target="_blank">http://opengl.czweb.org/ewtoc.html</a></li>
	<li>Check out the code example at the bottom of this link: <a href="https://web.cs.ship.edu/~djmoon/cgalgs/cgalgs-notes/tessellation.pdf" target="_blank">https://web.cs.ship.edu/~djmoon/cgalgs/cgalgs-notes/tessellation.pdf</a></li>
	<li>Math heavy notes found here: <a href="https://web.cs.ship.edu/~djmoon/cgalgs/cgalgs-notes/" target="_blank">https://web.cs.ship.edu/~djmoon/cgalgs/cgalgs-notes/</a></li>
	<li>Finite State Machine notes: <a href="https://web.cs.ship.edu/~djmoon/automata/automata-notes/automata-fas.pdf" target="_blank">https://web.cs.ship.edu/~djmoon/automata/automata-notes/automata-fas.pdf</a></li>
	<li>Definition of Win32 function names: <a href="http://www.novell.com/documentation/developer/samplecode/ndpscomp_sample/gateway_inc/WS2NLM.H.html" target="_blank">http://www.novell.com/documentation/developer/samplecode/ndpscomp_sample/gateway_inc/WS2NLM.H.html</a></li>
	<li>Custom Window captionbar: <a href="https://docs.microsoft.com/en-us/windows/win32/dwm/customframe" target="_blank">https://docs.microsoft.com/en-us/windows/win32/dwm/customframe</a></li>
	<li>Win32 system function: <a href="https://zetcode.com/gui/winapi/system/" target="_blank">https://zetcode.com/gui/winapi/system/</a></li>
	<li>Advanced controls in Windows API: <a href="https://zetcode.com/gui/winapi/advancedcontrols/" target="_blank">https://zetcode.com/gui/winapi/advancedcontrols/</a></li>
	<li>Custom controls in Windows API: <a href="https://zetcode.com/gui/winapi/customcontrols/" target="_blank">https://zetcode.com/gui/winapi/customcontrols/</a></li>
	<li>Notification icon MSDN resource: <a href="https://docs.microsoft.com/en-us/windows/win32/api/shellapi/ns-shellapi-notifyicondataa" target="_blank">https://docs.microsoft.com/en-us/windows/win32/api/shellapi/ns-shellapi-notifyicondataa?redirectedfrom=MSDN</a></li>
	<li>Function pointer tutorial: <a href="https://www.dreamincode.net/forums/topic/118308-function-pointer-tutorial/" target="_blank">https://www.dreamincode.net/forums/topic/118308-function-pointer-tutorial/</a></li>
	<li>OOP in C tutorial: <a href="https://www.dreamincode.net/forums/topic/77464-object-oriented-programming-in-c/" target="_blank">https://www.dreamincode.net/forums/topic/77464-object-oriented-programming-in-c/</a></li>
	<li>Data modeling for games in C: <a href="https://www.dreamincode.net/forums/topic/26590-data-modeling-for-games-in-c-part-i/" target="_blank">https://www.dreamincode.net/forums/topic/26590-data-modeling-for-games-in-c-part-i/</a></li>
	<li>OpenGL + Win32 font: <a href="http://aslike.egloos.com/2762856" target="_blank">http://aslike.egloos.com/2762856</a></li>
	<li>Make a DLL in Visual Studio (C++): <a href="https://aticleworld.com/how-to-create-and-use-dll-dynamic-link-library-in-c/" target="_blank">https://aticleworld.com/how-to-create-and-use-dll-dynamic-link-library-in-c/</a></li>
	<li>Very nice implementation of Astroid in C and SDL2: <a href="https://github.com/velorek1/asteroid" target="_blank">https://github.com/velorek1/asteroid</a></li>
	<li>Use glTF to create a scene model: <a href="https://github.com/KhronosGroup/glTF" target="_blank">https://github.com/KhronosGroup/glTF</a></li>
	<li>Use glTF to create a 3D format: <a href="http://paulbourke.net/dataformats/glTF/" target="_blank">http://paulbourke.net/dataformats/glTF/</a></li>
	<li>glTF written for C: <a href="https://github.com/jkuhlmann/cgltf" target="_blank">https://github.com/jkuhlmann/cgltf</a></li>
	<li>Opening a Window (win32) with good use of pragma: <a href="https://subscription.packtpub.com/book/business_and_other/9781800208087/1/ch01lvl1sec07/creating-a-window" target=_blank">https://subscription.packtpub.com/book/business_and_other/9781800208087/1/ch01lvl1sec07/creating-a-window</a></li>
	<li>glDebugMessageCallback: <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glDebugMessageCallback.xhtml" target="_blank">https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glDebugMessageCallback.xhtml</a></li>
	<li>Lighting tutorial with math: <a href="https://ncase.me/sight-and-light/" target="_blank">https://ncase.me/sight-and-light/</a></li>
	<li>Animation coding (C++): <a href="https://animcoding.com/post/animation-tech-intro-part-1-skinning" target="_blank">https://animcoding.com/post/animation-tech-intro-part-1-skinning</a></li>
	<li>Neural Matrials paper: <a href="https://cseweb.ucsd.edu/~viscomp/projects/NeuMIP/" target="_blank">https://cseweb.ucsd.edu/~viscomp/projects/NeuMIP/</a></li>
	<li>Multi-Resolution Neural Material online paper: <a href="https://cseweb.ucsd.edu/~viscomp/projects/NeuMIP/assets/neumip_final.pdf" target="_blank">https://cseweb.ucsd.edu/~viscomp/projects/NeuMIP/assets/neumip_final.pdf</a></li>
	<li>Gaussian Matreial Synthesis<a href="https://users.cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2018/04/gms.pdf" target="_blank">https://users.cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2018/04/gms.pdf</a></li>
	<li>Photorealistic Material Editing<a href="https://users.cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2019/09/pme.pdf" target="_blank">https://users.cg.tuwien.ac.at/~zsolnai/wp/wp-content/uploads/2019/09/pme.pdf</a></li>
	<li>What your website should look like: <a href="https://jadkhoury.github.io/terrain_blog.html" target="_blank">https://jadkhoury.github.io/terrain_blog.html</a></li>
	<li>Ray-casting in 2D games cheatsheet: <a href="https://sszczep.github.io/ray-casting-in-2d-game-engines/cheatsheet.html" target="_blank">https://sszczep.github.io/ray-casting-in-2d-game-engines/cheatsheet.html</a></li>
	<li>Ray-casting in 2D games writeup: <a href="https://sszczep.github.io/ray-casting-in-2d-game-engines/" target="_blank">https://sszczep.github.io/ray-casting-in-2d-game-engines/</a></li>
	<li>How to write better liraries: <a href="https://handmade.network/forums/articles/t/7138-how_to_write_better_game_libraries" target="_blank">https://handmade.network/forums/articles/t/7138-how_to_write_better_game_libraries</a></li>
	<li>GUI Skeleton code (Win32, Linux, GTK): <a href="https://handmade.network/forums/articles/t/2836-gui_program_skeleton" target="_blank">https://handmade.network/forums/articles/t/2836-gui_program_skeleton</a></li>
	<li>Implement a PNG reader: <a href="https://handmade.network/forums/articles/t/2822-tutorial_implementing_a_basic_png_reader_the_handmade_way" target="_blank">https://handmade.network/forums/articles/t/2822-tutorial_implementing_a_basic_png_reader_the_handmade_way</a></li>
	<li>PNG Structure: <a href="http://www.libpng.org/pub/png/spec/1.2/PNG-Structure.html" target="_blank">http://www.libpng.org/pub/png/spec/1.2/PNG-Structure.html</a></li>
	<li>PNG Chunks: <a href="http://www.libpng.org/pub/png/spec/1.2/PNG-Chunks.html" target="_blank">http://www.libpng.org/pub/png/spec/1.2/PNG-Chunks.html</a></li>
	<li>AABB collision detection library: <a href="https://github.com/siddharthroy12/sr_resolve" target="_blank">https://github.com/siddharthroy12/sr_resolve</a></li>
	<li>Indie dev reminder list: <a href="https://www.reddit.com/r/gamedev/comments/popigw/1_simple_lowcost_way_to_never_forget_your/" target="_blank">https://www.reddit.com/r/gamedev/comments/popigw/1_simple_lowcost_way_to_never_forget_your/</a></li>
	<li>OpenGL ES 2 extensive tutorial: <a href="https://pragprog.com/titles/kbogla/opengl-es-2-for-android/" target="_blank">https://pragprog.com/titles/kbogla/opengl-es-2-for-android/</a></li>
	<li>Steam genre details: <a href="https://howtomarketagame.com/2020/10/19/steamgenres/" target="_blank">https://howtomarketagame.com/2020/10/19/steamgenres/</a></li>
	<li>Legacy OGL Understanding Coordinate Transformation<a href="https://gdbooks.gitbooks.io/legacyopengl/content/Chapter4/CoordinateTransforms.html" target="_blank">https://gdbooks.gitbooks.io/legacyopengl/content/Chapter4/CoordinateTransforms.html</a></li>
	<li>Discussion of positioning objects in OpenGL (use the positioning code): <a href="https://www.reddit.com/r/opengl/comments/pmrcjb/how_to_rotate_houses_properly/" target="_blank">https://www.reddit.com/r/opengl/comments/pmrcjb/how_to_rotate_houses_properly/</a></li>
	<li>Reversed-Z rendering in OpenGL (4.5)<a href="https://www.wedesoft.de/software/2021/09/20/reversed-z-rendering/" target="_blank">https://www.wedesoft.de/software/2021/09/20/reversed-z-rendering/</a></li>
	<li>Rigid body game physics pt. 6<a href="https://www.wedesoft.de/simulation/2019/12/03/rigid-body-game-physics-6/" target="_blank">https://www.wedesoft.de/simulation/2019/12/03/rigid-body-game-physics-6/</a></li>
	<li>Minimal OpenGL example in C<a href="https://www.wedesoft.de/software/2018/08/03/raw-opengl/" target="_blank">https://www.wedesoft.de/software/2018/08/03/raw-opengl/</a></li>
	<li>Diffuse lighting tutorial: <a href="https://www.youtube.com/watch?v=e-lnyzN2wrM" target="_blank">https://www.youtube.com/watch?v=e-lnyzN2wrM</a></li>
	<li>Diffuse specular lighting tutorial: <a href="https://www.youtube.com/watch?v=dJo1Ao9XydM" target="_blank">https://www.youtube.com/watch?v=dJo1Ao9XydM</a></li>
	<li>ASCII flowchart generator: <a href="https://asciiflow.com/#/" target="_blank">https://asciiflow.com/#/</a></li>
	<li>Project based C-tutorials: <a href="https://github.com/rby90/project-based-tutorials-in-c" target="_blank">https://github.com/rby90/project-based-tutorials-in-c</a></li>
	<li>Procedurial Technique (L-Systems): <a href="https://en.wikipedia.org/wiki/L-system" target="_blank">https://en.wikipedia.org/wiki/L-system</a></li>
	<li>Wang Tiles: <a href="http://www.cr31.co.uk/stagecast/wang/intro.html" target="_blank">http://www.cr31.co.uk/stagecast/wang/intro.html</a></li>
	<li>Test framework for C / C++<a href="https://github.com/Snaipe/Criterion" target="_blank">https://github.com/Snaipe/Criterion</a></li>
	<li>PortableGL C99 Engine<a href="https://github.com/rswinkle/PortableGL" target="_blank">https://github.com/rswinkle/PortableGL</a></li>
	<li>Find a random number inside a circle: <a href="https://www.reddit.com/r/programming/comments/q5zmtt/finding_a_random_point_within_a_circle/" target="_blank">https://www.reddit.com/r/programming/comments/q5zmtt/finding_a_random_point_within_a_circle/</a></li>
	<li>5 ways to draw an outline: <a href="https://alexanderameye.github.io/notes/rendering-outlines/" target="_blank">https://alexanderameye.github.io/notes/rendering-outlines/</a></li>
	<li>Procedural L-Systems research paper: <a href="https://cgl.ethz.ch/Downloads/Publications/Papers/2001/p_Par01.pdf" target="_blank">https://cgl.ethz.ch/Downloads/Publications/Papers/2001/p_Par01.pdf</a></li>
	<li>Procedurally generated content: <a href="http://www.squidi.net/three/c_procedural.php" target="_blank">http://www.squidi.net/three/c_procedural.php</a></li>
	<li>Tutorial on jumping: <a href="http://www.squidi.net/three/entry.php?id=84" target="_blank">http://www.squidi.net/three/entry.php?id=84</a></li>
	<li>Volumetric Cloud paper: <a href="http://killzone.dl.playstation.net/killzone/horizonzerodawn/presentations/Siggraph15_Schneider_Real-Time_Volumetric_Cloudscapes_of_Horizon_Zero_Dawn.pdf" target="_blank">http://killzone.dl.playstation.net/killzone/horizonzerodawn/presentations/Siggraph15_Schneider_Real-Time_Volumetric_Cloudscapes_of_Horizon_Zero_Dawn.pdf</a></li>
	<li>Simulation Principle of Procedural Generation (Dwarf Fortress): <a href="http://www.gameaipro.com/GameAIPro2/GameAIPro2_Chapter41_Simulation_Principles_from_Dwarf_Fortress.pdf" target="_blank">http://www.gameaipro.com/GameAIPro2/GameAIPro2_Chapter41_Simulation_Principles_from_Dwarf_Fortress.pdf</a></li>
	<li>Network Programming with C book: <a href="https://www.amazon.co.uk/dp/1789349869" target="_blank">https://www.amazon.co.uk/dp/1789349869</a></li>
	<li>cglm math library: <a href="https://github.com/recp/cglm" target="_blank">https://github.com/recp/cglm</a></li>
	<li>3D rigid body physics simulation paper: <a href="http://jonathanbosson.github.io/reports/TNM085_group5.pdf" target="_blank">http://jonathanbosson.github.io/reports/TNM085_group5.pdf</a></li>
	<li>How to create a custom 2D physics engine: <a href="https://gamedevelopment.tutsplus.com/tutorials/how-to-create-a-custom-2d-physics-engine-the-basics-and-impulse-resolution--gamedev-6331" target="_blank">https://gamedevelopment.tutsplus.com/tutorials/how-to-create-a-custom-2d-physics-engine-the-basics-and-impulse-resolution--gamedev-6331</a></li>
	<li>Physichs: Angular Effect paper: <a href="https://www.chrishecker.com/images/c/c2/Gdmphys2.pdf" target="_blank">https://www.chrishecker.com/images/c/c2/Gdmphys2.pdf</a></li>
	<li>Texturing a circle: <a href="https://www.youtube.com/watch?v=GNcFjFmqEc8" target="_blank">https://www.youtube.com/watch?v=GNcFjFmqEc8</a></li>
	<li>BEST LEGACY OPENGL tutorial pt. 1: Introduction to Computer Graphics (California State Uni.)<a href="http://cse.csusb.edu/tongyu/courses/cs420/notes/intro.php" target="_blank">http://cse.csusb.edu/tongyu/courses/cs420/notes/intro.php</a></li>
	<li>BEST LEGACY OPENGL tutorial pt. 2: Advanced Computer Graphics (California State Uni.)<a href="http://cse.csusb.edu/tongyu/courses/cs520/notes/texture.php" target="_blank">http://cse.csusb.edu/tongyu/courses/cs520/notes/texture.php</a></li>
	<li>Bringing Deferred Lighting to the Next Level Paper: <a href="https://takahiroharada.files.wordpress.com/2015/04/forward_plus.pdf" target="_blank">https://takahiroharada.files.wordpress.com/2015/04/forward_plus.pdf</a></li>
	<li>Physical Based Shading in Practice: <a href="https://www.youtube.com/watch?v=j-A0mwsJRmk" target="_blank">https://www.youtube.com/watch?v=j-A0mwsJRmk</a></li>
	<li>Oren / Nayar Lighting Model (Diffuse Alternative)<a href="https://www.youtube.com/watch?v=CLISody-hO4" target="_blank">https://www.youtube.com/watch?v=CLISody-hO4</a></li>
	<li>gluLookAt example with strafing (in the comments): <a href="https://www.lighthouse3d.com/tutorials/glut-tutorial/keyboard-example-moving-around-the-world/" target="_blank">https://www.lighthouse3d.com/tutorials/glut-tutorial/keyboard-example-moving-around-the-world/</a></li>
	<li>Autotiling tutorial: <a href="https://gamedev.stackexchange.com/questions/148460/combinations-for-tiling-two-textures-together/148464#148464" target="_blank">https://gamedev.stackexchange.com/questions/148460/combinations-for-tiling-two-textures-together/148464#148464</a></li>
	<li>3D game shaders for beginners: <a href="https://lettier.github.io/3d-game-shaders-for-beginners/index.html" target="_blank">https://lettier.github.io/3d-game-shaders-for-beginners/index.html</a></li>
	<li>SoftEther - Open Source VPN client<a href="https://www.softether.org/5-download" target="_blank">https://www.softether.org/5-download</a></li>
	<li>Invisible Internet Project<a href="https://geti2p.net/en/about/intro" target="_blank">https://geti2p.net/en/about/intro</a></li>
	<li>Isometric Games Pro and Con: <a href="https://www.youtube.com/watch?v=kQ9-AFYV42Y" target="_blank">https://www.youtube.com/watch?v=kQ9-AFYV42Y</a></li>
	<li>What is the Furiour Transform? (video): <a href="https://www.youtube.com/watch?v=spUNpyF58BY" target="_blank">https://www.youtube.com/watch?v=spUNpyF58BY</a></li>
	<li>What is the Furiour Transform? (text): <a href="https://www.3blue1brown.com/lessons/fourier-transforms" target="_blank">https://www.3blue1brown.com/lessons/fourier-transforms</a></li>
	<li>Cubemap coord: <a href="https://i.stack.imgur.com/8saYJ.png" target="_blank">https://i.stack.imgur.com/8saYJ.png</a></li>
	<li>Common Teqniques to Improve Shadow Depth (MSDN): <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/common-techniques-to-improve-shadow-depth-maps?redirectedfrom=MSDN" target="_blank">https://docs.microsoft.com/en-us/windows/win32/dxtecharts/common-techniques-to-improve-shadow-depth-maps?redirectedfrom=MSDN</a></li>
	<li>Alias-Free Shadow Maps (paper)<a href="http://diglib.eg.org/bitstream/handle/10.2312/EGWR.EGSR04.161-166/161-166.pdf?sequence=1&isAllowed=y" target="_blank">http://diglib.eg.org/bitstream/handle/10.2312/EGWR.EGSR04.161-166/161-166.pdf?sequence=1&isAllowed=y</a></li>
	<li>Realtime Shading (slides)<a href="https://docs.google.com/presentation/d/1MwJcnSvkAzpT8BuoSqIkzlYLjdA_lBDrt8bW-vcwmDU/edit#slide=id.p" target="_blank">https://docs.google.com/presentation/d/1MwJcnSvkAzpT8BuoSqIkzlYLjdA_lBDrt8bW-vcwmDU/edit#slide=id.p</a></li>
	<li>C socket programming: <a href="https://www.cs.cmu.edu/~srini/15-441/S10/lectures/r01-sockets.pdf" target="_blank">https://www.cs.cmu.edu/~srini/15-441/S10/lectures/r01-sockets.pdf</a></li>
	<li>Approaching Zero overhead in modern OpenGL: <a href="https://www.reddit.com/r/opengl/comments/qvk0tj/gdc_2014_approaching_zero_driver_overhead/" target="_blank">https://www.reddit.com/r/opengl/comments/qvk0tj/gdc_2014_approaching_zero_driver_overhead/</a></li>
	<li>Circle Drawing (circular FOV): <a href="https://www.redblobgames.com/grids/circle-drawing/" target="_blank">https://www.redblobgames.com/grids/circle-drawing/</a></li>
	<li>Fix your FOV (Racing games)<a href="https://www.youtube.com/watch?v=AbbxkX7kS_M" target="_blank">https://www.youtube.com/watch?v=AbbxkX7kS_M</a></li>
	<li>Roguelike header only lib (C++20): <a href="https://github.com/s9w/oof" target="_blank"></a>https://github.com/s9w/oof</li>
	<li>How to make a game that sells (reddit-post): <a href="https://www.reddit.com/r/gamedev/comments/r0dik6/how_to_make_a_game_that_sells/" target="_blank">https://www.reddit.com/r/gamedev/comments/r0dik6/how_to_make_a_game_that_sells/</a></li>
	<li>Procgen: Nature of Code E-book (Math): <a href="https://natureofcode.com/book/" target="_blank">https://natureofcode.com/book/</a></li>
	<li>Procgen: video tutorial: <a href="https://www.youtube.com/playlist?list=PLFt_AvWsXl0eBW2EiBtl_sxmDtSgZBxB3" target="_blank">https://www.youtube.com/playlist?list=PLFt_AvWsXl0eBW2EiBtl_sxmDtSgZBxB3</a></li>
	<li>PS1 Style 3D Renderer: <a href="https://www.david-colson.com/2021/11/30/ps1-style-renderer.html" target="_blank">https://www.david-colson.com/2021/11/30/ps1-style-renderer.html</a></li>
	<li>OpenAL on Three Platforms: <a href="http://hacksoflife.blogspot.com/2010/11/openal-on-three-platforms.html" target="_blank">http://hacksoflife.blogspot.com/2010/11/openal-on-three-platforms.html</a></li>
	<li>Write your own linear algebra library in C: <a href="https://www.andreinc.net/2021/01/20/writing-your-own-linear-algebra-matrix-library-in-c" target="_blank">https://www.andreinc.net/2021/01/20/writing-your-own-linear-algebra-matrix-library-in-c</a></li>
	<li>Raymarching paper by Nvidia: <a href="https://developer.nvidia.com/gpugems/gpugems2/part-i-geometric-complexity/chapter-8-pixel-displacement-mapping-distance-functions" target="_blank">https://developer.nvidia.com/gpugems/gpugems2/part-i-geometric-complexity/chapter-8-pixel-displacement-mapping-distance-functions</a></li>
	<li>Sphere Tracing paper: <a href="https://graphics.stanford.edu/courses/cs348b-20-spring-content/uploads/hart.pdf" target="_blank">https://graphics.stanford.edu/courses/cs348b-20-spring-content/uploads/hart.pdf</a></li>
	<li>How to better answer questions online: <a href="https://scottlilly.com/suggestions-on-answering-online-programming-questions/" target="_blank">https://scottlilly.com/suggestions-on-answering-online-programming-questions/</a></li>
	<li>Pathfinding and movement cost: <a href="https://www.redblobgames.com/pathfinding/a-star/introduction.html" target="_blank">https://www.redblobgames.com/pathfinding/a-star/introduction.html</a></li>
	<li>OGL physics engine: <a href="https://www.youtube.com/watch?v=zIzlsphGjkY" target="_blank">https://www.youtube.com/watch?v=zIzlsphGjkY</a></li>
	<li>OGL physics engine camera: <a href="https://www.youtube.com/watch?v=MWf--8wDD5A" target="_blank">https://www.youtube.com/watch?v=MWf--8wDD5A</a></li>
	<li>BOOK: Texturing and Modelinng: A procedural approach: <a href="https://www.csee.umbc.edu/~ebert/book2e.html" target="_blank">https://www.csee.umbc.edu/~ebert/book2e.html</a></li>
	<li>Moment Shadow Mapping: <a href="https://therealmjp.github.io/posts/shadow-sample-update/" target="_blank">https://therealmjp.github.io/posts/shadow-sample-update/</a></li>
	<li>Undo and Redo implementation pt 1: <a href="https://therealmjp.github.io/posts/undo-and-redo/" target="_blank">https://therealmjp.github.io/posts/undo-and-redo/</a></li>
	<li>Undo and Redo implementation pt 2: <a href="https://therealmjp.github.io/posts/undo-and-redo-take-2/" target="_blank">https://therealmjp.github.io/posts/undo-and-redo-take-2/</a></li>
	<li>BOOK: OpenGL insights<a href="http://openglinsights.com/index.html" target="_blank">http://openglinsights.com/index.html</a></li>
	<li>Great video on ECS: <a href="https://www.youtube.com/watch?v=JxI3Eu5DPwE" target="_blank">https://www.youtube.com/watch?v=JxI3Eu5DPwE</a></li>
	<li>Minecraft in C github: <a href="https://github.com/johnpayne-dev/MinecraftC" target="_blank">https://github.com/johnpayne-dev/MinecraftC</a></li>
	<li>GCC C Preprocessor: <a href="https://gcc.gnu.org/onlinedocs/cpp/index.html" target="_blank">https://gcc.gnu.org/onlinedocs/cpp/index.html</a></li>
	<li>Make a clone of this: <a href="https://www.reddit.com/r/gamedev/comments/rtifsj/i_can_finally_say_after_many_many_hotfixes_that_i/" target="_blank">https://www.reddit.com/r/gamedev/comments/rtifsj/i_can_finally_say_after_many_many_hotfixes_that_i/</a></li>
	<li>PNG file info: <a href="http://www.libpng.org/pub/png/spec/1.2/PNG-Contents.html" target="_blank">http://www.libpng.org/pub/png/spec/1.2/PNG-Contents.html</a></li>
	<li>PNG throwaway application in C: <a href="https://gitlab.com/tsoding/png" target="_blank">https://gitlab.com/tsoding/png</a></li>
	<li>Struct inheritance in C discussion: <a href="https://stackoverflow.com/questions/1114349/struct-inheritance-in-c" target="_blank">https://stackoverflow.com/questions/1114349/struct-inheritance-in-c</a></li>
	<li>Expert C (e-book): <a href="https://progforperf.github.io/Expert_C_Programming.pdf" target="_blank">https://progforperf.github.io/Expert_C_Programming.pdf</a></li>
	<li>Bentrleys Rule of Optimization (slides): <a href="https://progforperf.github.io/Bentley_Rules.pdf" target="_blank">https://progforperf.github.io/Bentley_Rules.pdf</a></li>
	<li>What every programmer should know about memory (e-book): <a href="https://progforperf.github.io/cpumemory.pdf" target="_blank">https://progforperf.github.io/cpumemory.pdf</a></li>
	<li>Project Based Tutorials In C: <a href="https://github.com/rby90/project-based-tutorials-in-c" target="_blank">https://github.com/rby90/project-based-tutorials-in-c</a></li>
	<li>C unit testing discussion: <a href="https://www.reddit.com/r/C_Programming/comments/alpnvr/c_unit_testing/" target="_blank">https://www.reddit.com/r/C_Programming/comments/alpnvr/c_unit_testing/</a></li>
	
	<p>C JAM notes:</p>
	<li>Top 10 Daily Tips for Gamedevs: <a href="https://www.reddit.com/r/gamedev/comments/rtpj43/top_10_daily_game_dev_tips_2021/" target="_blank">https://www.reddit.com/r/gamedev/comments/rtpj43/top_10_daily_game_dev_tips_2021/</a></li>
	<li>Cutscene handling discussion: <a href="https://www.reddit.com/r/gamedev/comments/rtl02s/2d_rpg_cutscene_handling/" target="_blank">https://www.reddit.com/r/gamedev/comments/rtl02s/2d_rpg_cutscene_handling/</a></li>
	<li>Join if anybody else joins: <a href="https://itch.io/jam/c-jam" target="_blank">https://itch.io/jam/c-jam</a></li>
	<li><Game AI pro: <a href="http://www.gameaipro.com/" target="_blank">http://www.gameaipro.com/</a></li>
	<li>Procedural Content Generation in Games: <a href="http://pcgbook.com/" target="_blank">http://pcgbook.com/</a></li>
	<li>3D Game Shaders for Beginners: <a href="https://lettier.github.io/3d-game-shaders-for-beginners/index.html" target="_blank">https://lettier.github.io/3d-game-shaders-for-beginners/index.html</a></li>
	<li>Computer Graphics from Skratch: <a href="https://gabrielgambetta.com/computer-graphics-from-scratch/" target="_blank">https://gabrielgambetta.com/computer-graphics-from-scratch/</a></li>
	<li>OpenGL: How to draw a sphere: <a href="http://www.songho.ca/opengl/gl_sphere.html" target="_blank">http://www.songho.ca/opengl/gl_sphere.html</a></li>
	<li>Wave Function Collapse library (Take note of the coding): <a href="https://github.com/krychu/wfc" target="_blank">https://github.com/krychu/wfc</a></li>
	<li>Wave Function Collapse tutorial: <a href="https://www.gridbugs.org/wave-function-collapse/" target="_blank">https://www.gridbugs.org/wave-function-collapse/</a></li>
	<li>Modified ECS for turnbased games: <a href="https://www.gridbugs.org/modifying-entity-component-system-for-turn-based-games/" target="_blank">https://www.gridbugs.org/modifying-entity-component-system-for-turn-based-games/</a></li>
	<li>Notes on Axis Angle Rotation: <a href="https://github.com/KadaB/axis_angle_rotation" target="_blank">https://github.com/KadaB/axis_angle_rotation</a></li>
	<li>The architecture of space-shooter.c: (Nice writeup on a C game in OpenGL)<a href="https://github.com/tsherif/space-shooter.c/blob/master/ARCHITECTURE.md" target="_blank">https://github.com/tsherif/space-shooter.c/blob/master/ARCHITECTURE.md</a></li>
	<li>Xinput for controller on Windows: <a href="https://docs.microsoft.com/en-us/windows/win32/api/xinput/" target="_blank">https://docs.microsoft.com/en-us/windows/win32/api/xinput/</a></li>
	<li>Makefiles for C/C++ projects: <a href="https://avikdas.com/2019/12/16/makefiles-for-c-cpp-projects.html" target="_blank">https://avikdas.com/2019/12/16/makefiles-for-c-cpp-projects.html</a></li>
	<li>Clang Security Analyzer<a href="https://clang.llvm.org/docs/analyzer/checkers.html#security" target="_blank">https://clang.llvm.org/docs/analyzer/checkers.html#security</a></li>
	<li>Survey of Temporal Antialiasing Technique (Paper)<a href="http://behindthepixels.io/assets/files/TemporalAA.pdf" target="_blank">http://behindthepixels.io/assets/files/TemporalAA.pdf</a></li>
	<li>Checkerboard Rendering for integrated graphics<a href="https://www.intel.com/content/www/us/en/developer/articles/technical/checkerboard-rendering-for-real-time-upscaling-on-integrated-graphics.html" target="_blank">https://www.intel.com/content/www/us/en/developer/articles/technical/checkerboard-rendering-for-real-time-upscaling-on-integrated-graphics.html</a></li>
	<li>Dynamic Temporal Antialiasing and Upsampling<a href="https://www.activision.com/cdn/research/Dynamic_Temporal_Antialiasing_and_Upsampling_in_Call_of_Duty_v4.pdf" target="_blank">https://www.activision.com/cdn/research/Dynamic_Temporal_Antialiasing_and_Upsampling_in_Call_of_Duty_v4.pdf</a></li>
	<li>Tons of good articles and tutorials: <a href="https://www.iquilezles.org/index.html" target="_blank">https://www.iquilezles.org/index.html</a></li>
	<li>Antialiasing acronyms: <a href="https://twitter.com/Miamiamia0103/status/1490355292487487494/photo/1" target="_blank">https://twitter.com/Miamiamia0103/status/1490355292487487494/photo/1</a></li>
	<li>Explaining Homogenous Coordinates and Projective Geometry: <a href="https://www.tomdalling.com/blog/modern-opengl/explaining-homogenous-coordinates-and-projective-geometry/" target="_blank">https://www.tomdalling.com/blog/modern-opengl/explaining-homogenous-coordinates-and-projective-geometry/</a></li>
	<li>OpenGL FAQ and Troubleshooting guide: <a href="https://www.inf.pucrs.br/~flash/tcg/aulas/faq.pdf" target="_blank">https://www.inf.pucrs.br/~flash/tcg/aulas/faq.pdf</a></li>
	<li>Textmode graphics written in C<a href="https://github.com/saccharineboi/TRex" target="_blank">https://github.com/saccharineboi/TRex</a></li>
	<li>C Discord Bot: <a href="https://github.com/Cogmasters/concord" target="_blank">https://github.com/Cogmasters/concord</a></li>
	<li>Higher level programming in C library: <a href="https://libcello.org/" target="_blank">https://libcello.org/</a></li>
	<li>A static analyzer for C<a href="https://github.com/facebook/infer" target="_blank">https://github.com/facebook/infer</a></li>
	<li>Darkmode tweak for Win10<a href="https://github.com/adzm/win32-darkmode" target="_blank">https://github.com/adzm/win32-darkmode</a></li>
	<li>Dark patterns in gaming: <a href="https://www.darkpattern.games/" target="_blank">https://www.darkpattern.games/</a></li>
	<li>Webgpu for C: <a href="https://github.com/webgpu-native/webgpu-headers/blob/main/webgpu.h" target="_blank">https://github.com/webgpu-native/webgpu-headers/blob/main/webgpu.h</a></li>
	<li>Digital Forensic Wiki: <a href="https://forensicswiki.xyz/wiki/index.php?title=Main_Page" target="_blank">https://forensicswiki.xyz/wiki/index.php?title=Main_Page</a></li>
	<li>TUI with double buffering: <a href="https://github.com/velorek1/lynx" target="_blank">https://github.com/velorek1/lynx</a></li>
	<li>Writeup on how double buffering is done in cmd: <a href="http://oldstuff286.blogspot.com/2017/" target="_blank">http://oldstuff286.blogspot.com/2017/</a></li>
	<li>How to debug OpenGL: <a href="https://www.youtube.com/watch?v=Wk145_jUsBk" target="_blank">https://www.youtube.com/watch?v=Wk145_jUsBk</a></li>
	<li>C testing libraries (reddit thread): <a href="https://www.reddit.com/r/cprogramming/comments/tjauxt/commonly_used_cunit_testing_framework_in_2022/" target="_blank">https://www.reddit.com/r/cprogramming/comments/tjauxt/commonly_used_cunit_testing_framework_in_2022/</a></li>
	<li>OpenGL error checking thread (Stack Overflow): <a href="https://stackoverflow.com/questions/11256470/define-a-macro-to-facilitate-opengl-command-debugging" target="_blank">https://stackoverflow.com/questions/11256470/define-a-macro-to-facilitate-opengl-command-debugging</a></li>
	<li>OpenGL error lib: BuGLe<a href="https://www.opengl.org/sdk/tools/BuGLe/index.php" target="_blank">https://www.opengl.org/sdk/tools/BuGLe/index.php</a></li>
	<li>Cgltf loader<a href="https://github.com/jkuhlmann/cgltf" target="_blank">https://github.com/jkuhlmann/cgltf</a></li>
	<li>3D level design: the essential: <a href="https://wireframe.raspberrypi.com/articles/3d-level-design-the-essential-techniques?fbclid=IwAR2K9aKwfPzN0oksJql8K5OETqw1M0KaBJ4vbE6DBCPWDrb0YsVziutdVM0" target="_blank">https://wireframe.raspberrypi.com/articles/3d-level-design-the-essential-techniques?fbclid=IwAR2K9aKwfPzN0oksJql8K5OETqw1M0KaBJ4vbE6DBCPWDrb0YsVziutdVM0</a></li>
	<li>Procgen online book: <a href="http://pcgbook.com/" target="_blank">http://pcgbook.com/</a></li>
	<li>Lots of great win32 api tricks: <a href="http://www.catch22.net/tuts/win32/tips-and-tricks-part-2#" target="_blank">http://www.catch22.net/tuts/win32/tips-and-tricks-part-2#</a></li>
	<li>Enable custom theme in win32<a href="https://docs.microsoft.com/zh-cn/windows/win32/controls/cookbook-overview" target="_blank">https://docs.microsoft.com/zh-cn/windows/win32/controls/cookbook-overview</a></li>
	<li>Win32 Hotkey example: <a href="https://zetcode.com/gui/winapi/firststeps/" target="_blank">https://zetcode.com/gui/winapi/firststeps/</a></li>
	<li>Collision Detection tutorial: <a href="http://www.jeffreythompson.org/collision-detection/index.php" target="_blank">http://www.jeffreythompson.org/collision-detection/index.php</a></li>
	<li>DirectStorage Windows: <a href="https://github.com/microsoft/DirectStorage" target="_blank">https://github.com/microsoft/DirectStorage</a></li>
	<li>Fundations of GE: Vol 2: rendering: ><a href="https://foundationsofgameenginedev.com/FGED2-sample.pdf" target="_blank">https://foundationsofgameenginedev.com/FGED2-sample.pdf</a></li>
	<li>Paint a landscape with math: AWESOME!<a href="https://www.reddit.com/r/GraphicsProgramming/comments/u62ssy/painting_a_landscape_using_mathematics/" target="_blank">https://www.reddit.com/r/GraphicsProgramming/comments/u62ssy/painting_a_landscape_using_mathematics/</a></li>
	<li>Painting a character with math: <a href="https://www.youtube.com/watch?v=8--5LwHRhjk" target="_blank">https://www.youtube.com/watch?v=8--5LwHRhjk</a></li>
	<li>Prototypes for modelling: <a href="https://gameprogrammingpatterns.com/prototype.html#prototypes-for-data-modeling" target="_blank">https://gameprogrammingpatterns.com/prototype.html#prototypes-for-data-modeling</a></li>
	<li>Raytracer for those who skipped math: <a href="https://zserge.com/posts/raytracer/" target="_blank">https://zserge.com/posts/raytracer/</a></li>
	<li>Deferred Shader Buffer: <a href="https://www.reddit.com/r/GraphicsProgramming/comments/uf4ykj/faster_visibility_bufferdeferred_material/" target="_blank">https://www.reddit.com/r/GraphicsProgramming/comments/uf4ykj/faster_visibility_bufferdeferred_material/</a></li>
	<li>Notes on Data Structures and Programming in C<a href="http://cs.yale.edu/homes/aspnes/classes/223/notes.html" target="_blank">http://cs.yale.edu/homes/aspnes/classes/223/notes.html</a></li>
	<li>How to make lowpoly hands look good: <a href="https://www.reddit.com/r/gamedev/comments/urwmab/heres_how_to_achieve_nice_looking_full_five/" target="_blank">https://www.reddit.com/r/gamedev/comments/urwmab/heres_how_to_achieve_nice_looking_full_five/</a></li>
	<li>Curated list of collision detection stuff: <a href="https://github.com/jslee02/awesome-collision-detection" target="_blank">https://github.com/jslee02/awesome-collision-detection</a></li>
	<li>Build system (Cmake) example for windows: <a href="https://github.com/Goldan32/c-build-systems/tree/master/windows" target="_blank">https://github.com/Goldan32/c-build-systems/tree/master/windows</a></li>
	<li>How isometric coordinates work in a game: <a href="https://www.reddit.com/r/gamedev/comments/v2duc7/how_isometric_coordinates_work_in_2d_games/" target="_blank">https://www.reddit.com/r/gamedev/comments/v2duc7/how_isometric_coordinates_work_in_2d_games/</a></li>
	<li>Procgen: MarkovJunior probabilistic pattern matching (THE best Procgen): <a href="https://github.com/mxgmn/MarkovJunior" target="_blank">https://github.com/mxgmn/MarkovJunior</a></li>
	<li>Procgen: Wave Function Collapse (The best Procgen for 2D): <a href="https://github.com/mxgmn/WaveFunctionCollapse" target="_blank">https://github.com/mxgmn/WaveFunctionCollapse</a></li>
	<li>Shape library in C99: <a href="https://prideout.net/shapes" target="_blank">https://prideout.net/shapes</a></li>
	<li>Great Wave Function Collapse video explanation (Reddit thread): <a href="https://www.reddit.com/r/gamedev/comments/v563rn/superpositions_sudoku_the_wave_function_collapse/" target="_blank">https://www.reddit.com/r/gamedev/comments/v563rn/superpositions_sudoku_the_wave_function_collapse/</a></li>
	<li>Worley noise volumetric clouds example (in clojour)<a href="https://gist.github.com/wedesoft/7ec7d31ac031169ad4c6713ba6ebe598" target="_blank">https://gist.github.com/wedesoft/7ec7d31ac031169ad4c6713ba6ebe598</a></li>
	<li>Best Win32 Programming Book (5th edition): <a href="https://vulms.vu.edu.pk/Courses/CS410/Downloads/Charles%20Petzold%20-%20Programming%20Windows%20-%205th%20Ed.pdf" target="_blank">https://vulms.vu.edu.pk/Courses/CS410/Downloads/Charles%20Petzold%20-%20Programming%20Windows%20-%205th%20Ed.pdf</a></li>
	<li>Free Blender 3D model tutorials: <a href="https://quaternius.com/tutorials.html" target="_blank">https://quaternius.com/tutorials.html</a></li>
	<li>Domfetch: Find expired domains: <a href="https://www.reddit.com/r/alphaandbetausers/comments/vjno60/domfetchcom_we_created_a_free_tool_where_you_can/" target="_blank">https://www.reddit.com/r/alphaandbetausers/comments/vjno60/domfetchcom_we_created_a_free_tool_where_you_can/</a></li>
	<li>Soccer AI write-up: <a href="http://properlydecent.com/blog/soccer_game_development_concepts/" target="_blank">http://properlydecent.com/blog/soccer_game_development_concepts/</a></li>
	<li>Reddit question regarding soccer AI: <a href="https://www.reddit.com/r/howdidtheycodeit/comments/vkjoo9/ai_positioning_in_sports_games_like_fifa/" target="_blank">https://www.reddit.com/r/howdidtheycodeit/comments/vkjoo9/ai_positioning_in_sports_games_like_fifa/</a></li>
	<li>Perlin Noise writeup: <a href="https://eev.ee/blog/2016/05/29/perlin-noise/" target="_blank">https://eev.ee/blog/2016/05/29/perlin-noise/</a></li>
	<li>Procgen math with personallity (video): <a href="https://www.youtube.com/watch?v=KPoeNZZ6H4s" target="_blank">https://www.youtube.com/watch?v=KPoeNZZ6H4s</a></li>
	<li>Triangular grid: <a href="https://kvachev.com/blog/posts/triangular-grid/" target="_blank">https://kvachev.com/blog/posts/triangular-grid/</a></li>
	<li>Code examples for drawing shapes: <a href="https://iquilezles.org/articles/distfunctions2d/" target="_blank">https://iquilezles.org/articles/distfunctions2d/</a></li>
	<li>Ambient Occlusion presentation by Microsoft:<a href="https://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf" target="_blank">https://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf</a></li>
	<li>SSAO ambient occlusion by John Chapman: <a href="http://john-chapman-graphics.blogspot.com/2013/01/ssao-tutorial.html" target="_blank">http://john-chapman-graphics.blogspot.com/2013/01/ssao-tutorial.html</a></li>
	<li>Tile Bitmask: <a href="https://gamedevelopment.tutsplus.com/tutorials/how-to-use-tile-bitmasking-to-auto-tile-your-level-layouts--cms-25673" target="_blank">https://gamedevelopment.tutsplus.com/tutorials/how-to-use-tile-bitmasking-to-auto-tile-your-level-layouts--cms-25673</a></li>
	<li>Graphicscodex online book: <a href="http://graphicscodex.com/" target="_blank">http://graphicscodex.com/</a></li>
	<li>GTK4 tutorial for beginners: <a href="https://github.com/ToshioCP/Gtk4-tutorial" target="_blank">https://github.com/ToshioCP/Gtk4-tutorial</a></li>
	<li>Create a new thread win32: <a href="https://riptutorial.com/winapi/example/13881/create-a-new-thread" target="_blank">https://riptutorial.com/winapi/example/13881/create-a-new-thread</a></li>
	<li>Pixel Editor C tutorial (Really good!): <a href="https://www.youtube.com/watch?v=GXdT8twQxxI" target="_blank">https://www.youtube.com/watch?v=GXdT8twQxxI</a></li>
	<li>Quaternions: A practical guide: <a href="https://www.anyleaf.org/blog/quaternions:-a-practical-guide" target="_blank">https://www.anyleaf.org/blog/quaternions:-a-practical-guide</a></li>
	<li>Game AI Pro (Curated list of resources): <a href="http://www.gameaipro.com/" target="_blank">http://www.gameaipro.com/</a></li>
	<li>Gamedev Resource Megalist: <a href="https://github.com/notpresident35/The-Gamedev-Resource-Mega-List" target="_blank">https://github.com/notpresident35/The-Gamedev-Resource-Mega-List</a></li>
	<li>Polygon Mesh Lib for reference: <a href="https://www.pmp-library.org/" target="_blank">https://www.pmp-library.org/</a></li>
	<li>Porting a game written in C to Emscripten writeup: <a href="https://github.com/tsherif/space-shooter.c/blob/master/ARCHITECTURE.md" target="_blank">https://github.com/tsherif/space-shooter.c/blob/master/ARCHITECTURE.md</a></li>
	<li>Gaussian blur implementation (with code): <a href="https://blog.en.uwa4d.com/2022/08/11/screen-post-processing-effects-chapter-1-basic-algorithm-of-gaussian-blur-and-its-implementation/" target="_blank">https://blog.en.uwa4d.com/2022/08/11/screen-post-processing-effects-chapter-1-basic-algorithm-of-gaussian-blur-and-its-implementation/</a></li>
	<li>C++ Engine with OpenAL example: <a href="https://github.com/jackw1111/3d-graphics-project/tree/master/engine/core/graphics/src" target="_blank">https://github.com/jackw1111/3d-graphics-project/tree/master/engine/core/graphics/src</a></li>
	<li>Operator overloading in C: <a href="https://open-std.org/jtc1/sc22/wg14/www/docs/n3051.pdf" target="_blank">https://open-std.org/jtc1/sc22/wg14/www/docs/n3051.pdf</a></li>
	<li>Deconstructing Bezier curves: <a href="http://blog.pkh.me/p/33-deconstructing-be%cc%81zier-curves.html" target="_blank">http://blog.pkh.me/p/33-deconstructing-be%cc%81zier-curves.html</a></li>
	<li>The most useful math formulas: <a href="http://blog.pkh.me/p/29-the-most-useful-math-formulas.html" target="_blank">http://blog.pkh.me/p/29-the-most-useful-math-formulas.html</a></li>
	<li>Biome chart: <a href="https://upload.wikimedia.org/wikipedia/commons/6/68/Climate_influence_on_terrestrial_biome.svg" target="_blank">https://upload.wikimedia.org/wikipedia/commons/6/68/Climate_influence_on_terrestrial_biome.svg</a></li>
	<li>malloc thread: <a href=""https://www.reddit.com/r/C_Programming/comments/uemqc4/i_just_heard_that_there_is_another_type_of_malloc/i6ovntd/ target="_blank">https://www.reddit.com/r/C_Programming/comments/uemqc4/i_just_heard_that_there_is_another_type_of_malloc/i6ovntd/</a></li>
	<li>try-catch in C thread: <a href="https://old.reddit.com/r/C_Programming/comments/w3ltl4/try_catch_blocks_in_c/igxe30x/" target="_blank">https://old.reddit.com/r/C_Programming/comments/w3ltl4/try_catch_blocks_in_c/igxe30x/</a></li>
	<li>Continuous Distance-Dependent Level of Detail for Rendering Heightmaps: <a href="https://aggrobird.com/files/cdlod_latest.pdf" target="_blank">https://aggrobird.com/files/cdlod_latest.pdf</a></li>
	<li>Poolballs in glsl only example: <a href="https://www.getlazarus.org/pool/balls/" target="_blank">https://www.getlazarus.org/pool/balls/</a></li>
	<li>Procgen animal drawing + walking cycle: <a href="https://video.twimg.com/tweet_video/DXSke1eWkAAbj6b.mp4" target="_blank">https://video.twimg.com/tweet_video/DXSke1eWkAAbj6b.mp4</a></li>
	<li>Formula for various shapes: <a href="https://iquilezles.org/articles/distfunctions/" target="_blank">https://iquilezles.org/articles/distfunctions/</a></li>
	<li>Signed Distance Fields of a box (procgen): <a href="https://www.youtube.com/watch?v=62-pRVZuS5c" target="_blank">https://www.youtube.com/watch?v=62-pRVZuS5c</a></li>
	<li>Raymarching implementation writeup: <a href="https://tavianator.com/2022/ray_box_boundary.html" target="_blank">https://tavianator.com/2022/ray_box_boundary.html</a></li>
	<li>Qubic noise: <a href="https://jobtalle.com/cubic_noise.html" target="_blank">https://jobtalle.com/cubic_noise.html</a></li>
	<li>Olive.c graphics lib that renders to the browser: <a href="https://tsoding.org/olive.c/" target="_blank">https://tsoding.org/olive.c/</a></li>
	<li>Awesome Github Readme Profile List: <a href="https://github.com/MrAlpha786/awesome-github-profile-readme" target="_blank">https://github.com/MrAlpha786/awesome-github-profile-readme</a></li>
	<li>Blue Noise Dithering clouds: <a href="https://www.wedesoft.de/software/2022/09/21/blue-noise-dithering/" target="_blank">https://www.wedesoft.de/software/2022/09/21/blue-noise-dithering/</a></li>
	<li>Neural Control Variates Light simulation paper: <a href="https://arxiv.org/pdf/2006.01524.pdf" target="_blank">https://arxiv.org/pdf/2006.01524.pdf</a></li>
	<li>Hot reloading example: <a href="https://github.com/M-Fatah/hot_reloading_with_cmake" target="_blank">https://github.com/M-Fatah/hot_reloading_with_cmake</a></li>
	<li>Write a game engine in C: <a href="https://prdeving.wordpress.com/category/game-development/" target="_blank">https://prdeving.wordpress.com/category/game-development/</a></li>
	<li>Game Engine Architecture articles: <a href="https://www.haroldserrano.com/articles#gameenginesection" target="_blank">https://www.haroldserrano.com/articles#gameenginesection</a></li>
	<li>Quaternions explanation: <a href="https://lordarkam.wordpress.com/2022/08/28/quaternions-a-geometrical-interpretation/" target="_blank">https://lordarkam.wordpress.com/2022/08/28/quaternions-a-geometrical-interpretation/</a></li>
	<li>Real-Time Polygonal-Light Shading with Linearly Transformed Cosines (paper): <a href="https://drive.google.com/file/d/0BzvWIdpUpRx_d09ndGVjNVJzZjA/view?resourcekey=0-21tmiqk55JIZU8UoeJatXQ" target="_blank">https://drive.google.com/file/d/0BzvWIdpUpRx_d09ndGVjNVJzZjA/view?resourcekey=0-21tmiqk55JIZU8UoeJatXQ</a></li>
	<li>Create a shared and static library with GNU compiler: <a href="https://renenyffenegger.ch/notes/development/languages/C-C-plus-plus/GCC/create-libraries/index" target="_blank">https://renenyffenegger.ch/notes/development/languages/C-C-plus-plus/GCC/create-libraries/index</a></li>
	<li>Contructive Solid Geometry video: <a href="https://www.youtube.com/watch?v=Iqmg4gblreo" target="_blank">https://www.youtube.com/watch?v=Iqmg4gblreo</a></li>
	<li>CSG examples and demo:<a href="https://realtimecsg.com/" target="_blank">https://realtimecsg.com/</a></li>
	<li>Cube Map generation detailed example: <a href="https://logins.github.io/graphics/2022/09/26/CubemapGenerationWithOpenCV.html" target="_blank">https://logins.github.io/graphics/2022/09/26/CubemapGenerationWithOpenCV.html</a></li>
	<li>Importance based shadow mapping article: <a href="http://john-chapman-graphics.blogspot.com/2013/01/shadow-map-allocation.html" target="_blank">http://john-chapman-graphics.blogspot.com/2013/01/shadow-map-allocation.html</a></li>
	<li>libSQL repo: <a href="https://github.com/libsql/libsql" target="_blank">https://github.com/libsql/libsql</a></li>
	<li>Makefile tutorial: <a href="https://github.com/clemedon/Makefile_tutor" target="_blank">https://github.com/clemedon/Makefile_tutor</a></li>
	<li>How Raytracing works and how CGI uses it (reddit thread): <a href="https://www.reddit.com/r/GraphicsProgramming/comments/y0xjh2/how_ray_tracing_modern_cgi_works_and_how_to_do_it/" target="_blank">https://www.reddit.com/r/GraphicsProgramming/comments/y0xjh2/how_ray_tracing_modern_cgi_works_and_how_to_do_it/</a></li>
	<li>FFmpeg cheatsheet: <a href="https://gist.github.com/steven2358/ba153c642fe2bb1e47485962df07c730" target="_blank">https://gist.github.com/steven2358/ba153c642fe2bb1e47485962df07c730</a></li>
	<li>Reflections from local cubemap: <a href="https://developer.arm.com/documentation/102179/0100/Implement-reflections-with-a-local-cubemap" target="_blank">https://developer.arm.com/documentation/102179/0100/Implement-reflections-with-a-local-cubemap</a></li>
	<li>Realtime ray tracing in games: <a href="https://www.intel.com/content/www/us/en/developer/articles/guide/real-time-ray-tracing-in-games.html" target="_blank">https://www.intel.com/content/www/us/en/developer/articles/guide/real-time-ray-tracing-in-games.html</a></li>
	<li>Windows Alternate Data Stream (hacking): <a href="https://www.bleepingcomputer.com/tutorials/windows-alternate-data-streams/" target="_blank">https://www.bleepingcomputer.com/tutorials/windows-alternate-data-streams/</a></li>
	<li>Pixel perfect collition detection in C: <a href="https://www.reddit.com/r/C_Programming/comments/108idah/pixel_perfect_collision_detection_in_c/" target="_blank">https://www.reddit.com/r/C_Programming/comments/108idah/pixel_perfect_collision_detection_in_c/</a></li>
	<li>Lerp explained video: <a href="https://www.reddit.com/r/gamedev/comments/10yz4l1/did_a_video_exploring_lerp_in_detail_how_to_get/" target="_blank">https://www.reddit.com/r/gamedev/comments/10yz4l1/did_a_video_exploring_lerp_in_detail_how_to_get/</a></li>
	<li>Terrain generation breakdown: <a href="https://kbrecordzz.com/2023/02/23/terrain/" target="_blank">https://kbrecordzz.com/2023/02/23/terrain/</a></li>
	<li>Texture blending techniques writeup: <a href="https://kbrecordzz.com/2022/12/17/banjokazooie/" target="_blank">https://kbrecordzz.com/2022/12/17/banjokazooie/</a></li>
	<li>Minimal Cross Platform Graphics library (nice Win32 keyboard demo)<a href="https://zserge.com/posts/fenster/" target="_blank">https://zserge.com/posts/fenster/</a></li>
	<li>libnativedialog: <a href="https://github.com/AndroGR/nvdialog" target="_blank">https://github.com/AndroGR/nvdialog</a></li>
	<li>libwinsane: <a href="https://github.com/skeeto/scratch/tree/master/libwinsane" target="_blank">https://github.com/skeeto/scratch/tree/master/libwinsane</a></li>
	<li>Reflection in local cubemap: <a href="https://developer.arm.com/documentation/102179/0100/Implement-reflections-with-a-local-cubemap" target="_blank">https://developer.arm.com/documentation/102179/0100/Implement-reflections-with-a-local-cubemap</a></li>
	<li>Soft body dynamics: <a href="https://www.reddit.com/r/howdidtheycodeit/comments/x3eywr/how_do_games_do_car_crashes/" target="_blank">https://www.reddit.com/r/howdidtheycodeit/comments/x3eywr/how_do_games_do_car_crashes/</a></li>
	<li>Rigid Body System paper: <a href="https://matthias-research.github.io/pages/publications/PBDBodies.pdf" target="_blank">https://matthias-research.github.io/pages/publications/PBDBodies.pdf</a></li>
	<li>Two-View Pose Estimation and Direct-Mesh Scene Reconstruction from Image Triangulation<a href="https://github.com/weigert/t-pose" target="_blank">https://github.com/weigert/t-pose</a></li>
	<li>Why we use const as members of a function thread: <a href="https://www.reddit.com/r/C_Programming/comments/uz6o2s/why_we_use_const_as_a_member_of_a_function/" target="_blank">https://www.reddit.com/r/C_Programming/comments/uz6o2s/why_we_use_const_as_a_member_of_a_function/</a></li>
	<li>How to make ps1 graphics: <a href="https://www.reddit.com/r/gamedev/comments/11nkoiw/how_to_make_ps1_graphics_in_4_minutes/" target="_blank">https://www.reddit.com/r/gamedev/comments/11nkoiw/how_to_make_ps1_graphics_in_4_minutes/</a></li>
	<li>Architectual Patterns for editors thread: <a href="https://www.reddit.com/r/gameenginedevs/comments/11ofki4/what_are_some_architectural_patterns_for_creating/" target="_blank">https://www.reddit.com/r/gameenginedevs/comments/11ofki4/what_are_some_architectural_patterns_for_creating/</a></li>
	<li>Writing a garbage collector in C: <a href="https://maplant.com/gc.html" target="_blank">https://maplant.com/gc.html</a></li>
	<li>Making a 3rd person camera: <a href="https://radcade.com/game-engine-agnostic-third-person-camera/" target="_blank">https://radcade.com/game-engine-agnostic-third-person-camera/</a></li>
	<li>Subspace Culling for Ray-Box intersection: <a href="https://gpuopen.com/download/publications/I3D2023_SubspaceCulling_updated.pdf" target="_blank">https://gpuopen.com/download/publications/I3D2023_SubspaceCulling_updated.pdf</a></li>
	<li>Win32 examples (including mouse): <a href="https://www.opengl.org/archives/resources/code/samples/win32_tutorial/" target="_blank">https://www.opengl.org/archives/resources/code/samples/win32_tutorial/</a></li>
	<li>Fast Fluid Simulation on the GPU: <a href="https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-38-fast-fluid-dynamics-simulation-gpu" target="_blank">https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles/chapter-38-fast-fluid-dynamics-simulation-gpu</a></li>
	<li>Awesome win32 window tutorial: <a href="https://www.codementor.io/@malortie/build-win32-api-app-windows-messages-c-cpp-visual-studio-du107sbya" target="_blank">https://www.codementor.io/@malortie/build-win32-api-app-windows-messages-c-cpp-visual-studio-du107sbya</a></li>
	<li>Awesome win32 resource tutorial: <a href="https://www.codementor.io/@malortie/win32-app-load-apply-resources-to-window-c-cpp-visual-studio-du107jdb4" target="_blank"></a>https://www.codementor.io/@malortie/win32-app-load-apply-resources-to-window-c-cpp-visual-studio-du107jdb4</li>
	<li>Line rendering deep overview: <a href="https://panthavma.com/articles/lines/deep-overview-extraction/" target="_blank">https://panthavma.com/articles/lines/deep-overview-extraction/</a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
	<li><a href="" target="_blank"></a></li>
</ul>





<pre><code>
FUN FACT

There are 365.2422 days in a Solar year. The average Gregorian calendar year has 365.2425 days. There is a 0.0003 day difference between the Gregorian and the Solar years. For this reason the Gregorian calendar will advance 1 day every 3,333 years.
</code></pre>

<pre><code>
KindFile3 3 poeng 4 timer siden 
I'd go with Macros:

#include <stdio.h>

#define __timing(f) do { printf("\n\nstarting\n"); f; printf("\nending"); }while(0);

int foo(){
    printf("foo!");
}

int bar(int i){
    printf("bar: %d!",i);
}

int main(){
    __timing(foo());
    __timing(bar(1));
    return 0;
}
This prints:

starting
foo!
ending

starting
bar: 1!
ending
Obviously you will need to replace printf("starting") and printf("ending") with the start and end timing functions, which I'd have it globally, so start set current time, and later do the math new time - old time.

And one neat thing about this is you can use _DEBUG flag and have 2 versions like:

#if _DEBUG
    #define __timing(f) do { printf("\n\nstarting\n"); f; printf("\nending"); }while(0);
#else
    #define __timing(f) do { f; }while(0);
So if NOT in _DEBUG mode you can disable it.
#endif
</code></pre>

<pre><code>
struct point makepoint (int x, int y)
{
	struct point temp;
	
	temp.x = x;
	temp.y = y;
	return temp;
}

struct rect screen;
struct point middle;
struct point makepoint(int, int);

screen.pt1 = makepoint(0, 0);
screen.pt2 = makepoint(XMAX, YMAX);
middle = makepoint((screen.pt1.x + screen.pt2.y) / 2, (screen.pt1.y + screen.pt2.y) / 2);
</code></pre>

<pre><code>
Best way to calculate normals of a changing mesh? CeruleanBoolean141
Hello again! I am working on a GPGPU project to simulate hydraulic erosion over some terrain. The map I start with has normals, but when the erosion changes the shape of the terrain mesh, I need these normals to update.
The only thing I can think to do is use a geometry shader to recalculate the normals (either every frame or every N frames). My question is: is a geometry shader the way to go, or is there a better solution?
Thanks to anyone who takes the time to read this.

If you're happy with the flat shaded look you can use the derivative functions to calculate a normal.

vec3 X = dFdx ( vertexPosition );
vec3 Y = dFdy ( vertexPosition );
vec3 normal = normalize ( cross ( X, Y ) );

Smooth normals are also possible using this technique but it involves multiple passes. Here's(*) an example implementation of that in Cinder.
* = Vertex displacement mapping is a technique where a texture or a procedural function is used to dynamically change the position of vertices in a mesh. It is often used to create a terrain with mountains from a height field, ocean waves or an animated flag.

For dynamically changing height fields, like an animated flag, not only the vertex position should change, but also its associated normal vector. One way to calculate the new normal would be to use a geometry shader. This is often called per-face normal computation on the GPU, because it can only calculate one normal vector for the whole triangle. The result looks faceted: each triangle will appear to be flat.

To overcome this, you can use a normal map. This is an additional texture that corresponds to the height field and contains offsets to the original surface normals. A shader can then fetch the normal from this texture on a per pixel basis. The great news is that normals are even automatically interpolated, so per-pixel shading will look incredibly smooth.

You should calculate a new normal map every time your height field (a.k.a. displacement map) changes. This can easily be done on the GPU. Using floating point textures, this is even easier and can be done using a simple fragment shader.

This sample will show you how to:

    render to a floating point texture to create a displacement map on-the-fly
    render the corresponding normal map, also a floating point texture
    use both maps to render an animated, transparent piece of cloth that looks a lot like Sony PlayStation's XrossMediaBar background (but that's just a coincidence, don't you think? ;))

All of this is done on the GPU, very little work remains for the CPU. The sample can therefor easily run at 300+ FPS. Note that you do need a modern GPU for this, with support for floating point textures and vertex shader texture fetch. If your GPU supports shader model 3, you're probably good to go.

Source: https://github.com/paulhoux/Cinder-Samples/tree/master/SmoothDisplacementMapping

Simulating Mesh shader in compute shader: https://tellusim.com/mesh-shader-emulation/
</code></pre>
</code></pre>

<pre><code>
/* allc.c - This showcases all the syntatic
 * features of the C programming language.
 */


/* preprocessing directive */
#if 1                  /* if directive */

#define NULL (void *)0 /* define directive */

#undef NULL            /* undef directive */

#ifdef D               /* ifdef directive */
#endif

#ifndef D              /* ifndef directive */
#endif

#pragma deadbeef       /* pragma directive */

#else                  /* else directive */ 

#if defined 0
#endif

#include <stdio.h>     /* include directive */

#error "error"         /* error directive */

#endif                 /* endif directive */

/* variadic macro */
#define VAMACRO(...) __VA_ARGS__

/* static assertion */
_Static_assert(sizeof(char) == 1, "test");

/* stringizing operator */
#define stringize(x) #x

/* token pasting operator */
#define concat(a, b) a##b

/* external storage types and example of variadic function */
extern int printf(const char *, ...);

/* function pointer */
int (*ifunc)(void);

/* array of function pointer */
int (*afunc[10])(void);

/* enumerations */
enum enum_t { EA, EB, EC, ED };

enum { VA, VB, VC, VD } enum_variation;

/* structures */
struct struct_t {
  char a, b, c;

  /* bitfields */
  int b1:4, b2:4;

  /* anonymous union */
  union {
    int e, f;
  };
};

struct {
  char a, b, c;
} struct_variation;

/* unions */
union union_t {
  int a, b;
  /* anonymous struct */
  struct {
    int c, d;
  };
};

union {char a;}; union_variation;

/* alias for a data type */
typedef struct struct_t struct_t;
typedef union union_t union_t;
typedef enum enum_t enum_t;

/* trigraphs */
int trigraphsavailable()
// returns 0 or 1; language standard C99 or later
{
  // are trigraphs available??/
  return 0;
  return 1;
}

_Noreturn void noret(void){
  return;
}


/* function */
int main() {
  /* primitive types */
  char a; int b;  float c;
  double d;  void *p; float _Complex Co = 1.0+(float _Complex)1.0i;
  _Bool Bo; 

  /* array declaration */
  int ar[10];

  /* string literal */
  u8"Hello " "C";
  u"Hello " "C";
  U"Hello " "C";
  L"Hello " "C";

  /* character literal*/
  a = 'a';

  /* escape sequence */
  "\n"   /* newline */
  "\t"   /* horizontal tab */
  "\\"   /* backslash */
  "\f"
  "\r"   /* carriage return */
  "\?"
  "\v";  /* vertical tab */

  /* stringize operator */
  stringize(Hello C); /* "Hello C" */

  /* Token pasting operator */
  concat(a, r); /* ar */

  /* demonic array */
  1 [ar] = 1;

  /* array designated initializer */
  int ar2[10] = {[0] = 1, [1] = 2, [2] = 3};

  /* struct designated initializer */
  struct_t s = {.a = 1, .b = 2, .c = 3};

  /* arrow operator */
  (&s)->a;

  /* dot operator */
  (struct_t){ }.a = 1;
  (union_t){ }.a = 1;

  /* compound literals */
  (int[]){1, 2, 3, 4};

  /* compound literals with designated initializer*/
  (int[]){[0] = 1, [1] = 2, [2] = 3, 4};

  /* assignment operators */
  a = 0;   a *= 1;
  a /= 1;  a += 1;
  a -= 1;  a <<= 1;
  a >>= 1; a &= 1;
  a ^= 1;  a |= 1;
  a %= 1;

  /* address and indirection operators */
  &a; *ar;

  /* arithmetic operators */
  1 + 1; /* ADD */
  1 - 1; /* SUB */
  1 / 2; /* DIV */
  1 * 1; /* MUL */
  1 % 1; /* MOD */

  /* logical operators */
  1 && 1; /* AND */
  1 || 0; /* OR */
  !1;     /* NOT */

  /* increment and decrement operators */
  a++; a--; /* post fix */
  ++a; --a; /* pre fix */

  /* bitwise operators */
  1 << 2; /* left shift */
  1 >> 2; /* right shift */
  1 | 1;  /* OR */
  1 & 1;  /* AND */
  1 ^ 1;  /* XOR */
  ~1;     /* 1st complement */

  /* relational operators */
  1 > 0;  /* 1 is greater than 0 */
  1 < 0;  /* 1 is less than 0 */
  1 == 0; /* 1 is equal to 0 */
  1 != 0; /* 1 is not equal to 0 */
  1 >= 0;  /* 1 is greater than or equal to 0 */
  1 <= 0;  /* 1 is less than or equal to 0 */

  /* conditions */
  if (1 > 0)
    ;
  else
    ;

  /* ternary operators */
  (1 > 0) ? 1 : 0; /* if 1 > 0, return 1, else 0 */

  /* label and goto */
  goto l1;
l1:

  /* loops */
  do while(0);
  while (0)
    ;
  for (; 0;)
    continue;
    ;

  /* block scoping */
  {}

  /* switch statement */
  switch (1){
    case 0:
    case 1:
    default:
    break;
  }

  /* digraphs */
  ar<:0:> = 1;    /* ar[0] */
  <% %>           /* { } */
  %:define BEEF   /* #define BEEF */

  /* demonic digraphs */
  0<:ar:> = 1;

  /* storage-class specifier */
  static st; register re;
  auto au; extern ex; _Thread_local static Thr; 

  /* _Generic */
  _Generic((10), int: 1, char: 'A', default: "test");

  /* type qualifiers */
  const cons;
  int *restrict res;
  volatile vo;
  _Atomic At;

  /* signed and unsigned types */
  signed si; unsigned un;

  /* sizeof, _Alignof and _Alignas operators */
  sizeof(int); _Alignof(int); 
  _Alignas(4) char calign[4];

  /* integer constants */
  1;     /* decimal */
  01  ;  /* octal */
  0x01;  /* hexadecimal */

  /* floating point constants */
    /* decimal floating point constant */
    1.0e+1f;
    1e1f;

    /* hexadecimal floating point constant */
    0x01.00p+1f;
    0x1p+1f;

  /* return keyword */
  return 0;
}
Pretty sure "demonic arrays" was stated in the C standard. ~I just made it up~

Forgive me if I forgotten something. I wonder how it would like with other language like C++.

8 kommentarerdellagregjemgive awardrapportercrosspost
alle 8 kommentarer
sorter etter: beste
formateringshjelpinnholdspolicy
save

[–]tstanisl 9 poeng 3 timer siden* 
Missing things:

variadic macro #define M(x, ...)
__VA_ARGS__,
_Alignas from C11
_Atomic
_Complex
_Bool
Edit

const, consider constant pointer
volatile is not a storage specifier
comma operator e.g. 1,2
const/restrict/static/volatile specifier for array parameters:

void foo(int A[restrict const volatile static 42]);

restrict and _Thread_local (thx to u/trBlueJ)

continue

long, including long double

short

_Generic

_Imaginary

_Noreturn

_Static_assert

__func__

u,U,l,L,ul, UL, ll,LL, ull, ULL suffixes for integer literals

u8, u, U, L prefixes for string literals

escape characters e.g. \n, \\

character literals, like 'a'

string literals, "Hello"

unary +, -, and * (dereference)

a ^= 1 is duplicated

macro concatenation ##

macro stringification #

macro defined

trailing comma for initilizers: int A[] = {1,2,3 , }

Edit2: - function calls (thx u/potterman28wxcv ) - bitfields in structs - casts

permalenkeembedlagrerapportergive awardsvar

[–]trBlueJ 2 poeng 2 timer siden 
There's also _Thread_local.

permalenkeembedlagreforeldrerapportergive awardsvar

[–]potterman28wxcv 2 poeng 2 timer siden 
And function calls! :P

permalenkeembedlagreforeldrerapportergive awardsvar

[–]tstanisl 3 poeng 3 timer siden 
you could typedef an enum or a function as well.

typedef enum { E } enum_type;
typedef int fun_type(int);
</code></pre>

<pre><code>
Did you know that in Blender you can easily animate oscillating objects with a single driver expression? ✨

1. Select your object
2. In its rotation write:
"# sin(frame / 300 * pi * 2 * 3) * 0.5"
where 3 is the number of swings it does, and 0.5 is the amplitude multiplier (use a bigger number for bigger swings), and 300 is your end frame
3. Enjoy the perfect loop!
Source: <a href="https://twitter.com/passivestar_/status/1665634739288518661">https://twitter.com/passivestar_/status/1665634739288518661</a>
</code></pre>

<h1><a name="">Pro tips</a></h1>
<ul>
	<li>
	<h3>Camera orientation</h3>
	<p>Name your cam-, eye- and up-vectors: px, py, pz (or camera_x, ...), vx, vy, vz (view_x, ...), r/ux, r/uy, r/uz (up_x, ...)</p>
	<pre><code>
	
EDIT: I am starting my reply from scratch as I may have assumed too much familiarity with the subject.

The problem you are facing is that your formulas are basically not correct : your formula for rotating left/right are correct under the assumption that the "up" vector (the vector pointing upward from the camera) is always [0 1 0]
... which is not the case if you also want to rotate up/down. 
And your formula for rotating up down is not correct since it only modifies the Y component and rotations do not work that way.

The correct way to handle that is:

to store 3 variables that represent the camera position (as you did). Let's call them Px, Py, Pz
to store 3 variables that represent the camera view direction (instead of your eyeX/Y/Z that encode the point the camera is looking at). Let's call them Vx, Vy, Vz
to store 3 variables that represent the camera right vector (or up vector, as you wish). Let's take the right vector, and call it Rx, Ry, Rz.
Alternatively, you can have a nice "Vector" class that represent vectors instead of storing 3 variables each time. This is a detail at this point.

Now, your method to move your camera forward just becomes:

Px += Vx;
Py += Vy;
Pz += Vz;
You can use, for example, Rodrigues formula to rotate (hoping nobody will launch at you the "quaternion" magic word to express their cleverness ;) ). The general self-contained code to rotate around an arbitrary axis would then be:

// rotate the vector (vx, vy, vz) around (ax, ay, az) by an angle "angle"

void rotate(double &vx, double &vy, double &vz, double ax, double ay, double az, double angle) {
  double ca = cos(angle);
  double sa = sin(angle);
  double crossx = -vy*az + vz*ay;
  double crossy = -vz*ax + vx*az;
  double crossz = -vx*ay + vy*ax;
  double dot = ax*vx + ay*vy + az*vz;
  double rx = vx*ca + crossx*sa + dot*ax*(1-ca);
  double ry = vy*ca + crossy*sa + dot*ay*(1-ca);
  double rz = vz*ca + crossz*sa + dot*az*(1-ca);
  vx = rx; 
  vy = ry; 
  vz = rz;
}
And make sure to keep normalized coordinates for your camera vectors.

Now, to specifically rotate your camera up/down when you press a button:

// rotate up:
rotate(Vx, Vy, Vz, Rx, Ry, Rz, some_CONSTANT_angle);
// rotate down:
rotate(Vx, Vy, Vz, Rx, Ry, Rz, - some_CONSTANT_angle);
To rotate left/right, you first need to compute the "Up" vector that doesn't need to be stored (unless you want to, but it is redundant), and rotate both your view direction and right vectors:

// find up vector using a cross product:
  double Ux = Ry*Vz - Rz*Vy;
  double Uy = Rz*Vx - Rx*Vz;
  double Uz = Rx*Vy - Ry*Vx;

//rotate left
    rotate(Rx, Ry, Rz, Ux, Uy, Uz, some_CONSTANT_angle);
    rotate(Vx, Vy, Vz, Ux, Uy, Uz, some_CONSTANT_angle);
// rotate right
    rotate(Rx, Ry, Rz, Ux, Uy, Uz, - some_CONSTANT_angle);
    rotate(Vx, Vy, Vz, Ux, Uy, Uz, - some_CONSTANT_angle);
Setting up your camera matrix now becomes:

  gluLookAt( Px, Py, Pz, Px+Vx, Py+Vy, Pz+Vz, Rx, Ry, Rz); // or is it Ux, Uy, Uz at the end? don't remember.
Of course, I didn't test any of this code, and wrote it now. Hope it works!
	</code></pre>
	</li>
	<li>Expand the first chapter with this knowledge: <a href="https://levelup.gitconnected.com/5-computer-hardware-concepts-that-every-programmer-should-know-32711c759dc0" tatget="_blank">https://levelup.gitconnected.com/5-computer-hardware-concepts-that-every-programmer-should-know-32711c759dc0</a></li>
	<li>
	<h3>Various GUI library compatable with C</h3>
	<ul>
		<li>wxWidget: <a href="https://docs.wxwidgets.org/3.0/overview_helloworld.html" target="_blank">https://docs.wxwidgets.org/3.0/overview_helloworld.html</a></li>
		<li>LVGL: (https://github.com/lvgl/lvgl) <a href="https://lvgl.io/" target="_blank">https://lvgl.io/</a></li>
		<li>NAPPGUI: <a href="https://nappgui.com/en/home/web/home.html" target="_blank">https://nappgui.com/en/home/web/home.html</a></li>
		<li>RayGUI: <a href="https://github.com/raysan5/raygui" target="_blank">https://github.com/raysan5/raygui</a></li>
		<li>Nuklear: <a href="https://github.com/vurtun/nuklear" target="_blank">https://github.com/vurtun/nuklear</a></li>
		<li>LibUI: <a href="https://github.com/andlabs/libui" target="_blank">https://github.com/andlabs/libui</a></li>
		<li>GTK: <a href="https://www.gtk.org/" target="_blank">https://www.gtk.org/</a></li>
		<li>FLTK: <a href="https://www.fltk.org/" target="_blank">https://www.fltk.org/</a></li>
		<li>CImGUI: <a href="https://github.com/cimgui/cimgui" target="_blank">https://github.com/cimgui/cimgui</a></li>
		<li>IUP Portable User Interface<a href="https://www.tecgraf.puc-rio.br/iup/" target="_blank">https://www.tecgraf.puc-rio.br/iup/</a></li>
		<li>Glade GUI: <a href="https://glade.gnome.org/" target="_blank">https://glade.gnome.org/</a></li>
		<li>MicroUI: <a href="https://github.com/rxi/microui" target="_blank">https://github.com/rxi/microui</a></li>
	</ul>
	</li>
	<li>
	<p>
	Reddit.com/u/alt-no-more

	This is probably a very basic question, but I'm not even sure how to describe it well enough to ask google the answer. I've written a simple program in C that creates a stack via a linked list.

	The stack seems to work as intented, but I get a weird result when I print.

	Here's my code:
	</p>
	<pre><code>

	#include &lt;stdio.h&gt;;
	#include &lt;stdlib.h&gt;;

	typedef struct node {
		int data;
		struct node *next;
	} node_t;

	typedef struct stack {
		node_t *head;
	} stack_t;

	void push(stack_t *stack, int value) {
		node_t *node = (node_t*) malloc(sizeof(node_t*));
		node-&gt;data = value;
		node-&gt;next = stack-&gt;head;
		stack-&gt;head = node;
	}

	int pop(stack_t *stack) {
		int value = stack-&gt;head-&gt;data;
		stack-&gt;head = stack-&gt;head-&gt;next;
		return value;
	}

	int main(void) {

		stack_t *stack1 = (stack_t*) malloc(sizeof(stack_t*));
		push(stack1, 1);
		push(stack1, 2);
		push(stack1, 3);
		push(stack1, 4);
		printf("stack1\t");
		printf("%d ", pop(stack1));
		printf("%d ", pop(stack1));
		printf("%d ", pop(stack1));
		printf("%d\n", pop(stack1));

		stack_t *stack2 = (stack_t*) malloc(sizeof(stack_t*));
		push(stack2, 1);
		push(stack2, 2);
		push(stack2, 3);
		push(stack2, 4);
		printf("stack2\t%d %d %d %d\n", pop(stack2), pop(stack2), pop(stack2), pop(stack2));

		return 0;
	}
	</code></pre>
	<p>
	When I run this, I get the following output:

	stack1  4 3 2 1
	stack2  1 2 3 4
	I'm not sure why this is. In stack1, it's clear that everything pops in the correct order.

	There must be something I don't understand about how printf works
	</p>
	</li>
	<li>
	<h3>PNG libraries for OpenGL</h3>
		<ul>
			<li><a href="https://lodev.org/lodepng/" target="_blank">https://lodev.org/lodepng/</a></li>
		</ul>
	</li>
	<li>
	<h3>How is header only libraries made?</h3>
	
	<p>The compiler basically doesn't care what the file is called, whether it's a C or H extension, it just compiles the code all the same - like it may as well all be in one big source file. 
	When you #include a header it just says "pretend this other file's contents exist here".

	Yes, there's the issue of scope - what you define in one C file doesn't exist in other C files unless externed via header but it's really not that complicated.</p>
	
	<p>Perhaps a simple example could help. Consider the following:</p>
	<pre><code>
	[header.h]
	int all_my_great_stuff();    /* forward declare */
	#ifdef IMPLEMENTATION
	int all_my_great stuff()     /* implementation */
	{
	  return 1;
	} 
	#endif
	</code></pre>
	
	<p>and</p>
	
	<pre><code>
	[main.c]
	#include "header,h"
	/* only has forward declare at this point */

	#define IMPLEMENTATION
	#include "header,h"
	/* has forward declare and implementation in *this* unit */
	<p>The main thing to note is that the IMPLEMENTATION should only defined in *one* unit or obviously you will get colliding symbols as multiple units provide the same stuff. 
	You could play around with static functions but that would be wasteful.</p>
	</code></pre>
	</li>
	<li>
	<h3>Function pointers in C</h3>
	<p>Source: <a href="https://stackoverflow.com/questions/840501/how-do-function-pointers-in-c-work" target="_blank">https://stackoverflow.com/questions/840501/how-do-function-pointers-in-c-work</a></p>
	<pre><code>
	Let's start with a basic function which we will be pointing to:

	int addInt(int n, int m) {
		return n+m;
	}
	First thing, let's define a pointer to a function which receives 2 ints and returns an int:

	int (*functionPtr)(int,int);
	Now we can safely point to our function:

	functionPtr = &addInt;
	Now that we have a pointer to the function, let's use it:

	int sum = (*functionPtr)(2, 3); // sum == 5
	Passing the pointer to another function is basically the same:

	int add2to3(int (*functionPtr)(int, int)) {
		return (*functionPtr)(2, 3);
	}
	We can use function pointers in return values as well (try to keep up, it gets messy):

	// this is a function called functionFactory which receives parameter n
	// and returns a pointer to another function which receives two ints
	// and it returns another int
	int (*functionFactory(int n))(int, int) {
		printf("Got parameter %d", n);
		int (*functionPtr)(int,int) = &addInt;
		return functionPtr;
	}
	But it's much nicer to use a typedef:

	typedef int (*myFuncDef)(int, int);
	// note that the typedef name is indeed myFuncDef

	myFuncDef functionFactory(int n) {
		printf("Got parameter %d", n);
		myFuncDef functionPtr = &addInt;
		return functionPtr;
	}
	</ocde></pre>
	</li>
	<p>OpenGL colors</p>
	<pre><code>
	glColor3f(0.0, 0.0, 0.0);	// black 
	glColor3f(1.0, 0.0, 0.0);	// red 
	glColor3f(0.0, 1.0, 0.0);	// green 
	glColor3f(1.0, 1.0, 0.0);	// yellow 
	glColor3f(0.0, 0.0, 1.0);	// blue 
	glColor3f(1.0, 0.0, 1.0);	// magenta 
	glColor3f(0.0, 1.0, 1.0);	// cyan 
	glColor3f(1.0, 1.0, 1.0);	// white
	</code></pre>
	</li>
	<li>
	<p>OpenGL functions reference Fixed Functional Pipeline vs Programmable 3.3 core</p>
	<pre><code>
	/*
	 * If you want to use any of these old functions from the
	 * fixed function pipeline you can use TinyGL or Mesa
	 * for software rendering version or implement them as wrappers
	 * around modern OpenGL
	void     glBegin(GLenum);
	void     glClear(GLbitfield);
	void     glClearColor(GLclampf, GLclmapf, GLclampf, GLclampf);
	void     glColor3f(GLfloat, GLfloat, GLfloat);
	void     glColor4f(GLfloat, GLfloat, GLfloat, GLfloat);
	void     glCullFace(GLenum);
	void     glDisable(GLenum);
	void     glEnable(GLenum);
	void     glEnd(void);
	void     glFrustum(GLdouble, GLdouble, GLdouble, GLdouble, GLdouble, GLdouble);
	GLubyte *glGetString(GLenum);
	void     glLoadIdentity(void);
	void     glMatrixMode(GLenum);
	void     glRotatef(GLfloat, GLfloat, GLfloat, GLfloat);
	void     glRotated(GLdouble, GLdouble, GLdouble, GLdouble);
	void     glScalef(GLfloat, GLfloat, GLfloat);
	void     glScaled(GLdouble, GLdouble, GLdouble);
	void     glScissor(GLint, GLint, GLsizei, GLsizei);
	void     glTexCoord1f(GLfloat);
	void     glTexCoord2f(GLfloat, GLfloat);
	void     glTexCoord3f(GLfloat, GLfloat, GLfloat);
	void     glTexCoord4f(GLfloat, GLfloat, GLfloat, GLfloat);
	void     glTexCoord1d(GLdouble);
	void     glTexCoord2d(GLdouble, GLdouble);
	void     glTexCoord3d(GLdouble, GLdouble, GLdouble);
	void     glTexCoord4d(GLdouble, GLdouble, GLdouble, GLdouble);
	void     glTexImage2D(GLenum, GLint, GLint, GLsizei, GLsizei, GLint, GLenum, GLenum, const GLvoid*);
	void     glTexSubImage2D(GLenum GLint, GLint, GLint, GLsizei, GLsizei, GLenum, GLenum, const GLvoid*);
	void     glTranslatef(GLfloat, GLfloat, GLfloat);
	void     glTranslated(GLdouble, GLdouble, GLdouble);
	void     glVertex2f(GLfloat, GLfloat);
	void     glVertex3f(GLfloat, GLfloat, GLfloat);
	void     glVertex4f(GLfloat, GLfloat, GLfloat);
	void     glViewport(GLint, GLint, GLsizei, GLsizei);
	*/


	/* 3.3 core
	void     glActiveTexture(GLenum);
	void     glAttachShader(GLuint, GLuint);
	void     glBeginConditionalRender(GLuint, GLenum);
	void     glBeginQuery(GLenum, GLuint);
	void     glBeginTransformFeedback(GLenum);
	void     glBindAttribLocation(GLuint, GLuint, const GLchar*);
	void     glBindBuffer(GLenum, GLuint);
	void     glBindBufferBase(GLenum, GLuint, GLuint);
	void     glBindBufferRange(GLenum, GLuint, GLuint, GLintptr, GLsizeiptr);
	void     glBindFragDataLocation(GLuint, GLuint, const char*);
	void     glBindFragDataLocationIndexed(GLuint, GLuint, GLuint, const char*);
	void     glBindFramebuffer(GLenum, GLuint);
	void     glBindRenderbuffer(GLenum, GLuint);
	void     glBindSampler(GLuint, GLuint);
	void     glBindTexture(GLenum, GLuint);
	void     glBindVertexArray(GLuint);
	void     glBlendColor(GLclampf, GLclampf, GLclampf, GLclampf);
	void     glBlendEquation(GLenum);
	void     glBlendEquationSeparate(GLenum, GLenum);
	void     glBlendFunc(GLenum, GLenum);
	void     glBlendFuncSeparate(GLenum, GLenum, GLenum, GLenum);
	void     glBlitFramebuffer(GLint, GLint, GLint, GLint, GLint, GLint, GLint, GLint, GLbitfield, GLenum);
	void     glBufferData(GLenum, GLsizeiptr, const GLvoid*, GLenum);
	void     glBufferSubData(GLenum, GLintptr, GLsizeiptr, const GLvoid*);
	void     glCheckFramebufferStatus(GLenum);
	void     glClampColor(GLenum, GLenum);
	void     glClear(GLbitfield);

	void     glClearBufferiv(GLenum, GLint, const GLint*);
	void     glClearBufferuiv(GLenum, GLint, const GLint*);
	void     glClearBufferfv(GLenum, GLint, const GLfloat*);
	void     glClearBufferfi(GLenum, GLint, GLfloat, GLint);

	void     glClearColor(GLclampf, GLclampf, GLclampf, GLclampf);
	void     glClearDepth(GLclampd);
	void     glClearStencil(GLint);
	void     glCLientWaitSync(GLsync, GLbitfield, GLuint64);
	void     glColorMask(GLboolean, GLboolean, GLboolean, GLboolean);
	void     glCompileShader(GLuint);
	void     glCompressedTexImage1D(GLenum, GLint, GLsizei, GLint, GLsizei, const GLvoid*);
	void     glCompressedTexImage2D(GLenum, GLint, GLenum, GLsizei, GLsizei, GLint, GLsizei, const GLvoid*);
	void     glCompressedTexImage3D(GLenum, GLint, GLenum, GLsizei, GLsizei, GLsizei, GLint, GLsizei, const GLvoid*);
	void     glCompressedTexSubImage1D(GLenum, GLint, GLint, GLsizei, GLenum, GLsizei, const GLvoid*);
	*/
	</code></pre>
	</li>
	<li>
	<h3>Texturing a cube</h3>
	<p>Source: <a href="http://www.songho.ca/opengl/gl_vbo.html" target="_blank">http://www.songho.ca/opengl/gl_vbo.html</a></p>
	<pre><code>
	// unit cube      
	// A cube has 6 sides and each side has 4 vertices, therefore, the total number
	// of vertices is 24 (6 sides * 4 verts), and 72 floats in the vertex array
	// since each vertex has 3 components (x,y,z) (= 24 * 3)
	//    v6----- v5  
	//   /|      /|   
	//  v1------v0|   
	//  | |     | |   
	//  | v7----|-v4  
	//  |/      |/    
	//  v2------v3    

	// vertex position array
	GLfloat vertices[]  = {
		 .5f, .5f, .5f,  -.5f, .5f, .5f,  -.5f,-.5f, .5f,  .5f,-.5f, .5f, // v0,v1,v2,v3 (front)
		 .5f, .5f, .5f,   .5f,-.5f, .5f,   .5f,-.5f,-.5f,  .5f, .5f,-.5f, // v0,v3,v4,v5 (right)
		 .5f, .5f, .5f,   .5f, .5f,-.5f,  -.5f, .5f,-.5f, -.5f, .5f, .5f, // v0,v5,v6,v1 (top)
		-.5f, .5f, .5f,  -.5f, .5f,-.5f,  -.5f,-.5f,-.5f, -.5f,-.5f, .5f, // v1,v6,v7,v2 (left)
		-.5f,-.5f,-.5f,   .5f,-.5f,-.5f,   .5f,-.5f, .5f, -.5f,-.5f, .5f, // v7,v4,v3,v2 (bottom)
		 .5f,-.5f,-.5f,  -.5f,-.5f,-.5f,  -.5f, .5f,-.5f,  .5f, .5f,-.5f  // v4,v7,v6,v5 (back)
	};

	// normal array
	GLfloat normals[] = {
		 0, 0, 1,   0, 0, 1,   0, 0, 1,   0, 0, 1,  // v0,v1,v2,v3 (front)
		 1, 0, 0,   1, 0, 0,   1, 0, 0,   1, 0, 0,  // v0,v3,v4,v5 (right)
		 0, 1, 0,   0, 1, 0,   0, 1, 0,   0, 1, 0,  // v0,v5,v6,v1 (top)
		-1, 0, 0,  -1, 0, 0,  -1, 0, 0,  -1, 0, 0,  // v1,v6,v7,v2 (left)
		 0,-1, 0,   0,-1, 0,   0,-1, 0,   0,-1, 0,  // v7,v4,v3,v2 (bottom)
		 0, 0,-1,   0, 0,-1,   0, 0,-1,   0, 0,-1   // v4,v7,v6,v5 (back)
	};

	// colour array
	GLfloat colors[] = {
		 1, 1, 1,   1, 1, 0,   1, 0, 0,   1, 0, 1,  // v0,v1,v2,v3 (front)
		 1, 1, 1,   1, 0, 1,   0, 0, 1,   0, 1, 1,  // v0,v3,v4,v5 (right)
		 1, 1, 1,   0, 1, 1,   0, 1, 0,   1, 1, 0,  // v0,v5,v6,v1 (top)
		 1, 1, 0,   0, 1, 0,   0, 0, 0,   1, 0, 0,  // v1,v6,v7,v2 (left)
		 0, 0, 0,   0, 0, 1,   1, 0, 1,   1, 0, 0,  // v7,v4,v3,v2 (bottom)
		 0, 0, 1,   0, 0, 0,   0, 1, 0,   0, 1, 1   // v4,v7,v6,v5 (back)
	};

	// texture coord array
	GLfloat texCoords[] = {
		1, 0,   0, 0,   0, 1,   1, 1,               // v0,v1,v2,v3 (front)
		0, 0,   0, 1,   1, 1,   1, 0,               // v0,v3,v4,v5 (right)
		1, 1,   1, 0,   0, 0,   0, 1,               // v0,v5,v6,v1 (top)
		1, 0,   0, 0,   0, 1,   1, 1,               // v1,v6,v7,v2 (left)
		0, 1,   1, 1,   1, 0,   0, 0,               // v7,v4,v3,v2 (bottom)
		0, 1,   1, 1,   1, 0,   0, 0                // v4,v7,v6,v5 (back)
	};

	// index array for glDrawElements()
	// A cube requires 36 indices = 6 sides * 2 tris * 3 verts
	GLuint indices[] = {
		 0, 1, 2,   2, 3, 0,    // v0-v1-v2, v2-v3-v0 (front)
		 4, 5, 6,   6, 7, 4,    // v0-v3-v4, v4-v5-v0 (right)
		 8, 9,10,  10,11, 8,    // v0-v5-v6, v6-v1-v0 (top)
		12,13,14,  14,15,12,    // v1-v6-v7, v7-v2-v1 (left)
		16,17,18,  18,19,16,    // v7-v4-v3, v3-v2-v7 (bottom)
		20,21,22,  22,23,20     // v4-v7-v6, v6-v5-v4 (back)
	};
	</code></pre>
	</li>
	<li>
	<p>More copied from ProtableGL: <a href="https://github.com/rswinkle/PortableGL/blob/master/src/gl_impl_unsafe.c" target="_blank">https://github.com/rswinkle/PortableGL/blob/master/src/gl_impl_unsafe.c</a></p>
	<pre><code>
	// Stubs to let real OpenGL libs compile with minimal modifications/ifdefs
	// add what you need

	void glGetDoublev(GLenum pname, GLdouble* params) { }
	void glGetInteger64v(GLenum pname, GLint64* params) { }


	void glGetProgramiv(GLuint program, GLenum pname, GLint* params) { }
	void glGetProgramInfoLog(GLuint program, GLsizei maxLength, GLsizei* length, GLchar* infoLog) { }
	void glAttachShader(GLuint program, GLuint shader) { }
	void glCompileShader(GLuint shader) { }
	void glGetShaderInfoLog(GLuint shader, GLsizei maxLength, GLsizei* length, GLchar* infoLog) { }
	void glLinkProgram(GLuint program) { }
	void glShaderSource(GLuint shader, GLsizei count, const GLchar** string, const GLint* length) { }
	void glGetShaderiv(GLuint shader, GLenum pname, GLint* params) { }
	void glDeleteShader(GLuint shader) { }
	void glDetachShader(GLuint program, GLuint shader) { }

	GLuint glCreateProgram() { return 0; }
	GLuint glCreateShader(GLenum shaderType) { return 0; }
	GLint glGetUniformLocation(GLuint program, const GLchar* name) { return 0; }
	GLint glGetAttribLocation(GLuint program, const GLchar* name) { return 0; }

	GLboolean glUnmapBuffer(GLenum target) { return GL_FALSE; }
	GLboolean glUnmapNamedBuffer(GLuint buffer) { return GL_FALSE; }

	// TODO
	void glLineWidth(GLfloat width) { }

	void glActiveTexture(GLenum texture) { }
	void glTexParameterfv(GLenum target, GLenum pname, const GLfloat* params) { }

	void glUniform1f(GLint location, GLfloat v0) { }
	void glUniform2f(GLint location, GLfloat v0, GLfloat v1) { }
	void glUniform3f(GLint location, GLfloat v0, GLfloat v1, GLfloat v2) { }
	void glUniform4f(GLint location, GLfloat v0, GLfloat v1, GLfloat v2, GLfloat v3) { }

	void glUniform1i(GLint location, GLint v0) { }
	void glUniform2i(GLint location, GLint v0, GLint v1) { }
	void glUniform3i(GLint location, GLint v0, GLint v1, GLint v2) { }
	void glUniform4i(GLint location, GLint v0, GLint v1, GLint v2, GLint v3) { }

	void glUniform1ui(GLuint location, GLuint v0) { }
	void glUniform2ui(GLuint location, GLuint v0, GLuint v1) { }
	void glUniform3ui(GLuint location, GLuint v0, GLuint v1, GLuint v2) { }
	void glUniform4ui(GLuint location, GLuint v0, GLuint v1, GLuint v2, GLuint v3) { }

	void glUniform1fv(GLint location, GLsizei count, const GLfloat* value) { }
	void glUniform2fv(GLint location, GLsizei count, const GLfloat* value) { }
	void glUniform3fv(GLint location, GLsizei count, const GLfloat* value) { }
	void glUniform4fv(GLint location, GLsizei count, const GLfloat* value) { }

	void glUniform1iv(GLint location, GLsizei count, const GLint* value) { }
	void glUniform2iv(GLint location, GLsizei count, const GLint* value) { }
	void glUniform3iv(GLint location, GLsizei count, const GLint* value) { }
	void glUniform4iv(GLint location, GLsizei count, const GLint* value) { }

	void glUniform1uiv(GLint location, GLsizei count, const GLuint* value) { }
	void glUniform2uiv(GLint location, GLsizei count, const GLuint* value) { }
	void glUniform3uiv(GLint location, GLsizei count, const GLuint* value) { }
	void glUniform4uiv(GLint location, GLsizei count, const GLuint* value) { }

	void glUniformMatrix2fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix3fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix4fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix2x3fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix3x2fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix2x4fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix4x2fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix3x4fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }
	void glUniformMatrix4x3fv(GLint location, GLsizei count, GLboolean transpose, const GLfloat* value) { }


	</code></pre>
	</li>
	<li><b>x86 architecture</b> uses little endianess (<i>Least Significant Byte</i> stored in the lowest memory address) while <b>TPC/IP headers</b> uses big endianess (<i>Most Significant Byte</i> stored on 
	lowest memory address)</li>
	<li>Remove the console window programmatically: <b>#pragma comment(linker, "/subsystem:\"windows\" "/entry:\"mainCRTStartup\")</b></li>
	<li>You can choose the UNICODE version of a program runtime by adding - <b>#define UNICODE</b> (win32 runtime) and <b>#define _UNICODE</b> (C runtime). (strings then needs L"")</li>
	<li>Strip a lot of unnessacery libs with <b>#define WIN32_MEAN_AND_LEAN</b> and <b>VC_EXTRALEAN</b>.</li>
	<li>Select the GPU by adding these lines: 
	<b><br/><pre><code>
	#ifdef _WIN32
	#include &lt;windows.h&gt;
	extern "C" {
		__declspec(dllexport) DWORD NvOptimusEnablement = 0x00000001;
		__declspec(dllexport) int AmdPowerXpressRequestHighPerformance = 0x00000001;
	}
	<i>// Or on one line each</i>: extern "C" __declspec(dllexport) DWORD NvOptimusEnablement = 0x00000001;
	#endif
	</code></pre></b>
	</li>
	<li>Undefine unused params in the <b>WinMain</b> with <b>UNREFERENCED_PARAMETER(eg. <i>lpCmdLine</i>)</b></li>
	<li>Defining compiler version and adding additional libs programmatically
	<pre><code>
	#ifdef _MSC_VER                         // Check if MS Visual C compiler
	#  include &lt;windows.h&gt;			// Only include the windows headers if compiling for Windows
	#  pragma comment(lib, "opengl32.lib")  // Compiler-specific directive to avoid manually configuration
	#  pragma comment(lib, "glu32.lib")     // Link libraries
	#endif
	</code></pre>
	</li>
	<li>
	Assuming readers are familiar with binary representation, LOWORD & HIWORD are macros for retrieving specific bits of wParam. Using bitwise operators, the LOWORD macro can be seen as:

	<pre><code>#define LOWORD(l) ((WORD)(((DWORD_PTR)(l)) & 0xffff))</code></pre>
	The HIWORD macro is defined as:

	<pre><code>#define HIWORD(l) ((WORD)((((DWORD_PTR)(l)) >> 16) & 0xffff))</code></pre>
	</li>
	<li><p>Test if window is in focus and is active, otherwise this is where to handle pausing</p>
	<pre><code>
	case WM_ACTIVATE:		// Watch For Window Activate Message
        {
            if (!HIWORD(wParam))	// Check Minimization State
            {
                active=TRUE;		// Program Is Active
            }
            else
            {
                active=FALSE;		// Program Is No Longer Active
            }
            return 0;			// Return To The Message Loop
	}
	</code></pre>
	</li>
	<li>
	<pre><code>
	case WM_SYSCOMMAND:			//Intercept System Commands
	{
		switch (wParam)			//Check System Calls
		{
			case SC_SCREENSAVE:	//Screensaver Trying To Start?
			case SC_MONITORPOWER:	//Monitor Trying To Enter Powersave?
			return 0;		//Prevent From Happening
		}
		break;				//Exit
	}
	</code></pre>
	</li>
	<li>
	<pre><code>
	bool	keys[256];		//Array Used For The Keyboard Routine
	bool	active=TRUE;		//Window Active Flag Set To TRUE By Default
	...
	
	case WM_KEYDOWN:		//Is A Key Being Held Down?
	{
		keys[wParam] = TRUE;	//If So, Mark It As TRUE
		return 0;		//Jump Back
	}

	case WM_KEYUP:			//Has A Key Been Released?
	{
		keys[wParam] = FALSE;	//If So, Mark It As FALSE
		return 0;		//Jump Back
	}
	</code></pre>
	</li>
	<li> Also this to set various options (tweak as needed)
	<pre><code>
	#ifdef _MSC_VER        // Check if MS Visual C compiler
	#   ifndef _MBCS
	#      define _MBCS    // Uses Multi-byte character set
	#   endif
	#   ifdef _UNICODE     // Not using Unicode character set
	#      undef _UNICODE 
	#   endif
	#   ifdef UNICODE
	#      undef UNICODE 
	#   endif
	#endif
	</code></pre>
	</li>
	<li>
	<p>Endianess conversion in GCC compilers (Source: r/TheDefault8 in <a href="https://www.reddit.com/r/opengl/comments/pr9zlh/integer_texture_not_rendering/" target="_blank">https://www.reddit.com/r/opengl/comments/pr9zlh/integer_texture_not_rendering/</a>)</p>
	<pre><code>
	#if (defined(__BYTE_ORDER__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__) || \
		(defined(BYTE_ORDER) && BYTE_ORDER == LITTLE_ENDIAN) || \
		defined(__LITTLE_ENDIAN__) || \
		defined(_MSC_VER) || \
		defined(__ARMEL__) || \
		defined(__THUMBEL__) || \
		defined(__AARCH64EL__) || \
		defined(_MIPSEL) || defined(__MIPSEL) || defined(__MIPSEL__)
	#   define BO_LITTLE_ENDIAN 1
	#else
	#   define BO_LITTLE_ENDIAN 0
	#endif

	uint32_t htonl(uint32_t x)
	{
		#if BO_LITTLE_ENDIAN
			uint8_t *s = (uint8_t *)&x;
			return (uint32_t)(s[0] << 24 | s[1] << 16 | s[2] << 8 | s[3]);
		#else
			return x;
		#endif
	}

	uint16_t htons(uint16_t x)
	{
		#if BO_LITTLE_ENDIAN
			uint8_t *s = (uint8_t *)&x;
			return (uint16_t)(s[0] << 8 | s[1]);
		#else
			return x;
		#endif
	}
	</code></pre>
	</li>
	<li>
	<p>Big endianess for older GCC compilers:</p>
	<pre><code>
	You may try __BIG_ENDIAN__ or __BIG_ENDIAN or _BIG_ENDIAN which are often defined on big endian compilers.

	This will improve detection. But if you specifically target PowerPC platforms, you can add a few more tests to improve even more detection. Try _ARCH_PPC or __PPC__ or __PPC or PPC or __powerpc__ 
	or __powerpc or even powerpc. Bind all these defines together, and you have a pretty fair chance to detect big endian systems, and powerpc in particular, whatever the compiler and its version.
	</code></pre>
	</li>
	<li>
	<p>Contra questions (Source: <a href="https://stackoverflow.com/questions/8978935/detecting-endianness" target="_blank">https://stackoverflow.com/questions/8978935/detecting-endianness</a>)</p>
	<pre><code>
	Instead of looking for a compile-time check, why not just use big-endian order (which is considered the "network order" by many) and use the htons/htonl/ntohs/ntohl functions provided by 
	most UNIX-systems and Windows. They're already defined to do the job you're trying to do. Why reinvent the wheel?
	</code></pre>
	</li>
	<li>
	<p>Boost-like C alternatives</p>
	<pre><code>
	<a href="https://docs.gtk.org/glib/" target="_blank">https://docs.gtk.org/glib/</a>
	<a href="http://apr.apache.org/" target="_blank">http://apr.apache.org/</a>
	<a href="https://www.hpl.hp.com/personal/Hans_Boehm/gc/" target="_blank">https://www.hpl.hp.com/personal/Hans_Boehm/gc/</a>
	</code></pre>
	</li>
	<li>
	<p>Collision detection</p>
	<pre><code>
	auto verts = sceneObject->getEditVerts();
	auto norms = sceneObject->getEditNorms();
	auto triangleInds = mesh->getCount();
	int numTrid = triangleInds->getCount();
	
	uint3 *triData = (uint3 *)triangleInds->getData();
	float3 *vertsData = *(float3 *)verts->getData();
	float3 *normsData = *(float3 *)norms->getData();
	
	// for each triangle in the collision geometry
	for (int i = 0; i < numTris; i++) {
		bool outsidePlane = false;
		bool outsideAllVerts = false;
		bool outsideAllEdges = false;
		
		float v1 = vertsData[triData[i].x];
		float v2 = vertsData[triData[i].y];
		float v3 = vertsData[triData[i].z];
		
		// Assume flat normals for collision (all 3 n would be the same)
		float pN = (float4)(normsData[triData[i].x].normalized(), 0.0f)).xyz();
		
		// only test for vertical polygons
		if (fabs(pN.y) > 0.1f)
			continue;
			
		float d = -((v1 + v2 + v3) / 3.0f).dot(pN);
		
		// get point-to-plane distance from model center
		float ppd = pN.dot(collSphereOrigin) + d;
		
		if (ppd > collSphereRadius)
		{
			outsidePlane = true;
			continue;
		}
	}
	</code></pre>
	<pre><code>
	This is a rather simple formula for point-plance distance with plance equation
	
	<b>Ax+By+Cz+0=e</b>
	
	<b>Distance</b> = (A*x0+B*y0+C*z0+D)/sqrt(A*A+B*B+C*C)
	
	where (x0, y0, z0) are point coordinates. If your plane is normal vector (A, B, C) is normalized (unit), then denominator may be omitted.
	
	(A sign of distance usually is not important for interesection purposes
	</code></pre>
	<pre><code>
	static bool intersectRaySegmentSphere(float 3 0, float3 d, float3 so, float radius2, float &ip)
	{
		// we pass in d non-normalized to keep it's length
		// then we use the length later to compare the intersection point to make sure 
		// we're within the actual ray segment
		float l = d.length();
		d /= l;
		
		float3 m = o - so;
		float b = m.dot(d);
		float c = m.dot(m) - radius2;
		
		// Exit if r's origin outside s (c > 0) and r poiting away from s (b > 0)
		if (c > 0.0f && b > 0.0f)
			return false;
		float discr = b * b - c;
		
		// A negative discriment corresponds to ray missing sphere
		if (discr < 0.0f)
			return false;
			
		// Ray now found to intersect sphere, compute smallest t value of intersection
		float t = -b - sqrtf(discr);
		
		// If t is negative, ray started inside shpere so clamp t to zero
		if (t < 0.0f)
			t = 0.0f;
		ip = o + (d * t);
		
		if (t > 1)
			return false;
		return true;
	}
	</pre></code>
	<pre><code>
	bool outsideV1 = ((v1-collSphereOrigin).lengthSquared() > collSphereRadius2));
	bool outsideV2 = ((v2-collSphereOrigin).lengthSquared() > collSphereRadius2));
	bool outsideV3 = ((v3-collSphereOrigin).lengthSquared() > collSphereRadius2));
	
	if (outsideV1 && outsideV2 && outsideV3) {
		// Sphere outside of all triangle vertices
		outsideAllVerts = true;
	}
	
	// build 3 rays (line segments)
	float3 a = v2-v1;
	float3 b = v3-v2;
	float3 c = v1-v3;
	
	float3 ip;
	
	if(!intersectRaySegmentSphere(v1, a, collSphereOrigin, collSphereRadius2, ip) &&
	   !intersectRaySegmentSphere(v2, b, collSphereOrigin, collSphereRadius2, ip) &&
	   !intersectRaySegmentSphere(v3, c, collSphereOrigin, collSphereRadius2, ip))
	{
		outsideAllEdges = true;
	}
	
	if (outsideAllVerts && outsideAllEdges) {
		continue;
	}
	
	sceneObject->getMeshes()[0]->getMaterial()->setDiffuse(float4(1, 0, 0, 1));
	
	// push the character (us) outside of the intersected body
	shiftDelta += pN*(collSphereRadius-ppd);
	numCollisions++;
	
	// This is on indention lower then the above code (in the functions global scope)
	if (numCollisions != 0) {
		shiftDelta /= (float)numCollisions;
		
		if (shiftDelta.length() > lastWalkSpeed)
		{
			shiftDelta = shiftDelta.normalized();
			shiftDelta *= lastWalkSpeed*1.1f;
		}
	}
	
	model->setPos(model->getPos() + shiftDelta);
	
	</pre></code>
	</li>
	<li>
	<pre><code>
	One of the simplest formulas or expressions possible is the cosine of a linear argument. Popular wisdom (especially between old-school coders) is that trigonometric functions are expensive and that 
	therefore it is important to avoid them (by means of LUTs or linear/triangular approximations). Often popular wisdom is wrong - despite the above still holds true in some especial cases (a CPU heavy 
	inner loop) it does not in general: for example, in the GPU, computing a cosine is way, way faster than any attempt to approximate it. So, lets take advantage of this and go with the straight cosine expresion:

	color(t) = a + b * cos[2PI(c * t + d)]
	
	Example: 
	// cosine based palette, 4 vec3 params
	vec3 palette( in float t, in vec3 a, in vec3 b, in vec3 c, in vec3 d )
	{
		return a + b*cos( 6.28318*(c*t+d) );
	}
	</code></pre>
	</li>
	<li>
	<pre><code>
	<b>r/Lumornys</b> 
	If you're going to cover both fixed-function and programmable pipeline, you can make a sort of history lesson on what was introduced when - glBegin/glEnd in 1.0, arrays in 1.1, VBO in 1.5, shaders in 2.0 
	(with slightly different syntax), then deprecating old stuff in 3.0, etc.

	There seem to be misconceptions in some tutorials about what is "old" and what is "new", as if before "modern" OpenGL 3.0 there was nothing but 1.0. In fact, the transition was a lot more gradual.
	</code></pre>
	</li>
	<li>Consider this approch for folder structure:
	<pre><code>
	├── src
	│   ├── base
	│   │   └── render.ts
	│   ├── core
	│   │   ├── camera
	│   │   │   └── camera.ts
	│   │   ├── cutscene
	│   │   │   └── cutscene.ts
	│   │   ├── debug
	│   │   │   └── debug.ts
	│   │   ├── gameobjects
	│   │   │   ├── circle.ts
	│   │   │   ├── gameObject.ts
	│   │   │   ├── rect.ts
	│   │   │   ├── roundrect.ts
	│   │   │   └── sprite.ts
	│   │   ├── game.ts
	│   │   ├── group
	│   │   │   └── group.ts
	│   │   ├── input
	│   │   │   └── input.ts
	│   │   ├── interactive
	│   │   │   └── text.ts
	│   │   ├── lights
	│   │   │   └── staticLight.ts
	│   │   ├── loader
	│   │   │   └── loader.ts
	│   │   ├── map
	│   │   │   └── tilemap.ts
	│   │   ├── math
	│   │   │   └── clamp.ts
	│   │   ├── particles
	│   │   │   ├── particleEmitter.ts
	│   │   │   └── particle.ts
	│   │   ├── physics
	│   │   │   ├── circleToRectIntersect.ts
	│   │   │   ├── collider.ts
	│   │   │   └── rectToRectIntersect.ts
	│   │   ├── scene.ts
	│   │   ├── sound
	│   │   │   └── sound.ts
	│   │   └── storage
	│   │       └── storage.ts
	│   ├── helper
	│   │   └── color
	│   │       ├── getValuesHSL.ts
	│   │       ├── getValuesRGB.ts
	│   │       ├── hexToHSL.ts
	│   │       ├── hexToRGBA.ts
	│   │       ├── hexToRGB.ts
	│   │       ├── hslaToRGBA.ts
	│   │       ├── hslToRGB.ts
	│   │       ├── isHex.ts
	│   │       ├── isHSL.ts
	│   │       ├── isRGB.ts
	│   │       ├── randomColor.ts
	│   │       ├── rgbaToHSLA.ts
	│   │       ├── rgbaToRGB.ts
	│   │       ├── rgbToHSL.ts
	│   │       └── rgbToRGBA.ts
	│   ├── index.ts
	│   └── utils
	│       ├── randomInt.ts
	│       └── validURL.ts
	</code></pre>
	</li>
	<li> Text on screen formatting
	<pre><code>
	 // update VBO for each character
	float vertices[6][4] = {
		{ xpos,     ypos + h,   0.0f, 0.0f },
		{ xpos,     ypos,       0.0f, 1.0f },
		{ xpos + w, ypos,       1.0f, 1.0f },

		{ xpos,     ypos + h,   0.0f, 0.0f },
		{ xpos + w, ypos,       1.0f, 1.0f },
		{ xpos + w, ypos + h,   1.0f, 0.0f }
	};
	</code></pre>
	</li>
	<li>Extend the client area into the main window (add buttons to the top row, above the filemenu): <a href="https://docs.microsoft.com/en-us/windows/win32/api/dwmapi/nf-dwmapi-dwmextendframeintoclientarea?redirectedfrom=MSDN" target="_blank">https://docs.microsoft.com/en-us/windows/win32/api/dwmapi/nf-dwmapi-dwmextendframeintoclientarea?redirectedfrom=MSDN</a>
	<li>Read up on WinML and DirectML</li>
	<li>WinML alternative: <a href="https://github.com/libfann/fann" target="_blank">https://github.com/libfann/fann</a></li>
	<li>Advice on Enemy AI: Decision trees of some kind and path finding/search algorithms...</li>
	<li>Quest design thread: <a href="https://www.reddit.com/r/gamedesign/comments/ocbvpc/quest_design_what_really_makes_good_quest_design/" target="_blank">https://www.reddit.com/r/gamedesign/comments/ocbvpc/quest_design_what_really_makes_good_quest_design/</a>
	<pre><code><p>r/Eklundz</p>
	My thoughts on good quest design:

	Meaningful: no “kill 5 rats” quests, proper stuff.
	Multiple solutions: This is something 99% of all games fail at. A good quest need to have 2-3 different solutions, otherwise it will just feel like a mandatory railroad.
	Challenging: If a quest is not challenging its pointless.
	It should lead to something: A good quest leads to something new, it’s not just an isolated event. There are a few different examples here, World Of Warcraft have quests the devs call 
	“bread crumb quests” that lead the player to a new zone by giving them a letter or something to deliver to the captain of the guard in a fort in the next zone, or something similar. 
	These quests might not be challenging but they feel meaningful because you start a journey and go to explore new things. Another example would be a quest that changes the state of the world, 
	like siege quests in Skyrim where the city changes ruler after you finish it.
	
	Those are my thoughts.
	
	<p>r/therooseisloose578</p>
	...
	
	Most of the time you can break quests into two things. The actions that the player needs to take in order to complete the quest, and the narrative context/wrapper to the quest. For the actions, 
	that relates to the "puzzle" aspect that you are talking about. Some people like puzzles so then that would be a good quest for them. The narrative context relates to pretty much everything else 
	your talking about. So that's the story, and why you're doing what you're doing. What you refer to as "player expression" is actually commonly referred to as "player agency" and studies have shown 
	that players enjoy quests more if there is high percieved player agency.
	
	...
	
	<p>r/Xolarix</p>
	...
	
	Very rarely is it a singular quest, most of them are actually questlines, where you complete multiple tasks, and there is an overarching story in the questline. And it's not just a single side 
	quest that branches off from the main story, but there are literally dozens of side quests and each of them take like 15-30 minutes to complete, which is why that game is so immersive.
	
	...
	
	So I'd say it's a combination of good writing, and interesting unique mechanics for quests that force the player to do something new, or use the knowledge they already had in a new way, 
	or where using that mechanic doesn't have the expected outcome for that quest.
	
	...
	</code></pre>
	</li>
	<li>
	<a href="https://www.reddit.com/r/C_Programming/comments/oqh7dr/how_to_convert_a_signed_32_bit_int_to_a_signed_16/" target="_blank">https://www.reddit.com/r/C_Programming/comments/oqh7dr/how_to_convert_a_signed_32_bit_int_to_a_signed_16/</a>
	<pre><code>
	maep 16 poeng 4 timer siden* 
	Hi, (ex) professional audio dev here. Unless you work with embedded audio, the common practice is to convert your samples to float, normalized to [-1, 1]. That makes writing filters much easier and 
	you no longer have to think about scaling issues, but be warned that you might run into denormals.

	When mixing two channels in s16 you could to a right-shift (which acts as x * 0.5) before to avoid clipping. The problem with that method is that it doesn't preserverve loudness. The correct approach 
	for uncorrelated signals is multiplying with 1/sqrt(2) [1] which approximates to (x * 0.7), but then you might get clipping.

	Most fixed point DSPs support saturation arithmetic which deals with clipping issues, but on desktop CPUs you have to do that manually.

	With all that being said, to mix two uncorrelated 16-bit samples, a and b, in fixed-point:

	int16_t mix(int16_t a, int16_t b) {
		// mix samples
		int32_t x = (int32_t)a + (int32_t)b;
		// multiply with 1/sqrt(2) in Q15 [2]
		// x = (x * 23170) >> 15; // using arithmeric right shift
		// u/richardxday pointed out that ARS is not ideal, and afaik implementation defined
		// div is better and on modern compilers equally fast
		x = (x * 23170) / 32768;
		// clip output
		x = x < INT16_MIN ? INT16_MIN : 
			x > INT16_MAX ? INT16_MAX : x;
		return (int16_t)x;
	}
	As you can see in compiler explorer, the div is turned into a sar instruction: https://godbolt.org/z/3sohca9oj

	If you want to get deeper into this topic, I highly recommend reading this free book: http://www.dspguide.com/pdfbook.htm
	<pre><code>
	richardxday 5 poeng 2 timer siden 
	Just a small point, I'd recommend avoiding ASR's if possible because they round asymmetrically (towards -ve infinity). A right shift is equivalent to a divide for positive numbers and not equivalent for negative numbers.

	For example:

	5 >> 1 = 2

	-5 >> 1 = -3

	This means you'll get different results for your sqrt(.5) gain for +ve and -ve numbers.

	I'd suggest sticking with a divide unless performance *requires* a faster method.

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]maep 3 poeng 2 timer siden 
	Good point. I also skipped rounding (adding 0.5 or 16384 in Q15) to keep it a bit simpler.

	The thing is, we're talking about the least significant bit here, which is inaudable noise at -96 dB. For all practical intents and purpose this is good enough.
	</code></pre>
	
	<pre><code>
	Jorengarenar 17 poeng 9 timer siden* 
	Sint16

	Why aren't you using standard's fixed width integers from stdint.h header?

	Is it possible the sign bit is getting discarded doing it this way?

	32-bit integer -32768 would be represented in binary using two's complement as:

	1111 1111 1111 1111 1000 0000 0000 0000
	If we now "cut" it down to 16-bit we get: 1000 0000 0000 0000, which is still -32768

	permalenkeembedlagrerapportergive awardsvar

	[–]DeeBoFour20[S] 11 poeng 9 timer siden 
	Sint16 is from SDL. This code is in an SDL callback function so I'm just using that here.

	I guess I'm good then regarding the cast to 16 bit. I assume that also holds true for any negative value larger than -32768?

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]Beliriel 2 poeng 6 timer siden 
	int32_t -65536 would get casted to int16_t 0 though if understood that right.

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]Selacios 4 poeng 6 timer siden 
	Yes, although officially signed downcasting in C is implementation-defined, so the actual behavior depends on the compiler.

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]Beliriel 0 poeng 5 timer siden 
	What about
	((x &gt;&gt; 16) & -32768) & ( x & 32767)

	x being an int32.
	Then you can basically just cut off the top two bytes and still get the signed remainder &lt; 65536 correctly no. Did I oversee something?

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]Selacios 1 poeng 2 timer siden 
	The minimum int32_t, -2^31, has binary

	10000000000000000000000000000000

	Using your suggested code, it would become

	1000000000000000

	by taking the bottom 15 bits of the original plus the sign bit of the original. This is actually min int16_t, -2^15.

	However, these two actually have different signed remainders mod 65536 (the original has mod 0, the new number has mod -32768). I think what you're looking for is the simpler

	x & 65535

	which works because every bit above bit 15 represents a power of 2 which is 65536 or greater, hence does not contribute to the mod 65536 in any way.


	[–]Beliriel 1 poeng 22 minutter siden 
	Mod can be negative? That's pretty funky. Yes my intention was casting it (or rather truncating the number) without losing the sign.
	</code></pre>
	
	<pre><code>
	I know noise with an amplitude of -96dB FS doesn't sound like much (see what I did there?) but it is FS so may be a lot higher wrt the signal. Also, it's correlated noise so is distinctly less pleasant than 
	uncorrelated noise.

	Finally, considering that dithering is often applied to 24 bit signals, 1 bit correlated noise on 16-bit signals is probably worthwhile doing something about, especially since it's so easy.

	Granted, dithering is a whole other subject but my point is that for a simple change you can eliminate a source of noise.

	As for rounding, a trick is to solve both problems at once with:

	/*--------------------------------------------------------------------------------*/
	/*
	* Mix two uncorrelated 16-bit samples * * @param a sample a * @param b sample b * 
	* @return mix of a and b with a gain of -3dB, rounded to nearest (away from zero) / 
	/--------------------------------------------------------------------------------*/ 
	int16_t mix(int16_t a, int16_t b) { // add samples, multiply by numerator of -3dB gain int32_t sample32 = ((int32_t)a + (int32_t)b) * 23170;

	// bias the sample32 value to round to nearest (away from zero) *and*
	// to compensate for -ve bias of ASR (biases in LSBs):
	// sign | bias for ASR | bias for RTN | total bias
	// +ve  |      0       |      .5      |     .5
	// -ve  |     .5       |     -.5      |      0
	// LSB in this case is 32768 so .5 * LSB = 16384
	sample32 += (sample32 >= 0) ? 16384 : 0;

	// perform ASR for denominator of -3dB gain (which will now be unbiased because of the above)
	sample32 >>= 15;

	// limit at 16-bit limits
	sample32 = (sample32 < -32768) ? -32768 : ((sample32 > 32767) ? 32767 : sample32);

	// return cast version
	return (int16_t)sample32;
	}

	(I've just rustled up above so it's untested!)

	permalenkeembedlagreforeldrerapportergive awardsvar

	[–]capilot 1 poeng 2 timer siden 
	I didn't know about multiplying by √2 before, but I guess it makes sense.

	I've also heard that dithering is a good idea; that is, adding white noise in [-16384 16384] before converting back to int16.
	</code></pre>
	</code></pre>
	<a href="https://factualaudio.com/post/sum/" target="_blank">https://factualaudio.com/post/sum/</a>
	</li>
	<li>
	<p>How exactly do modern widget toolkits (GTK+, QT) draw widgets?</p>
	<p>jtsiomb 6 poeng en time siden 
		There are two schools of thought when it comes to implementing widget toolkits. One is that every widget is a window, and the top-level window is a parent of a whole hierarchy. 
		The other is that the toolkit creates only top-level windows, and everything else is drawin inside that top-level window by the toolkit itself.

		Older systems like Motif and Win32 "controls" follow the first approach. GTK and Qt are complicated. For GTK I think it depends on the "engine" you have selected. The default 
		GTK "engine" I think also uses subwindows for widgets, but most of the shinier rounder-er engines are probably drawing everything on a pixmap.

		Rounded corners are not an issue with either way, but they do require support from the X server in the first case. That support is widely available however, and it's called 
		the X shape extension. You can have even top-level windows with arbitrary shapes. And you can even change that shape on the fly. See my "shapeblobs" hack: <a href="https://github.com/jtsiomb/shapeblobs" target="_blank">https://github.com/jtsiomb/shapeblobs</a> 
		(video: <a href="https://www.youtube.com/watch?v=HwJhQEVdPOE" target="_blank">https://www.youtube.com/watch?v=HwJhQEVdPOE</a>)

		Shadows of top-level windows are independent of GUI toolkit. They are handled by the desktop compositor if one is running. If one isn't running you generally can't have shadows 
		(or at least semi-transparent fuzzy shadows) on top-level windows, because you can't have alpha blending with the rest of the desktop.

		Shadows on widgets within a window require the second approach of drawing everything in the window by the toolkit. The compositor only touches top-level windows.</p>
	</li>
	<li>
	<p>Physics Math: Spring suspension</p>
	<pre><code>
	<p>Hooke's Law:</p>
	F=kx
	"x" being the displacement and "k" being the multiplier for the strength of the spring.
	<p>Hooke's Law including dampning</p>
	F=kx-dv
	"v" being the velocity and "d" being the multiplier for the strength of the damper
	</code></pre>
	</li>
	<li>
	<pre><code>
	futurechiefexecutive til r/startups

	kommenterdellagregjemgive awardrapportercrosspost
	If you're anything like me, being more productive as a Founder is always an ongoing effort. Here's something I picked up a couple of months back that's helped me significantly:

	Monday Morning

	Start your day by writing down your answers to these three questions:

	What are the top three things I want to accomplish this week?
	What steps do I need to take to accomplish each of them?
	What are the challenges or blockers that stand in my way?
	Friday Afternoon

	Come back to this and close the feedback loop with:

	Compared to the priorities I set on Monday, how did I do?
	What did I do well? What made me happy?
	What didn't go as planned? Where can I improve?
	You can do this on a notebook, Notion, or G-Docs if you're okay with manual upkeep. MyCheckins or Standuply work well as dedicated tools.

	TL;DR - Plan each week, review it at the end, and improve the next week with lessons from the last.
	</code></pre>
	</li>
	
	<pre><code>
	<h3>Installing and setting up OpenAL with HRTF</h3>
	Download OpenAL Soft <a href="https://openal-soft.org/" rel="_blank nofollow noreferrer">https://openal-soft.org/</a> and unzip it to C:\libraries\
	
	If you have 64-bit Windows:
		Copy soft_oal.dll from the Win32 folder into C:\Windows\SysWOW64
		Copy soft_oal.dll from the Win64 folder into C:\Windows\System32
	
	If you have 32-bit Windows:
		Copy soft_oal.dll from the Win32 folder into C:\Windows\System32
		
	<h3>Enable HRTFs in OpenAL Soft</h3>
	We need to create a configuration file that will tell OpenAL Soft to use HRTFs.

    Open Notepad
    Type the following:
		<pre>hrtf = true</pre>
    Click the <b>File menu</b> and <b>Save As...</b>
    Type <b>%APPDATA%</b> and hit enter. It will automatically take you to the folder where we need to save this configuration file.
    Change the <b>Save as</b> type drop-down list to say <b>All files (*.*)</b>
    Type the File name as <b>"alsoft.ini"</b> and click <b>Save</b>.
	
	<pre><code>
	<h3>Example using OpenAL with customer audio loading library in C++</h3>
	#include <stdio.h>
	#include <AL\al.h>
	#include <AL\alc.h>

	struct RIFF_Header {
		char chunkID[4];
		long chunkSize;
		char format[4];
	};

	struct WAVE_Format {
		char subChunkID[4];
		long subChunkSize;
		short audioFormat;
		short numChannels;
		long sampleRate;
		long byteRate;
		short blockAlign;
		short bitsPerSample;
	};

	struct WAVE_Data {
		char subChunkID[4];
		long subChunk2Size;
	};

	bool loadWavFile(const char* filename, ALuint* buffer,
					 ALsizei* size, ALsizei* frequency,
					 ALenum* format) {
	  FILE* soundFile = NULL;
	  WAVE_Format wave_format;
	  RIFF_Header riff_header;
	  WAVE_Data wave_data;
	  unsigned char* data;

	  try {
		soundFile = fopen(filename, "rb");
		if (!soundFile)
		  throw (filename);

		fread(&riff_header, sizeof(RIFF_Header), 1, soundFile);

		if ((riff_header.chunkID[0] != 'R' ||
			 riff_header.chunkID[1] != 'I' ||
			 riff_header.chunkID[2] != 'F' ||
			 riff_header.chunkID[3] != 'F') &&
			(riff_header.format[0] != 'W' ||
			 riff_header.format[1] != 'A' ||
			 riff_header.format[2] != 'V' ||
			 riff_header.format[3] != 'E'))
				 throw ("Invalid RIFF or WAVE Header");

		fread(&wave_format, sizeof(WAVE_Format), 1, soundFile);

		if (wave_format.subChunkID[0] != 'f' ||
			wave_format.subChunkID[1] != 'm' ||
			wave_format.subChunkID[2] != 't' ||
			wave_format.subChunkID[3] != ' ')
				 throw ("Invalid Wave Format");

		if (wave_format.subChunkSize > 16)
			fseek(soundFile, sizeof(short), SEEK_CUR);

		fread(&wave_data, sizeof(WAVE_Data), 1, soundFile);

		if (wave_data.subChunkID[0] != 'd' ||
			wave_data.subChunkID[1] != 'a' ||
			wave_data.subChunkID[2] != 't' ||
			wave_data.subChunkID[3] != 'a')
				 throw ("Invalid data header");

		data = new unsigned char[wave_data.subChunk2Size];

		if (!fread(data, wave_data.subChunk2Size, 1, soundFile))
			throw ("error loading WAVE data into struct!");

		*size = wave_data.subChunk2Size;
		*frequency = wave_format.sampleRate;

		if (wave_format.numChannels == 1) {
			if (wave_format.bitsPerSample == 8 )
				*format = AL_FORMAT_MONO8;
			else if (wave_format.bitsPerSample == 16)
				*format = AL_FORMAT_MONO16;
		} else if (wave_format.numChannels == 2) {
			if (wave_format.bitsPerSample == 8 )
				*format = AL_FORMAT_STEREO8;
			else if (wave_format.bitsPerSample == 16)
				*format = AL_FORMAT_STEREO16;
		}

		alGenBuffers(1, buffer);
		alBufferData(*buffer, *format, (void*)data,
					 *size, *frequency);
		fclose(soundFile);
		return true;
	  } catch(char* error) {
		if (soundFile != NULL)
			fclose(soundFile);
		return false;
	  }
	}

	int main(){

		//Sound play data
		ALint state;                            // The state of the sound source
		ALuint bufferID;                        // The OpenAL sound buffer ID
		ALuint sourceID;                        // The OpenAL sound source
		ALenum format;                          // The sound data format
		ALsizei freq;                           // The frequency of the sound data
		ALsizei size;                           // Data size

		// Checking for error before alcMakeContextCurrent can cause a crash to happen...
		ALCdevice* device = alcOpenDevice(NULL);
		// You could still check whether the device was opened successfully using if( !device )
		ALCcontext* context = alcCreateContext(device, NULL);
		alcMakeContextCurrent(context);

		// Create sound buffer and source
		alGenBuffers(1, &bufferID);
		alGenSources(1, &sourceID);

		// Set the source and listener to the same location
		alListener3f(AL_POSITION, 0.0f, 0.0f, 0.0f);
		alSource3f(sourceID, AL_POSITION, 0.0f, 0.0f, 0.0f);

		loadWavFile("..\\wavdata\\YOURWAVHERE.wav", &bufferID, &size, &freq, &format);

		alSourcei(sourceID, AL_BUFFER, bufferID);

		alSourcePlay(sourceID);

		do{
			alGetSourcei(sourceID, AL_SOURCE_STATE, &state);
		} while (state != AL_STOPPED);


		alDeleteBuffers(1, &bufferID);
		alDeleteSources(1, &sourceID);
		alcDestroyContext(context);
		alcCloseDevice(device);

		return 0;
	}
	</code></pre>
	
	I want to be able to run this application significantly faster than real-time. At the same time, the sound must be saved for later postprocessing. Is there a way to access the OpenAL output programmatically (virtually) without ever 
	playing the sound on the real playback device?

	Ideally, I'd like to have access that would be played during every tick of the main loop of my application. Normally one tick corresponds to one rendered frame (e.g. 1/30th of a second). But in this case we would be running the app 
	as fast as possible.

	We ended up using OpenAL Soft to do this. Example:


	#include "alext.h"
	LPALCLOOPBACKOPENDEVICESOFT alcLoopbackOpenDeviceSOFT;
	alcLoopbackOpenDeviceSOFT = alcGetProcAddress(NULL,"alcLoopbackOpenDeviceSOFT");

	replace your default device with this device

	ALCcontext *context = alcCreateContext(device, attrs);

	Set the attrs as you would for your default device

	Then in the main loop use:

	LPALCRENDERSAMPLESSOFT alcRenderSamplesSOFT;
	alcRenderSamplesSOFT = alcGetProcAddress(NULL, "alcRenderSamplesSOFT");
	alcRenderSamplesSOFT(device, buffer, 1024);

	Here the buffer will store 1024 samples. This code runs faster than real-time, therefore you can sample frames every tick
	---
	I'm creating a context with

	alcCreateContext(device, NULL).

	The problem is that ALC_STEREO_SOURCES is 3 by default, so my program freezes if I try to reproduce more than 3 stereo sounds.
	How can I set ALC_STEREO_SOURCES to 32?
	
	You can specify context creation attributes by making an array of type ALCInt, containing ordered pairs of names and values.
	So for example:
	ALCInt myParams[3] = {ALC_STEREO_SOURCES, 32, 0};
	alcCreateContex	t(myDevice, myParams);
	---
	<p id="note">
		OpenAL applies attenuation only to mono sound.
	</p>
	---
	

	I am writing a dialogue system for my game engine in C++. In order to group dialogue together I am having different dialogue sections placed within one file, and one buffer. Therefore how do I tell OpenAL to play the buffer from a 
	specific time (or sample it doesn't really matter to me) into the buffer. Thanks for any help in advance!

	void PlayFromSpecifiedTime(ALfloat seconds) const
	{
		alSourcef(source, AL_SEC_OFFSET, seconds);
		alSourcePlay(source);
	}

	Or, if you want to play from a certain sample from the buffer:

	void PlayFromSpecifiedSample(ALint sample) const
	{
		alSourcei(source, AL_SAMPLE_OFFSET, sample);
		alSourcePlay(source);
	}

	You can also add a check at the beginning to see if you're not trying to skip to a certain time (or sample) beyond the total amount from the buffer. If it does, you simply return; out of it. This assumes you know what you're doing.
	---
	I'm new using OpenAl library. I'm following the OpenAl programming guide but i can't find.

	I have this code extracted from page 10 of the OpenAl programming guide but still have no sound. I use OSX Snow Leopard, i know OSX doesn't have ALUT defined.

	#include <stdio.h>
	#include <sys/types.h>
	#include <sys/stat.h>
	#include <unistd.h>
	#include <stdlib.h>

	#include <OpenAL/al.h>
	#include <OpenAL/alc.h>

	using namespace std;

	#define NUM_BUFFERS 3
	#define BUFFER_SIZE 4096

	int main(int argc, char **argv)
	{
		ALCdevice *dev;
		ALCcontext *ctx;
		struct stat statbuf;

		Aluint buffer[NUM_BUFFERS];
		Aluint source[NUM_SOURCES];

		ALsizei size, freq;
		ALenum format;
		ALvoid *data;

		// Initialization 
		dev = alcOpenDevice(NULL); // select the "preferred dev" 

		if (dev) 
		{ 
			ctx = alcCreateContext(dev,NULL); 
			alcMakeContextCurrent(ctx);  
		} 
		// Check for EAX 2.0 support 
		// g_bEAX = alIsExtensionPresent("EAX2.0");

		// Generate Buffers 
		alGetError(); // clear error code 
		alGenBuffers(NUM_BUFFERS, buffer); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
			DisplayALError("alGenBuffers :", error); 
			return 1; 
		} 
		// Load test.wav 
		loadWAVFile("sample.wav", &format, &data, &size, &freq, &loop); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
			DisplayALError("LoadWAVFile sample.wav : ", error); 
			alDeleteBuffers(NUM_BUFFERS, buffer); 
		 return 1; 
		}

		// Copy test.wav data into AL Buffer 0 
		alBufferData(buffer[0], format, data, size, freq); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
		 DisplayALError("alBufferData buffer 0 : ", error); 
		 alDeleteBuffers(NUM_BUFFERS, buffer); 
		 return 1; 
		} 

		// Unload test.wav 
		unloadWAV(format, data, size, freq); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
			DisplayALError("UnloadWAV : ", error); 
			alDeleteBuffers(NUM_BUFFERS, buffer); 
			return 1; 
		} 
		// Generate Sources 
		alGenSources(1, source); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
			DisplayALError("alGenSources 1 : ", error); 
			return 1; 
		} 
		// Attach buffer 0 to source
		alSourcei(source[0], AL_BUFFER, buffer[0]); 
		if ((error = alGetError()) != AL_NO_ERROR) 
		{ 
			DisplayALError("alSourcei AL_BUFFER 0 : ", error); 
		} 

		// Exit 
		ctx = alcGetCurrentContext(); 
		dev = alcGetContextsDevice(ctx); 
		alcMakeContextCurrent(NULL); 
		alcDestroyContext(ctx); 
		alcCloseDevice(dev);

		return 0;
	}

	What things I missed to make this code work ??? What i'm doing wrong ???

	Any advice could help, thanks.

	ANSWER: You are not calling alSourcePlay(source[0]) to start the playback.
	
	ANSWER: People should also keep in mind that alSourcePlay() will execute asynchronously. So if you immediately clean up your audio resources after it returns, you probably won't hear anything at all before the program immediately exits. 
	---
	include <AL/al.h>    // OpenAL header files
	#include <AL/alc.h>

	#include <list>

	using std::list;

	#define FREQ 22050   // Sample rate
	#define CAP_SIZE 2048 // How much to capture at a time (affects latency)

	int main(int argC,char* argV[])
	{
		list<ALuint> bufferQueue; // A quick and dirty queue of buffer objects

		ALenum errorCode=0;
		ALuint helloBuffer[16], helloSource[1];
		ALCdevice* audioDevice = alcOpenDevice(NULL); // Request default audio device
		errorCode = alcGetError(audioDevice);
		ALCcontext* audioContext = alcCreateContext(audioDevice,NULL); // Create the audio context
		alcMakeContextCurrent(audioContext);
		errorCode = alcGetError(audioDevice);
		// Request the default capture device with a half-second buffer
		ALCdevice* inputDevice = alcCaptureOpenDevice(NULL,FREQ,AL_FORMAT_MONO16,FREQ/2);
		errorCode = alcGetError(inputDevice);
		alcCaptureStart(inputDevice); // Begin capturing
		errorCode = alcGetError(inputDevice);

		alGenBuffers(16,&helloBuffer[0]); // Create some buffer-objects
		errorCode = alGetError();

		// Queue our buffers onto an STL list
		for (int ii=0;ii<16;++ii) {
			bufferQueue.push_back(helloBuffer[ii]);
		}

	  alGenSources (1, &helloSource[0]); // Create a sound source
		errorCode = alGetError();

		short buffer[FREQ*2]; // A buffer to hold captured audio
		ALCint samplesIn=0;  // How many samples are captured
		ALint availBuffers=0; // Buffers to be recovered
		ALuint myBuff; // The buffer we're using
		ALuint buffHolder[16]; // An array to hold catch the unqueued buffers
		bool done = false;
		while (!done) { // Main loop
			// Poll for recoverable buffers
			alGetSourcei(helloSource[0],AL_BUFFERS_PROCESSED,&availBuffers);
			if (availBuffers>0) {
				alSourceUnqueueBuffers(helloSource[0],availBuffers,buffHolder);
				for (int ii=0;ii<availBuffers;++ii) {
					// Push the recovered buffers back on the queue
					bufferQueue.push_back(buffHolder[ii]);
				}
			}
			// Poll for captured audio
			alcGetIntegerv(inputDevice,ALC_CAPTURE_SAMPLES,1,&samplesIn);
			if (samplesIn>CAP_SIZE) {
				// Grab the sound
				alcCaptureSamples(inputDevice,buffer,CAP_SIZE);

				//***** Process/filter captured data here *****//
				//for (int ii=0;ii<CAP_SIZE;++ii) {
				//  buffer[ii]*=0.1; // Make it quieter
				//}

				// Stuff the captured data in a buffer-object
				if (!bufferQueue.empty()) { // We just drop the data if no buffers are available
					myBuff = bufferQueue.front(); bufferQueue.pop_front();
					alBufferData(myBuff,AL_FORMAT_MONO16,buffer,CAP_SIZE*sizeof(short),FREQ);

					// Queue the buffer
					alSourceQueueBuffers(helloSource[0],1,&myBuff);

					// Restart the source if needed
					// (if we take too long and the queue dries up,
					//  the source stops playing).
					ALint sState=0;
					alGetSourcei(helloSource[0],AL_SOURCE_STATE,&sState);
					if (sState!=AL_PLAYING) {
						alSourcePlay(helloSource[0]);
					}
				}
			}
		}
		// Stop capture
		alcCaptureStop(inputDevice);
		alcCaptureCloseDevice(inputDevice);

		// Stop the sources
		alSourceStopv(1,&helloSource[0]);
		for (int ii=0;ii<1;++ii) {
			alSourcei(helloSource[ii],AL_BUFFER,0);
		}
		// Clean-up 
		alDeleteSources(1,&helloSource[0]); 
		alDeleteBuffers(16,&helloBuffer[0]);
		errorCode = alGetError();
		alcMakeContextCurrent(NULL);
		errorCode = alGetError();
		alcDestroyContext(audioContext);
		alcCloseDevice(audioDevice);

		return 0;
	}
	</code></pre>
</ul>
</details>






<style>
<!-- ul.index { -->
	<!-- display: flex; -->
	<!-- flex-direction: row; -->
	<!-- flex-wrap: wrap; -->
	<!-- margin: auto 0; -->
<!-- } -->

<!-- li { -->
	<!-- margin: 1rem auto; -->
	<!-- padding: 1rem; -->
	<!-- border: 1px dashed green; -->
	<!-- list-style-type: none; -->
	<!-- text-decoration: none; -->
	<!-- min-width: 20rem; -->
	<!-- width: 30%; -->
	<!-- min-height: 40rem; -->
	<!-- height: 25%; -->
	
<!-- } -->

<!-- a { -->
	<!-- color: powerblue; -->
	<!-- background: tomato; -->
	<!-- font-family: "Helvetica, Arial, sans-serif"; -->
<!-- } -->
</style>

<script>
	const update = document.getElementById("update").innerText = "Timestamp needed..";
	const images = document.querySelectorAll("img");
	const index = document.querySelectorAll(".index");
	const summary = document.querySelectorAll("details");
	const source = document.querySelectorAll("pre");
	const code = document.querySelectorAll("code");
	const note = document.querySelectorAll("#note");
		
	<!-- function addLineNumbers (code) { -->
		<!-- let lines = code.innerHTML.split("\n"); -->
		<!-- while (code.childNode.length > 0) { -->
			<!-- code.removeChild(code.childNode[0]); -->
		<!-- } -->
		
		<!-- for (let i = 0; i < lines.length; i++) { -->
			<!-- let span = document.createElement("span"); -->
			<!-- span.className = "line"; -->
			<!-- span.innerText = lines[i]; -->
			<!-- code.appendChild(span); -->
			<!-- code.appendChild(document.createTextNode("\n")); -->
		<!-- } -->
	<!-- } -->
	
	<!-- window.addEventListnere("load", function() { -->
		<!-- let pres = document.getElementTagName("code"); -->
		<!-- for (let i = 0; i < pres.length; i++) { -->
			<!-- addLineNumbers(pres[i]); -->
		<!-- } -->
	<!-- }, false); -->
	
	<!-- function addLineClass (pre) { -->
		<!-- var lines = pre.innerText.split("\n"); // can use innerHTML also -->
		<!-- while(pre.childNodes.length > 0) { -->
			<!-- pre.removeChild(pre.childNodes[0]); -->
		<!-- } -->
		<!-- for(var i = 0; i < lines.length; i++) { -->
			<!-- var span = document.createElement("span"); -->
			<!-- span.className = "line"; -->
			<!-- span.innerText = lines[i]; // can use innerHTML also -->
			<!-- pre.appendChild(span); -->
			<!-- pre.appendChild(document.createTextNode("\n")); -->
		<!-- } -->
	<!-- } -->
    
    <!-- window.addEventListener("load", function () { -->
		<!-- var pres = document.getElementsByTagName("pre"); -->
		<!-- for (var i = 0; i < pres.length; i++) { -->
			<!-- addLineClass(pres[i]); -->
		<!-- } -->
	<!-- }, false); -->
	
	// Read all tokens within <pre><code>
	const tokens = [];
	// Highlight reserved keywords, but scan entire line to remove notes etc.
	const keywords = [
		'#include', '#pragma', '#define',
		'argc', 'argv[]',
		'NULL', 'unsigned', 'typedef', 'struct', 'union', 'enum', 
		'void', 'void*', 'void *', 
		'char', 'char*', 'char *', 
		'string',
		'short', 'int', 'float', 'double', 'long',
		'bool', 'true', 'false', 
		'if', 'else if', 'else',
		'for', 'do', 'while',
		'switch', 'case',  
		'//', '/*',	'*/', 
		'default', 'return' 
	];
	let text = "";
	//keywords.forEach(syntax_highlight, code);
	
	<!-- function show_index (index) { -->
		<!-- index.forEach(list => { -->
			<!-- list.style.listStyleType = "none"; -->
			<!-- list.style.height = "100vh"; -->
		<!-- }); -->
	<!-- } -->
	
	function details_styling (summary) {
		summary.forEach(item => {
			item.style.paddingLeft = "1rem";
			item.style.cursor = "pointer";
			// item.style.fontSize = "28px";
			item.style.color = "darkslateblue";
		});
	}
	<!-- Should be renamed first_occuranse and been used to mark words with a class (p0, highlight, first-time) in i-tags -->
	<!-- function italic_styling (i) { -->
		<!-- italic.forEach(el => { -->
			<!-- el.style.backgroundColor = "tomato"; -->
			<!-- el.style.fontFamily = "sans-serif"; -->
			<!-- el.style.fontWeight = "700"; -->
		<!-- }); -->
	<!-- } -->
	function show_images (img) {
		let count = 0;
		img.forEach(image => {
			image.style.display = "block";
			
			if (image.style.width <= image.style.height) {
				<!-- if (image.style.width % 2 !== 1) { -->
					<!-- image.style.width = "570px"; -->
				<!-- } else { -->
					<!-- image.style.width = "640px; -->
				<!-- } -->
				count+=1;
			} 
			else if (image.style.width >= image.style.height) {
				image.style.width = "720px";
				count+=1;
			}
			<!-- console.log("ran", count); -->
		});
	}
	function sourcecode (src) {
		src.forEach(code => {
			code.style.padding = "40px 24px";
			code.style.background = "#F2EFEB";
			code.style.color = "#003712";
		});
	}
	// const words = Array.from(code, codeBlock => codeBlock.textContent.split(" "));
	// will return an array of arrays of words for each <code> element. But since your keywords 
	// array does contain just single words but also phrases, you'll probably have to go with a different approach. I assume that eventually you'll want 
	// to wrap each keyword in a <span> element, is that correct?
	
	function syntax_highlight (syntax, src) {
		// Split each word into an array
		const words = Array.from(code, codeBlock => codeBlock.textContent.split(' ')); 		// List of words contains '\n', '\t' and ""
		
		// Iterates once per code block
		for (let i = 0; i < words.length; i++) {
			for (let index = 0; index < keywords.length; index++) {	
				if (keywords[index] === words[i]) {
					//console.log(`HI ${words[i]}`);
					//console.log(`HELLO ${keywords[index]}`);
					console.log("Match");
				}
				else {
					//console.log("No match");
				}
				if (keywords[index] === words[i]) {
					console.log(`${words[i]} === ${keywords[index]}`);
				} 
				else if (keywords[index] !== words[i]){
					//console.log(`${keywords[index]}`);
				}
				//console.log(words[i], keywords[index]);				
			}
		}
	}
	function show_notes (src) {		
		src.forEach(notes => {
			//bold.style.color = "#000";
			notes.style.padding = "42px 25px";
			notes.style.background = "#F3AB8C";
			notes.style.color = "#16161D"; // Eigengrau (the color you see in the absence of light)
			notes.style.textShadow = "#B9C 0px 0px 1px";
		});
	}
	
	show_index(index);
	details_styling(summary);
	<!-- italic_styling(italic); -->
	show_images(images);
	sourcecode(source);
	show_notes(note);
	syntax_highlight(keywords, code);
</script>
